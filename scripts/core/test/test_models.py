#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸.

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìš´ë¡œë“œëœ ì–¼êµ´ì¸ì‹ ëª¨ë¸ë“¤ì´ ì œëŒ€ë¡œ ë¡œë“œë˜ê³  ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import os
import sys
import logging
import numpy as np
from pathlib import Path
import onnxruntime as ort
import cv2

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.append(str(project_root))

from common.logging import setup_logging

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

class ModelTester:
    """ëª¨ë¸ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.models_dir = Path("models/weights")
        self.test_results = {}
        
    def test_all_models(self):
        """ëª¨ë“  ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
        print("ğŸ§ª Model Testing Started")
        print("=" * 60)
        
        # ì–¼êµ´ ê²€ì¶œ ëª¨ë¸ í…ŒìŠ¤íŠ¸
        self.test_detection_models()
        
        # ì–¼êµ´ ì¸ì‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸
        self.test_recognition_models()
        
        # ê²°ê³¼ ì¶œë ¥
        self.print_test_results()
        
    def test_detection_models(self):
        """ì–¼êµ´ ê²€ì¶œ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“¸ Testing Face Detection Models:")
        print("-" * 40)
        
        detection_models = [
            {
                "name": "SCRFD 10G",
                "path": "face_detection_scrfd_10g_20250628.onnx",
                "input_size": (640, 640)
            },
            {
                "name": "RetinaFace MNet025", 
                "path": "face_detection_retinaface_mnet025_20250628.onnx",
                "input_size": (640, 640)
            }
        ]
        
        for model_info in detection_models:
            result = self.test_onnx_model(
                model_info["name"],
                model_info["path"], 
                model_info["input_size"],
                "detection"
            )
            self.test_results[model_info["name"]] = result
    
    def test_recognition_models(self):
        """ì–¼êµ´ ì¸ì‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ” Testing Face Recognition Models:")
        print("-" * 40)
        
        recognition_models = [
            {
                "name": "ArcFace R100 (Buffalo_L)",
                "path": "face_recognition_arcface_r100_20250628.onnx",
                "input_size": (112, 112)
            },
            {
                "name": "ArcFace R50 (Buffalo_S)",
                "path": "face_recognition_arcface_r50_20250628.onnx", 
                "input_size": (112, 112)
            },
            {
                "name": "MobileFaceNet",
                "path": "face_recognition_mobilefacenet_20250628.onnx",
                "input_size": (112, 112)
            }
        ]
        
        for model_info in recognition_models:
            result = self.test_onnx_model(
                model_info["name"],
                model_info["path"],
                model_info["input_size"], 
                "recognition"
            )
            self.test_results[model_info["name"]] = result
    
    def test_onnx_model(self, model_name: str, model_path: str, input_size: tuple, model_type: str) -> dict:
        """ONNX ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
        full_path = self.models_dir / model_path
        result = {
            "status": "FAILED",
            "error": None,
            "file_exists": False,
            "file_size_mb": 0,
            "loadable": False,
            "input_shape": None,
            "output_shape": None,
            "inference_time_ms": None
        }
        
        try:
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not full_path.exists():
                result["error"] = f"Model file not found: {full_path}"
                print(f"âŒ {model_name}: File not found")
                return result
                
            result["file_exists"] = True
            result["file_size_mb"] = round(full_path.stat().st_size / (1024 * 1024), 1)
            
            # ONNX ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
            try:
                # CPU ì œê³µìë¡œ ì„¸ì…˜ ìƒì„±
                providers = ['CPUExecutionProvider']
                session = ort.InferenceSession(str(full_path), providers=providers)
                result["loadable"] = True
                
                # ì…ë ¥/ì¶œë ¥ ì •ë³´ í™•ì¸
                input_info = session.get_inputs()[0]
                output_info = session.get_outputs()[0]
                result["input_shape"] = input_info.shape
                result["output_shape"] = output_info.shape
                
                # ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ ì¶”ë¡  í…ŒìŠ¤íŠ¸
                if model_type == "detection":
                    # ê²€ì¶œ ëª¨ë¸: [batch, channels, height, width]
                    dummy_input = np.random.rand(1, 3, input_size[1], input_size[0]).astype(np.float32)
                else:
                    # ì¸ì‹ ëª¨ë¸: [batch, channels, height, width] 
                    dummy_input = np.random.rand(1, 3, input_size[1], input_size[0]).astype(np.float32)
                
                # ì¶”ë¡  ì‹œê°„ ì¸¡ì •
                import time
                start_time = time.time()
                
                # ì¶”ë¡  ì‹¤í–‰
                input_name = input_info.name
                outputs = session.run(None, {input_name: dummy_input})
                
                end_time = time.time()
                result["inference_time_ms"] = round((end_time - start_time) * 1000, 2)
                
                result["status"] = "SUCCESS"
                print(f"âœ… {model_name}: OK ({result['file_size_mb']}MB, {result['inference_time_ms']}ms)")
                
            except Exception as e:
                result["error"] = f"Model loading/inference failed: {str(e)}"
                print(f"âŒ {model_name}: Loading failed - {str(e)}")
                
        except Exception as e:
            result["error"] = f"Unexpected error: {str(e)}"
            print(f"âŒ {model_name}: Unexpected error - {str(e)}")
            
        return result
    
    def test_opencv_model(self):
        """OpenCV Haar Cascade ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
        model_path = self.models_dir / "face_detection_opencv_haarcascade_20250628.xml"
        
        try:
            if not model_path.exists():
                print(f"âŒ OpenCV Haar Cascade: File not found")
                return False
                
            # OpenCVë¡œ ë¡œë“œ í…ŒìŠ¤íŠ¸
            face_cascade = cv2.CascadeClassifier(str(model_path))
            
            if face_cascade.empty():
                print(f"âŒ OpenCV Haar Cascade: Failed to load")
                return False
                
            # ë”ë¯¸ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸
            dummy_img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
            gray = cv2.cvtColor(dummy_img, cv2.COLOR_BGR2GRAY)
            
            # ê²€ì¶œ í…ŒìŠ¤íŠ¸
            faces = face_cascade.detectMultiScale(gray, 1.1, 3)
            
            file_size_mb = round(model_path.stat().st_size / (1024 * 1024), 1)
            print(f"âœ… OpenCV Haar Cascade: OK ({file_size_mb}MB)")
            
            self.test_results["OpenCV Haar Cascade"] = {
                "status": "SUCCESS",
                "file_size_mb": file_size_mb
            }
            return True
            
        except Exception as e:
            print(f"âŒ OpenCV Haar Cascade: {str(e)}")
            self.test_results["OpenCV Haar Cascade"] = {
                "status": "FAILED",
                "error": str(e)
            }
            return False
    
    def print_test_results(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\nğŸ“Š Test Results Summary:")
        print("=" * 60)
        
        success_count = 0
        total_count = len(self.test_results)
        
        for model_name, result in self.test_results.items():
            status_icon = "âœ…" if result["status"] == "SUCCESS" else "âŒ"
            print(f"{status_icon} {model_name}")
            
            if result["status"] == "SUCCESS":
                success_count += 1
                if "file_size_mb" in result:
                    print(f"   ğŸ“ Size: {result['file_size_mb']}MB")
                if "inference_time_ms" in result:
                    print(f"   â±ï¸  Inference: {result['inference_time_ms']}ms")
            else:
                print(f"   âŒ Error: {result.get('error', 'Unknown error')}")
            print()
        
        # OpenCV ëª¨ë¸ë„ í…ŒìŠ¤íŠ¸
        self.test_opencv_model()
        if "OpenCV Haar Cascade" in self.test_results:
            if self.test_results["OpenCV Haar Cascade"]["status"] == "SUCCESS":
                success_count += 1
            total_count += 1
        
        print(f"ğŸ¯ Overall Result: {success_count}/{total_count} models passed")
        
        if success_count == total_count:
            print("ğŸ‰ All models are working correctly!")
        else:
            print("âš ï¸  Some models have issues. Check the errors above.")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ëª¨ë¸ í…ŒìŠ¤íŠ¸ ë„êµ¬")
    parser.add_argument("--verbose", "-v", action="store_true", help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")
    
    args = parser.parse_args()
    
    # ë¡œê¹… ì„¤ì •
    setup_logging()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # ëª¨ë¸ í…ŒìŠ¤í„° ì‹¤í–‰
    tester = ModelTester()
    tester.test_all_models()


if __name__ == "__main__":
    main() 