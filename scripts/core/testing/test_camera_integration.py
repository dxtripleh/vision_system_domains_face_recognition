#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Camera Integration Test Script.

ì‹¤ì œ ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¼êµ´ì¸ì‹ ì‹œìŠ¤í…œì˜ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import cv2
import time
import logging
import numpy as np
from pathlib import Path
from typing import Dict, Any, List, Optional
import json
from datetime import datetime

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from scripts.core.validation.validate_hardware_connection import HardwareValidator
from domains.face_recognition.core.services.face_detection_service import FaceDetectionService
from domains.face_recognition.core.services.face_recognition_service import FaceRecognitionService
from scripts.core.monitoring.performance_monitor import PerformanceMonitor

logger = logging.getLogger(__name__)


class CameraIntegrationTester:
    """ì¹´ë©”ë¼ í†µí•© í…ŒìŠ¤íŠ¸"""
    
    def __init__(self, camera_id: int = 0, test_duration: int = 30):
        self.camera_id = camera_id
        self.test_duration = test_duration
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
        self.test_results = {
            'start_time': None,
            'end_time': None,
            'hardware_status': {},
            'detection_results': [],
            'recognition_results': [],
            'performance_metrics': {},
            'errors': [],
            'summary': {}
        }
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.hardware_validator = HardwareValidator()
        self.detection_service = FaceDetectionService(use_mock=False)
        self.recognition_service = FaceRecognitionService(use_mock=False)
        self.performance_monitor = PerformanceMonitor()
        
        # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        self.results_dir = Path("data/test_results")
        self.results_dir.mkdir(parents=True, exist_ok=True)
    
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("ğŸš€ ì¹´ë©”ë¼ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        self.test_results['start_time'] = datetime.now().isoformat()
        
        try:
            # 1. í•˜ë“œì›¨ì–´ ê²€ì¦
            logger.info("1ï¸âƒ£ í•˜ë“œì›¨ì–´ ì—°ê²° ê²€ì¦...")
            self._test_hardware_connection()
            
            # 2. ì¹´ë©”ë¼ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
            logger.info("2ï¸âƒ£ ì¹´ë©”ë¼ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸...")
            self._test_camera_basic_functions()
            
            # 3. ì–¼êµ´ ê²€ì¶œ í…ŒìŠ¤íŠ¸
            logger.info("3ï¸âƒ£ ì‹¤ì‹œê°„ ì–¼êµ´ ê²€ì¶œ í…ŒìŠ¤íŠ¸...")
            self._test_face_detection()
            
            # 4. ì–¼êµ´ ì¸ì‹ í…ŒìŠ¤íŠ¸ (ì¸ë¬¼ì´ ë“±ë¡ëœ ê²½ìš°)
            logger.info("4ï¸âƒ£ ì–¼êµ´ ì¸ì‹ í…ŒìŠ¤íŠ¸...")
            self._test_face_recognition()
            
            # 5. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
            logger.info("5ï¸âƒ£ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬...")
            self._test_performance_benchmark()
            
            # 6. ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸
            logger.info("6ï¸âƒ£ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸...")
            self._test_stress_conditions()
            
            # ê²°ê³¼ ë¶„ì„ ë° ìš”ì•½
            self._analyze_results()
            
            logger.info("âœ… ì¹´ë©”ë¼ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
            
        except Exception as e:
            error_msg = f"í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            logger.error(error_msg)
            self.test_results['errors'].append(error_msg)
        
        finally:
            self.test_results['end_time'] = datetime.now().isoformat()
            self._save_test_results()
        
        return self.test_results
    
    def _test_hardware_connection(self):
        """í•˜ë“œì›¨ì–´ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            # ì¹´ë©”ë¼ ì—°ê²° ê²€ì¦
            validation_result = self.hardware_validator.validate_camera_connection(self.camera_id)
            self.test_results['hardware_status'] = validation_result
            
            if not validation_result['camera_available']:
                raise RuntimeError("ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            logger.info(f"  âœ… ì¹´ë©”ë¼ {self.camera_id} ì—°ê²° í™•ì¸")
            logger.info(f"  ğŸ“¹ í•´ìƒë„: {validation_result['resolution']}")
            logger.info(f"  ğŸ¥ FPS: {validation_result['fps']}")
            
        except Exception as e:
            error_msg = f"í•˜ë“œì›¨ì–´ ê²€ì¦ ì‹¤íŒ¨: {str(e)}"
            self.test_results['errors'].append(error_msg)
            raise
    
    def _test_camera_basic_functions(self):
        """ì¹´ë©”ë¼ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        cap = None
        try:
            cap = cv2.VideoCapture(self.camera_id)
            
            if not cap.isOpened():
                raise RuntimeError("ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # í•´ìƒë„ ì„¤ì • í…ŒìŠ¤íŠ¸
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            
            # í”„ë ˆì„ ìº¡ì²˜ í…ŒìŠ¤íŠ¸
            frame_count = 0
            test_frames = 10
            
            for i in range(test_frames):
                ret, frame = cap.read()
                if ret and frame is not None:
                    frame_count += 1
                    # ì²« ë²ˆì§¸ í”„ë ˆì„ ì €ì¥
                    if i == 0:
                        test_image_path = self.results_dir / "test_frame.jpg"
                        cv2.imwrite(str(test_image_path), frame)
                
                time.sleep(0.1)
            
            success_rate = frame_count / test_frames
            logger.info(f"  ğŸ“Š í”„ë ˆì„ ìº¡ì²˜ ì„±ê³µë¥ : {success_rate:.1%}")
            
            if success_rate < 0.8:
                self.test_results['errors'].append(f"ë‚®ì€ í”„ë ˆì„ ìº¡ì²˜ ì„±ê³µë¥ : {success_rate:.1%}")
            
        except Exception as e:
            error_msg = f"ì¹´ë©”ë¼ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"
            self.test_results['errors'].append(error_msg)
            raise
        
        finally:
            if cap:
                cap.release()
    
    def _test_face_detection(self):
        """ì–¼êµ´ ê²€ì¶œ í…ŒìŠ¤íŠ¸"""
        cap = None
        try:
            cap = cv2.VideoCapture(self.camera_id)
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            
            detection_count = 0
            total_frames = 0
            processing_times = []
            
            logger.info("  ğŸ‘¤ ì–¼êµ´ì„ ì¹´ë©”ë¼ ì•ì— ìœ„ì¹˜ì‹œì¼œ ì£¼ì„¸ìš”...")
            
            start_time = time.time()
            while time.time() - start_time < 10:  # 10ì´ˆê°„ í…ŒìŠ¤íŠ¸
                ret, frame = cap.read()
                if not ret:
                    continue
                
                total_frames += 1
                
                # ì–¼êµ´ ê²€ì¶œ
                detection_start = time.perf_counter()
                result = self.detection_service.detect_faces(frame)
                processing_time = (time.perf_counter() - detection_start) * 1000
                
                processing_times.append(processing_time)
                
                if result.face_count > 0:
                    detection_count += 1
                    
                    # ì²« ë²ˆì§¸ ê²€ì¶œ ì‹œ ì´ë¯¸ì§€ ì €ì¥
                    if detection_count == 1:
                        # ê²€ì¶œëœ ì–¼êµ´ì— ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                        annotated_frame = frame.copy()
                        for face in result.faces:
                            x, y, w, h = face.bbox
                            cv2.rectangle(annotated_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                            cv2.putText(annotated_frame, f"Confidence: {face.confidence:.2f}", 
                                      (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
                        
                        detection_image_path = self.results_dir / "face_detection_result.jpg"
                        cv2.imwrite(str(detection_image_path), annotated_frame)
                        logger.info(f"    ğŸ’¾ ê²€ì¶œ ê²°ê³¼ ì €ì¥: {detection_image_path}")
                
                # ì‹¤ì‹œê°„ í”¼ë“œë°±
                if total_frames % 30 == 0:  # 30í”„ë ˆì„ë§ˆë‹¤
                    current_rate = detection_count / total_frames if total_frames > 0 else 0
                    logger.info(f"    ğŸ“ˆ í˜„ì¬ ê²€ì¶œë¥ : {current_rate:.1%} ({detection_count}/{total_frames})")
            
            # ê²°ê³¼ ì €ì¥
            detection_rate = detection_count / total_frames if total_frames > 0 else 0
            avg_processing_time = np.mean(processing_times) if processing_times else 0
            
            detection_result = {
                'total_frames': total_frames,
                'detection_count': detection_count,
                'detection_rate': detection_rate,
                'avg_processing_time_ms': avg_processing_time,
                'max_processing_time_ms': max(processing_times) if processing_times else 0,
                'min_processing_time_ms': min(processing_times) if processing_times else 0
            }
            
            self.test_results['detection_results'] = detection_result
            
            logger.info(f"  ğŸ“Š ê²€ì¶œë¥ : {detection_rate:.1%}")
            logger.info(f"  â±ï¸ í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_processing_time:.1f}ms")
            
            if detection_rate < 0.3:
                self.test_results['errors'].append(f"ë‚®ì€ ì–¼êµ´ ê²€ì¶œë¥ : {detection_rate:.1%}")
            
        except Exception as e:
            error_msg = f"ì–¼êµ´ ê²€ì¶œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"
            self.test_results['errors'].append(error_msg)
            logger.error(error_msg)
        
        finally:
            if cap:
                cap.release()
    
    def _test_face_recognition(self):
        """ì–¼êµ´ ì¸ì‹ í…ŒìŠ¤íŠ¸"""
        # Mock ëª¨ë“œì—ì„œëŠ” ì¸ì‹ í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ
        if self.recognition_service.use_mock:
            logger.info("  âš ï¸ Mock ëª¨ë“œì—ì„œëŠ” ì–¼êµ´ ì¸ì‹ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤")
            return
        
        cap = None
        try:
            cap = cv2.VideoCapture(self.camera_id)
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            
            recognition_attempts = 0
            recognition_success = 0
            processing_times = []
            
            logger.info("  ğŸ§‘â€ğŸ’¼ ë“±ë¡ëœ ì¸ë¬¼ì˜ ì–¼êµ´ì„ ì¹´ë©”ë¼ ì•ì— ìœ„ì¹˜ì‹œì¼œ ì£¼ì„¸ìš”...")
            
            start_time = time.time()
            while time.time() - start_time < 15:  # 15ì´ˆê°„ í…ŒìŠ¤íŠ¸
                ret, frame = cap.read()
                if not ret:
                    continue
                
                # ì–¼êµ´ ê²€ì¶œ
                detection_result = self.detection_service.detect_faces(frame)
                
                if detection_result.face_count > 0:
                    for face in detection_result.faces:
                        recognition_attempts += 1
                        
                        # ì–¼êµ´ ì¸ì‹
                        recognition_start = time.perf_counter()
                        identified_person = self.recognition_service.identify_face(face)
                        processing_time = (time.perf_counter() - recognition_start) * 1000
                        
                        processing_times.append(processing_time)
                        
                        if identified_person:
                            recognition_success += 1
                            logger.info(f"    âœ… ì¸ì‹ ì„±ê³µ: {identified_person.name}")
                
                time.sleep(0.1)
            
            # ê²°ê³¼ ì €ì¥
            recognition_rate = recognition_success / recognition_attempts if recognition_attempts > 0 else 0
            avg_processing_time = np.mean(processing_times) if processing_times else 0
            
            recognition_result = {
                'recognition_attempts': recognition_attempts,
                'recognition_success': recognition_success,
                'recognition_rate': recognition_rate,
                'avg_processing_time_ms': avg_processing_time
            }
            
            self.test_results['recognition_results'] = recognition_result
            
            logger.info(f"  ğŸ“Š ì¸ì‹ë¥ : {recognition_rate:.1%}")
            logger.info(f"  â±ï¸ í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_processing_time:.1f}ms")
            
        except Exception as e:
            error_msg = f"ì–¼êµ´ ì¸ì‹ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"
            self.test_results['errors'].append(error_msg)
            logger.error(error_msg)
        
        finally:
            if cap:
                cap.release()
    
    def _test_performance_benchmark(self):
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸"""
        try:
            self.performance_monitor.start_monitoring()
            
            cap = cv2.VideoCapture(self.camera_id)
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            
            frame_times = []
            fps_values = []
            
            logger.info("  ğŸƒâ€â™‚ï¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘...")
            
            start_time = time.time()
            frame_count = 0
            
            while time.time() - start_time < 10:  # 10ì´ˆê°„ ë²¤ì¹˜ë§ˆí¬
                frame_start = time.perf_counter()
                
                ret, frame = cap.read()
                if ret:
                    # ì–¼êµ´ ê²€ì¶œ ìˆ˜í–‰
                    self.detection_service.detect_faces(frame)
                    frame_count += 1
                
                frame_end = time.perf_counter()
                frame_time = frame_end - frame_start
                frame_times.append(frame_time)
                
                # FPS ê³„ì‚°
                if frame_count > 1:
                    fps = 1.0 / frame_time if frame_time > 0 else 0
                    fps_values.append(fps)
                    
                    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡
                    self.performance_monitor.record_vision_metrics(
                        fps=fps,
                        processing_time_ms=frame_time * 1000,
                        detection_count=1
                    )
            
            cap.release()
            
            # ì„±ëŠ¥ í†µê³„ ê³„ì‚°
            avg_fps = np.mean(fps_values) if fps_values else 0
            avg_frame_time = np.mean(frame_times) if frame_times else 0
            
            performance_result = {
                'avg_fps': avg_fps,
                'max_fps': max(fps_values) if fps_values else 0,
                'min_fps': min(fps_values) if fps_values else 0,
                'avg_frame_time_ms': avg_frame_time * 1000,
                'total_frames': frame_count
            }
            
            self.test_results['performance_metrics'] = performance_result
            
            logger.info(f"  ğŸ“ˆ í‰ê·  FPS: {avg_fps:.1f}")
            logger.info(f"  â±ï¸ í‰ê·  í”„ë ˆì„ ì‹œê°„: {avg_frame_time*1000:.1f}ms")
            
            self.performance_monitor.stop_monitoring()
            
        except Exception as e:
            error_msg = f"ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {str(e)}"
            self.test_results['errors'].append(error_msg)
            logger.error(error_msg)
    
    def _test_stress_conditions(self):
        """ìŠ¤íŠ¸ë ˆìŠ¤ ì¡°ê±´ í…ŒìŠ¤íŠ¸"""
        try:
            logger.info("  ğŸ’ª ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
            
            cap = cv2.VideoCapture(self.camera_id)
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            
            # ì—°ì† ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ (30ì´ˆê°„)
            stress_duration = 30
            start_time = time.time()
            frame_count = 0
            error_count = 0
            
            while time.time() - start_time < stress_duration:
                try:
                    ret, frame = cap.read()
                    if ret:
                        # ì–¼êµ´ ê²€ì¶œ ì—°ì† ìˆ˜í–‰
                        self.detection_service.detect_faces(frame)
                        frame_count += 1
                    else:
                        error_count += 1
                
                except Exception as e:
                    error_count += 1
                    logger.warning(f"    âš ï¸ í”„ë ˆì„ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            
            cap.release()
            
            # ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ê²°ê³¼
            error_rate = error_count / (frame_count + error_count) if (frame_count + error_count) > 0 else 0
            
            stress_result = {
                'duration_seconds': stress_duration,
                'total_frames': frame_count,
                'error_count': error_count,
                'error_rate': error_rate,
                'avg_fps_under_stress': frame_count / stress_duration
            }
            
            self.test_results['stress_test'] = stress_result
            
            logger.info(f"  ğŸ“Š ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ - ì²˜ë¦¬ í”„ë ˆì„: {frame_count}")
            logger.info(f"  âŒ ì˜¤ë¥˜ìœ¨: {error_rate:.1%}")
            
            if error_rate > 0.05:  # 5% ì´ìƒ ì˜¤ë¥˜
                self.test_results['errors'].append(f"ë†’ì€ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜ìœ¨: {error_rate:.1%}")
            
        except Exception as e:
            error_msg = f"ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"
            self.test_results['errors'].append(error_msg)
            logger.error(error_msg)
    
    def _analyze_results(self):
        """ê²°ê³¼ ë¶„ì„ ë° ìš”ì•½"""
        summary = {
            'overall_status': 'PASS',
            'test_duration': None,
            'hardware_ok': False,
            'detection_ok': False,
            'recognition_ok': False,
            'performance_ok': False,
            'recommendations': []
        }
        
        # í…ŒìŠ¤íŠ¸ ì§€ì† ì‹œê°„ ê³„ì‚°
        if self.test_results['start_time'] and self.test_results['end_time']:
            start = datetime.fromisoformat(self.test_results['start_time'])
            end = datetime.fromisoformat(self.test_results['end_time'])
            summary['test_duration'] = (end - start).total_seconds()
        
        # í•˜ë“œì›¨ì–´ ìƒíƒœ í™•ì¸
        hardware_status = self.test_results.get('hardware_status', {})
        summary['hardware_ok'] = hardware_status.get('camera_available', False)
        
        # ê²€ì¶œ ì„±ëŠ¥ í™•ì¸
        detection_results = self.test_results.get('detection_results', {})
        detection_rate = detection_results.get('detection_rate', 0)
        summary['detection_ok'] = detection_rate >= 0.3
        
        # ì¸ì‹ ì„±ëŠ¥ í™•ì¸ (Mock ëª¨ë“œê°€ ì•„ë‹Œ ê²½ìš°)
        if not self.recognition_service.use_mock:
            recognition_results = self.test_results.get('recognition_results', {})
            recognition_rate = recognition_results.get('recognition_rate', 0)
            summary['recognition_ok'] = recognition_rate >= 0.5
        else:
            summary['recognition_ok'] = True  # Mock ëª¨ë“œì—ì„œëŠ” Pass
        
        # ì„±ëŠ¥ í™•ì¸
        performance_metrics = self.test_results.get('performance_metrics', {})
        avg_fps = performance_metrics.get('avg_fps', 0)
        summary['performance_ok'] = avg_fps >= 10
        
        # ì „ì²´ ìƒíƒœ ê²°ì •
        if self.test_results['errors'] or not all([
            summary['hardware_ok'],
            summary['detection_ok'],
            summary['recognition_ok'],
            summary['performance_ok']
        ]):
            summary['overall_status'] = 'FAIL'
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        if not summary['hardware_ok']:
            summary['recommendations'].append("ì¹´ë©”ë¼ ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”")
        
        if not summary['detection_ok']:
            summary['recommendations'].append("ì¡°ëª… ì¡°ê±´ì„ ê°œì„ í•˜ê±°ë‚˜ ì¹´ë©”ë¼ ìœ„ì¹˜ë¥¼ ì¡°ì •í•˜ì„¸ìš”")
        
        if not summary['performance_ok']:
            summary['recommendations'].append("ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ë¥¼ í™•ì¸í•˜ê³  ë¶ˆí•„ìš”í•œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•˜ì„¸ìš”")
        
        if avg_fps < 15:
            summary['recommendations'].append("í•´ìƒë„ë¥¼ ë‚®ì¶”ê±°ë‚˜ GPU ê°€ì†ì„ í™œì„±í™”í•˜ì„¸ìš”")
        
        self.test_results['summary'] = summary
    
    def _save_test_results(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        results_file = self.results_dir / f"camera_test_results_{timestamp}.json"
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {results_file}")
    
    def print_summary(self):
        """í…ŒìŠ¤íŠ¸ ìš”ì•½ ì¶œë ¥"""
        summary = self.test_results.get('summary', {})
        
        print("\n" + "="*60)
        print("ğŸ¯ ì¹´ë©”ë¼ í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("="*60)
        
        status_emoji = "âœ…" if summary.get('overall_status') == 'PASS' else "âŒ"
        print(f"{status_emoji} ì „ì²´ ìƒíƒœ: {summary.get('overall_status', 'UNKNOWN')}")
        
        if summary.get('test_duration'):
            print(f"â±ï¸ í…ŒìŠ¤íŠ¸ ì‹œê°„: {summary['test_duration']:.1f}ì´ˆ")
        
        print(f"ğŸ”§ í•˜ë“œì›¨ì–´: {'âœ… OK' if summary.get('hardware_ok') else 'âŒ FAIL'}")
        print(f"ğŸ‘¤ ì–¼êµ´ ê²€ì¶œ: {'âœ… OK' if summary.get('detection_ok') else 'âŒ FAIL'}")
        print(f"ğŸ§‘â€ğŸ’¼ ì–¼êµ´ ì¸ì‹: {'âœ… OK' if summary.get('recognition_ok') else 'âŒ FAIL'}")
        print(f"ğŸš€ ì„±ëŠ¥: {'âœ… OK' if summary.get('performance_ok') else 'âŒ FAIL'}")
        
        # ìƒì„¸ ë©”íŠ¸ë¦­
        if self.test_results.get('detection_results'):
            detection = self.test_results['detection_results']
            print(f"\nğŸ“Š ê²€ì¶œ ì„±ëŠ¥:")
            print(f"   - ê²€ì¶œë¥ : {detection.get('detection_rate', 0):.1%}")
            print(f"   - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {detection.get('avg_processing_time_ms', 0):.1f}ms")
        
        if self.test_results.get('performance_metrics'):
            performance = self.test_results['performance_metrics']
            print(f"\nğŸ“ˆ ì „ì²´ ì„±ëŠ¥:")
            print(f"   - í‰ê·  FPS: {performance.get('avg_fps', 0):.1f}")
            print(f"   - ìµœëŒ€ FPS: {performance.get('max_fps', 0):.1f}")
        
        # ì˜¤ë¥˜ ë° ê¶Œì¥ì‚¬í•­
        if self.test_results.get('errors'):
            print(f"\nâŒ ë°œê²¬ëœ ë¬¸ì œì :")
            for error in self.test_results['errors']:
                print(f"   - {error}")
        
        if summary.get('recommendations'):
            print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
            for rec in summary['recommendations']:
                print(f"   - {rec}")
        
        print("="*60)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ì¹´ë©”ë¼ í†µí•© í…ŒìŠ¤íŠ¸")
    parser.add_argument(
        "--camera-id", 
        type=int, 
        default=0,
        help="ì¹´ë©”ë¼ ID (ê¸°ë³¸ê°’: 0)"
    )
    parser.add_argument(
        "--duration", 
        type=int, 
        default=30,
        help="í…ŒìŠ¤íŠ¸ ì§€ì† ì‹œê°„ (ì´ˆ, ê¸°ë³¸ê°’: 30)"
    )
    parser.add_argument(
        "--quick", 
        action="store_true",
        help="ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ê¸°ë³¸ ê¸°ëŠ¥ë§Œ)"
    )
    
    args = parser.parse_args()
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)8s] %(message)s'
    )
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    tester = CameraIntegrationTester(
        camera_id=args.camera_id,
        test_duration=args.duration
    )
    
    try:
        print(f"\nğŸ¬ ì¹´ë©”ë¼ {args.camera_id} í†µí•© í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        print("ğŸ“‹ í…ŒìŠ¤íŠ¸ í•­ëª©:")
        print("   1. í•˜ë“œì›¨ì–´ ì—°ê²° ê²€ì¦")
        print("   2. ì¹´ë©”ë¼ ê¸°ë³¸ ê¸°ëŠ¥")
        print("   3. ì–¼êµ´ ê²€ì¶œ í…ŒìŠ¤íŠ¸")
        print("   4. ì–¼êµ´ ì¸ì‹ í…ŒìŠ¤íŠ¸")
        print("   5. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
        if not args.quick:
            print("   6. ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸")
        print()
        
        if args.quick:
            # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ
            tester._test_hardware_connection()
            tester._test_camera_basic_functions()
            tester._test_face_detection()
            tester._analyze_results()
        else:
            # ì „ì²´ í…ŒìŠ¤íŠ¸
            tester.run_comprehensive_test()
        
        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        tester.print_summary()
        
        # ì„±ê³µ/ì‹¤íŒ¨ ë°˜í™˜
        summary = tester.test_results.get('summary', {})
        return 0 if summary.get('overall_status') == 'PASS' else 1
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return 1
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return 1


if __name__ == "__main__":
    exit(main()) 