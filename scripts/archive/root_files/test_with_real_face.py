#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì‹¤ì œ ì–¼êµ´ ì´ë¯¸ì§€ë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸
"""

import cv2
import numpy as np
from pathlib import Path

def test_with_real_face():
    """ì‹¤ì œ ì–¼êµ´ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸"""
    
    # ì¹´ë©”ë¼ì—ì„œ ì‹¤ì œ ì–¼êµ´ ì´ë¯¸ì§€ ìº¡ì²˜
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("ğŸ“· ì¹´ë©”ë¼ì—ì„œ ì–¼êµ´ì„ ìº¡ì²˜í•©ë‹ˆë‹¤. 3ì´ˆ í›„ ì´¬ì˜ë©ë‹ˆë‹¤...")
    
    # 3ì´ˆ ëŒ€ê¸°
    for i in range(3, 0, -1):
        print(f"{i}...")
        cv2.waitKey(1000)
    
    ret, frame = cap.read()
    cap.release()
    
    if not ret:
        print("âŒ ì´ë¯¸ì§€ë¥¼ ìº¡ì²˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… ì´ë¯¸ì§€ ìº¡ì²˜ ì™„ë£Œ: {frame.shape}")
    
    # ì´ë¯¸ì§€ ì €ì¥
    cv2.imwrite("test_face.jpg", frame)
    print("ğŸ’¾ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì €ì¥: test_face.jpg")
    
    # ëª¨ë¸ í…ŒìŠ¤íŠ¸
    models = [
        ('YuNet', 'face_detection_yunet_2023mar.onnx', 'yunet'),
        ('UltraFace', 'ultraface_rfb_320_robust.onnx', 'ultraface'),
        ('RetinaFace', 'face_detection_retinaface_resnet50.onnx', 'retinaface'),
        ('SCRFD', 'face_detection_scrfd_10g_20250628.onnx', 'scrfd')
    ]
    
    for name, model_file, model_type in models:
        print(f"\n{'='*30}")
        print(f"í…ŒìŠ¤íŠ¸: {name}")
        
        model_path = Path('models/weights') / model_file
        
        if not model_path.exists():
            print(f"âŒ íŒŒì¼ ì—†ìŒ: {model_file}")
            continue
        
        try:
            # ëª¨ë¸ ë¡œë“œ
            net = cv2.dnn.readNetFromONNX(str(model_path))
            print(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
            
            # ì „ì²˜ë¦¬
            if model_type == 'yunet':
                blob = cv2.dnn.blobFromImage(frame, 1.0, (320, 320), (0, 0, 0), True, False)
            elif model_type == 'ultraface':
                resized = cv2.resize(frame, (320, 240))
                blob = resized.astype(np.float32)
                blob = (blob - 127.0) / 127.0
                blob = blob.transpose(2, 0, 1)[np.newaxis, :]
            else:  # retinaface, scrfd
                blob = cv2.dnn.blobFromImage(frame, 1.0, (640, 640), (0, 0, 0), True, False)
            
            # ì¶”ë¡ 
            net.setInput(blob)
            outputs = net.forward()
            
            print(f"ì¶œë ¥ shape: {[out.shape for out in outputs]}")
            
            # ê²€ì¶œ ê²°ê³¼ í™•ì¸
            detections = []
            
            if model_type == 'yunet' and len(outputs) > 0:
                output = outputs[0]
                print(f"YuNet ì¶œë ¥ ìƒ˜í”Œ: {output[0] if len(output) > 0 else 'None'}")
                
                for detection in output:
                    if len(detection) >= 10:  # YuNetì€ 10ê°œ ê°’
                        confidence = detection[4] if len(detection) > 4 else 0.5
                        if confidence > 0.1:
                            detections.append({
                                'bbox': [0, 0, 100, 100],  # ì„ì‹œ ê°’
                                'confidence': float(confidence),
                                'model_type': 'yunet'
                            })
            
            elif model_type == 'ultraface' and len(outputs) > 0:
                boxes = outputs[0]
                print(f"UltraFace ì¶œë ¥ ìƒ˜í”Œ: {boxes[0] if len(boxes) > 0 else 'None'}")
                
                # ìƒìœ„ 5ê°œë§Œ ì‚¬ìš©
                for i, box in enumerate(boxes[:5]):
                    if len(box) >= 4:
                        x1, y1, x2, y2 = box[:4]
                        w = x2 - x1
                        h = y2 - y1
                        if w > 0 and h > 0:
                            detections.append({
                                'bbox': [int(x1 * 640 / 320), int(y1 * 480 / 240), 
                                        int(w * 640 / 320), int(h * 480 / 240)],
                                'confidence': 0.8,
                                'model_type': 'ultraface'
                            })
            
            else:  # retinaface, scrfd
                for output in outputs:
                    if len(output.shape) == 2 and output.shape[1] >= 5:
                        print(f"{name} ì¶œë ¥ ìƒ˜í”Œ: {output[0] if len(output) > 0 else 'None'}")
                        
                        for detection in output:
                            if len(detection) >= 5:
                                confidence = detection[4]
                                if confidence > 0.1:
                                    detections.append({
                                        'bbox': [0, 0, 100, 100],  # ì„ì‹œ ê°’
                                        'confidence': float(confidence),
                                        'model_type': model_type
                                    })
            
            print(f"ğŸ” ê²€ì¶œëœ ì–¼êµ´: {len(detections)}ê°œ")
            
            # ê²°ê³¼ ì‹œê°í™”
            result_image = frame.copy()
            for i, det in enumerate(detections):
                bbox = det['bbox']
                confidence = det['confidence']
                model_type = det['model_type']
                
                x, y, w, h = bbox
                cv2.rectangle(result_image, (x, y), (x + w, y + h), (0, 255, 0), 2)
                cv2.putText(result_image, f"{model_type}: {confidence:.2f}", 
                           (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            
            # ê²°ê³¼ ì €ì¥
            output_file = f"result_{model_type}.jpg"
            cv2.imwrite(output_file, result_image)
            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {str(e)}")

if __name__ == "__main__":
    test_with_real_face() 