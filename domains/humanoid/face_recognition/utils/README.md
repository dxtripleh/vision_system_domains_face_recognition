# Utils - ì–¼êµ´ì¸ì‹ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ

## ğŸ“‹ ê°œìš”

ì´ í´ë”ëŠ” ì–¼êµ´ì¸ì‹ ê¸°ëŠ¥ì— í•„ìš”í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ê³¼ í—¬í¼ ìŠ¤í¬ë¦½íŠ¸ë“¤ì„ í¬í•¨í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ ì²˜ë¦¬, ì‹œê°í™”, ë°ì´í„° ë³€í™˜ ë“± ë‹¤ì–‘í•œ ë³´ì¡° ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ—ï¸ í´ë” êµ¬ì¡°

```
utils/
â”œâ”€â”€ __init__.py                    # ìœ í‹¸ë¦¬í‹° íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
â”œâ”€â”€ README.md                      # ì´ íŒŒì¼
â””â”€â”€ demo.py                        # ë°ëª¨ ìŠ¤í¬ë¦½íŠ¸
```

## ğŸ” í¬í•¨ëœ ìœ í‹¸ë¦¬í‹°ë“¤

### 1. Demo Script (ë°ëª¨ ìŠ¤í¬ë¦½íŠ¸)
- **íŒŒì¼**: `demo.py`
- **ëª©ì **: ì–¼êµ´ì¸ì‹ ê¸°ëŠ¥ ë°ëª¨ ë° í…ŒìŠ¤íŠ¸
- **ê¸°ëŠ¥**: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±, ê²°ê³¼ ì‹œê°í™”, ì„±ëŠ¥ ì¸¡ì •
- **ì‚¬ìš©ì²˜**: ê°œë°œ í…ŒìŠ¤íŠ¸, ê¸°ëŠ¥ ê²€ì¦, ë°ëª¨ ì‹œì—°

## ğŸš€ ì‚¬ìš©ë²•

### ë°ëª¨ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©ë²•
```python
from domains.humanoid.face_recognition.utils.demo import main, create_test_image

# ë°ëª¨ ì‹¤í–‰
main()

# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
test_image = create_test_image(width=640, height=480)
```

### ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©ë²•
```python
# ì´ë¯¸ì§€ ì „ì²˜ë¦¬
from domains.humanoid.face_recognition.utils import preprocess_image
processed_image = preprocess_image(image, target_size=(112, 112))

# ê²°ê³¼ ì‹œê°í™”
from domains.humanoid.face_recognition.utils import visualize_results
annotated_image = visualize_results(image, detection_results)

# ë°ì´í„° ë³€í™˜
from domains.humanoid.face_recognition.utils import convert_bbox_format
normalized_bbox = convert_bbox_format(bbox, from_format='xyxy', to_format='xywh')
```

## ğŸ”§ ìœ í‹¸ë¦¬í‹° ê¸°ëŠ¥

### ì´ë¯¸ì§€ ì²˜ë¦¬ ê¸°ëŠ¥
- **í¬ê¸° ì¡°ì •**: ë‹¤ì–‘í•œ í¬ê¸°ë¡œ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§•
- **ì •ê·œí™”**: í”½ì…€ê°’ ì •ê·œí™” (0-255 â†’ 0-1)
- **ìƒ‰ìƒ ë³€í™˜**: BGR â†” RGB ë³€í™˜
- **íšŒì „/ë°˜ì „**: ì´ë¯¸ì§€ ê¸°í•˜í•™ì  ë³€í™˜

### ì‹œê°í™” ê¸°ëŠ¥
- **ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°**: ì–¼êµ´ ê²€ì¶œ ê²°ê³¼ ì‹œê°í™”
- **ëœë“œë§ˆí¬ í‘œì‹œ**: ì–¼êµ´ íŠ¹ì§•ì  í‘œì‹œ
- **ì‹ ë¢°ë„ í‘œì‹œ**: ê²€ì¶œ/ì¸ì‹ ì‹ ë¢°ë„ ì ìˆ˜ í‘œì‹œ
- **ì‹ ì› ì •ë³´ í‘œì‹œ**: ì¸ì‹ëœ ì‚¬ëŒ ì •ë³´ í‘œì‹œ

### ë°ì´í„° ë³€í™˜ ê¸°ëŠ¥
- **ì¢Œí‘œ ë³€í™˜**: ë‹¤ì–‘í•œ ë°”ìš´ë”© ë°•ìŠ¤ í˜•ì‹ ë³€í™˜
- **ì„ë² ë”© ë³€í™˜**: íŠ¹ì§• ë²¡í„° í˜•ì‹ ë³€í™˜
- **ë©”íƒ€ë°ì´í„° ë³€í™˜**: JSON â†” ë”•ì…”ë„ˆë¦¬ ë³€í™˜

### ì„±ëŠ¥ ì¸¡ì • ê¸°ëŠ¥
- **ì‹œê°„ ì¸¡ì •**: í•¨ìˆ˜ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
- **ë©”ëª¨ë¦¬ ì¸¡ì •**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
- **FPS ê³„ì‚°**: í”„ë ˆì„ ì²˜ë¦¬ ì†ë„ ê³„ì‚°
- **ì •í™•ë„ ê³„ì‚°**: ê²€ì¶œ/ì¸ì‹ ì •í™•ë„ ê³„ì‚°

## ğŸ“Š ìœ í‹¸ë¦¬í‹° ì˜ˆì‹œ

### ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì˜ˆì‹œ
```python
def preprocess_image(image, target_size=(112, 112)):
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜"""
    # í¬ê¸° ì¡°ì •
    resized = cv2.resize(image, target_size)
    
    # ìƒ‰ìƒ ë³€í™˜ (BGR â†’ RGB)
    rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
    
    # ì •ê·œí™”
    normalized = rgb.astype(np.float32) / 255.0
    
    return normalized
```

### ê²°ê³¼ ì‹œê°í™” ì˜ˆì‹œ
```python
def visualize_results(image, results):
    """ê²€ì¶œ ê²°ê³¼ ì‹œê°í™”"""
    annotated_image = image.copy()
    
    for result in results:
        bbox = result['bbox']
        confidence = result['confidence']
        identity = result.get('identity', 'Unknown')
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        cv2.rectangle(annotated_image, 
                     (bbox[0], bbox[1]), 
                     (bbox[2], bbox[3]), 
                     (0, 255, 0), 2)
        
        # ë¼ë²¨ ê·¸ë¦¬ê¸°
        label = f"{identity}: {confidence:.2f}"
        cv2.putText(annotated_image, label, 
                   (bbox[0], bbox[1] - 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    
    return annotated_image
```

### ì„±ëŠ¥ ì¸¡ì • ì˜ˆì‹œ
```python
import time
import psutil

def measure_performance(func):
    """í•¨ìˆ˜ ì„±ëŠ¥ ì¸¡ì • ë°ì½”ë ˆì´í„°"""
    def wrapper(*args, **kwargs):
        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss
        
        result = func(*args, **kwargs)
        
        end_time = time.time()
        end_memory = psutil.Process().memory_info().rss
        
        execution_time = end_time - start_time
        memory_used = end_memory - start_memory
        
        print(f"ì‹¤í–‰ ì‹œê°„: {execution_time*1000:.2f}ms")
        print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©: {memory_used/1024/1024:.2f}MB")
        
        return result
    return wrapper
```

## ğŸ”— ì˜ì¡´ì„±

### ë‚´ë¶€ ì˜ì¡´ì„±
- `../models/`: ì–¼êµ´ì¸ì‹ ëª¨ë¸ë“¤
- `../services/`: ì–¼êµ´ì¸ì‹ ì„œë¹„ìŠ¤ë“¤
- `common/`: ê³µí†µ ìœ í‹¸ë¦¬í‹°
- `shared/vision_core/`: ë¹„ì „ ì•Œê³ ë¦¬ì¦˜ ê³µí†µ ê¸°ëŠ¥

### ì™¸ë¶€ ì˜ì¡´ì„±
```python
# requirements.txt
opencv-python>=4.5.0
numpy>=1.21.0
matplotlib>=3.5.0
pillow>=8.3.0
psutil>=5.8.0
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

### ìœ í‹¸ë¦¬í‹° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
# ì „ì²´ ìœ í‹¸ë¦¬í‹° í…ŒìŠ¤íŠ¸
python -m pytest tests/test_utils.py -v

# íŠ¹ì • ìœ í‹¸ë¦¬í‹° í…ŒìŠ¤íŠ¸
python -m pytest tests/test_utils.py::TestImageProcessing -v
python -m pytest tests/test_utils.py::TestVisualization -v
```

### í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ
```python
def test_image_preprocessing():
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
    test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
    
    # ì „ì²˜ë¦¬ ìˆ˜í–‰
    processed = preprocess_image(test_image, target_size=(112, 112))
    
    # ê²°ê³¼ ê²€ì¦
    assert processed.shape == (112, 112, 3)
    assert processed.dtype == np.float32
    assert processed.max() <= 1.0
    assert processed.min() >= 0.0
```

## ğŸ“ íŒŒì¼ ê´€ë¦¬

### ìœ í‹¸ë¦¬í‹° íŒŒì¼ ë„¤ì´ë° ê·œì¹™
- **íŒ¨í„´**: `{function}_{category}.py`
- **ì˜ˆì‹œ**: `image_processing.py`, `visualization.py`, `data_conversion.py`

### ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë„¤ì´ë° ê·œì¹™
- **íŒ¨í„´**: `{action}_{object}_{detail}`
- **ì˜ˆì‹œ**: `preprocess_image`, `visualize_detection_results`, `convert_bbox_format`

## ğŸ”§ ê°œë°œ ê°€ì´ë“œ

### ìƒˆë¡œìš´ ìœ í‹¸ë¦¬í‹° ì¶”ê°€
1. **ìœ í‹¸ë¦¬í‹° íŒŒì¼ ìƒì„±**: `new_utility.py` íŒŒì¼ ìƒì„±
2. **í•¨ìˆ˜ êµ¬í˜„**: í•„ìš”í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ êµ¬í˜„
3. **íƒ€ì… íŒíŠ¸**: ëª¨ë“  í•¨ìˆ˜ì— íƒ€ì… íŒíŠ¸ ì¶”ê°€
4. **ë¬¸ì„œí™”**: í•¨ìˆ˜ë³„ docstring ì‘ì„±
5. **í…ŒìŠ¤íŠ¸ ì‘ì„±**: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

### ìœ í‹¸ë¦¬í‹° í™•ì¥
```python
# ìƒˆë¡œìš´ ì´ë¯¸ì§€ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°
def enhance_image_quality(image):
    """ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ"""
    # ë…¸ì´ì¦ˆ ì œê±°
    denoised = cv2.fastNlMeansDenoisingColored(image)
    
    # ëŒ€ë¹„ í–¥ìƒ
    lab = cv2.cvtColor(denoised, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
    cl = clahe.apply(l)
    enhanced = cv2.merge((cl,a,b))
    enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
    
    return enhanced
```

## ğŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

#### 1. ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨
```python
# í•´ê²° ë°©ë²•
def safe_load_image(image_path):
    """ì•ˆì „í•œ ì´ë¯¸ì§€ ë¡œë”©"""
    try:
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return image
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ë¡œë”© ì˜¤ë¥˜: {e}")
        return None
```

#### 2. ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# í•´ê²° ë°©ë²•
def optimize_memory_usage(image):
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”"""
    # ì´ë¯¸ì§€ í¬ê¸° ì¤„ì´ê¸°
    if image.shape[0] > 1080 or image.shape[1] > 1920:
        scale = min(1080/image.shape[0], 1920/image.shape[1])
        new_size = (int(image.shape[1]*scale), int(image.shape[0]*scale))
        image = cv2.resize(image, new_size)
    
    # ë°ì´í„° íƒ€ì… ìµœì í™”
    if image.dtype == np.float64:
        image = image.astype(np.float32)
    
    return image
```

#### 3. ì‹œê°í™” ì„±ëŠ¥ ì €í•˜
```python
# í•´ê²° ë°©ë²•
def optimize_visualization(image, results, max_display=10):
    """ì‹œê°í™” ì„±ëŠ¥ ìµœì í™”"""
    # í‘œì‹œí•  ê²°ê³¼ ìˆ˜ ì œí•œ
    if len(results) > max_display:
        results = sorted(results, key=lambda x: x['confidence'], reverse=True)[:max_display]
    
    # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
    if image.shape[0] > 720:
        scale = 720 / image.shape[0]
        new_size = (int(image.shape[1]*scale), int(image.shape[0]*scale))
        image = cv2.resize(image, new_size)
    
    return visualize_results(image, results)
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### ì„±ëŠ¥ ìµœì í™” ê¸°ë²•
- **ë°°ì¹˜ ì²˜ë¦¬**: ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
- **ë©”ëª¨ë¦¬ í’€ë§**: ë©”ëª¨ë¦¬ ì¬ì‚¬ìš©ìœ¼ë¡œ í• ë‹¹ ì˜¤ë²„í—¤ë“œ ê°ì†Œ
- **ìºì‹±**: ìì£¼ ì‚¬ìš©ë˜ëŠ” ê²°ê³¼ ìºì‹±
- **ë³‘ë ¬ ì²˜ë¦¬**: ë©€í‹°ìŠ¤ë ˆë”©/ë©€í‹°í”„ë¡œì„¸ì‹± í™œìš©

### ìµœì í™” ì˜ˆì‹œ
```python
from functools import lru_cache
import multiprocessing as mp

@lru_cache(maxsize=128)
def cached_image_processing(image_hash):
    """ìºì‹œëœ ì´ë¯¸ì§€ ì²˜ë¦¬"""
    # ì´ë¯¸ì§€ ì²˜ë¦¬ ë¡œì§
    pass

def parallel_image_processing(images):
    """ë³‘ë ¬ ì´ë¯¸ì§€ ì²˜ë¦¬"""
    with mp.Pool() as pool:
        results = pool.map(process_single_image, images)
    return results
```

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- [ì–¼êµ´ì¸ì‹ ê¸°ëŠ¥ ë¬¸ì„œ](../README.md)
- [ëª¨ë¸ ë¬¸ì„œ](../models/README.md)
- [ì„œë¹„ìŠ¤ ë¬¸ì„œ](../services/README.md)
- [Humanoid ë„ë©”ì¸ ë¬¸ì„œ](../../README.md)
- [í”„ë¡œì íŠ¸ ì „ì²´ ë¬¸ì„œ](../../../../README.md)

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ ë°œìƒí•˜ê±°ë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´:
1. ì´ README íŒŒì¼ í™•ì¸
2. ìƒìœ„ í´ë”ì˜ README.md í™•ì¸
3. í…ŒìŠ¤íŠ¸ ì½”ë“œ ì°¸ì¡°
4. ê°œë°œíŒ€ì— ë¬¸ì˜

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-07-04
**ë²„ì „**: 1.0.0
**ì‘ì„±ì**: Vision System Team 