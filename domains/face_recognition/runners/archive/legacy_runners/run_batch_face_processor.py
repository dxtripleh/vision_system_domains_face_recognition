#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ë°°ì¹˜ ì–¼êµ´ ì²˜ë¦¬ ì‹œìŠ¤í…œ (ì—…ë¡œë“œ íŒŒì¼ìš©)

ğŸ“‹ ì—…ë¡œë“œ ë°ì´í„° íë¦„ (ì‚¬ìš©ì ì œì•ˆ):
   ì‚¬ì§„/ë™ì˜ìƒ ì—…ë¡œë“œ â†’ data/domains/face_recognition/raw_input/uploads â†’ ì–¼êµ´ ê²€ì¶œ â†’ ì‚¬ìš©ì ì„ íƒ/ì´ë¦„ì§€ì • â†’ data/domains/face_recognition/staging
                                                                                    â†“
                                                                            ğŸ¯ ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ë™ì¼:
                                                                            1ï¸âƒ£ ì¦‰ì‹œ ë“±ë¡ (ì„ë² ë”© â†’ storage)
                                                                            2ï¸âƒ£ í›ˆë ¨ìš© ìˆ˜ì§‘ (í’ˆì§ˆí‰ê°€ â†’ datasets)
"""

import cv2
import numpy as np
import time
import sys
import os
import uuid
import json
import shutil
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional, Tuple
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent.parent.parent
sys.path.append(str(project_root))

from domains.face_recognition.core.services.face_detection_service import FaceDetectionService
from domains.face_recognition.core.services.face_recognition_service import FaceRecognitionService
from shared.vision_core.quality.face_quality_assessor import CustomFaceQualityAssessor
from common.logging import setup_logging

logger = logging.getLogger(__name__)

class BatchFaceProcessor:
    """ë°°ì¹˜ ì–¼êµ´ ì²˜ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.detection_service = FaceDetectionService()
        self.recognition_service = FaceRecognitionService()
        self.quality_assessor = CustomFaceQualityAssessor()
        
        # ğŸ¯ ìƒˆë¡œìš´ ê²½ë¡œ êµ¬ì¡° ì ìš©
        self.upload_dir = Path("data/domains/face_recognition/raw_input/uploads")
        self.upload_dir.mkdir(parents=True, exist_ok=True)
        
        # ğŸ¯ face_staging í´ë” (ê³µí†µ í—ˆë¸Œ) - ìƒˆë¡œìš´ ê²½ë¡œ
        self.face_staging_dir = Path("data/domains/face_recognition/staging")
        self.face_staging_dir.mkdir(parents=True, exist_ok=True)
        
        # ì§€ì› íŒŒì¼ í˜•ì‹
        self.image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
        self.video_extensions = {'.mp4', '.avi', '.mov', '.mkv', '.wmv'}
        
    def run_interactive_mode(self):
        """ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰"""
        print("ğŸ“ ë°°ì¹˜ ì–¼êµ´ ì²˜ë¦¬ ì‹œìŠ¤í…œ")
        print("=" * 50)
        print("ğŸ“‹ ì§€ì› ê¸°ëŠ¥:")
        print("  1. ì´ë¯¸ì§€ íŒŒì¼ì—ì„œ ì–¼êµ´ ê²€ì¶œ")
        print("  2. ë™ì˜ìƒ íŒŒì¼ì—ì„œ ì–¼êµ´ ê²€ì¶œ")
        print("  3. ì—…ë¡œë“œ í´ë” ì¼ê´„ ì²˜ë¦¬")
        print("  0. ì¢…ë£Œ")
        
        while True:
            try:
                choice = input("\nì„ íƒí•˜ì„¸ìš” (0-3): ").strip()
                
                if choice == '0':
                    break
                elif choice == '1':
                    self._process_image_files()
                elif choice == '2':
                    self._process_video_files()
                elif choice == '3':
                    self._process_upload_folder()
                else:
                    print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
                    
            except KeyboardInterrupt:
                print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
    
    def _process_image_files(self):
        """ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬"""
        print("\nğŸ“· ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬")
        
        # íŒŒì¼ ê²½ë¡œ ì…ë ¥
        file_path = input("ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        
        if not file_path:
            print("âŒ íŒŒì¼ ê²½ë¡œê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        file_path = Path(file_path)
        
        if not file_path.exists():
            print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
            return
        
        if file_path.suffix.lower() not in self.image_extensions:
            print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹: {file_path.suffix}")
            return
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        self._process_single_image(file_path)
    
    def _process_video_files(self):
        """ë™ì˜ìƒ íŒŒì¼ ì²˜ë¦¬"""
        print("\nğŸ¥ ë™ì˜ìƒ íŒŒì¼ ì²˜ë¦¬")
        
        # íŒŒì¼ ê²½ë¡œ ì…ë ¥
        file_path = input("ë™ì˜ìƒ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        
        if not file_path:
            print("âŒ íŒŒì¼ ê²½ë¡œê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        file_path = Path(file_path)
        
        if not file_path.exists():
            print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
            return
        
        if file_path.suffix.lower() not in self.video_extensions:
            print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë™ì˜ìƒ í˜•ì‹: {file_path.suffix}")
            return
        
        # ë™ì˜ìƒ ì²˜ë¦¬
        self._process_single_video(file_path)
    
    def _process_upload_folder(self):
        """ì—…ë¡œë“œ í´ë” ì¼ê´„ ì²˜ë¦¬"""
        print(f"\nğŸ“‚ ì—…ë¡œë“œ í´ë” ì¼ê´„ ì²˜ë¦¬: {self.upload_dir}")
        
        # ì—…ë¡œë“œ í´ë” ìŠ¤ìº”
        all_files = []
        
        for file_path in self.upload_dir.iterdir():
            if file_path.is_file():
                ext = file_path.suffix.lower()
                if ext in self.image_extensions or ext in self.video_extensions:
                    all_files.append(file_path)
        
        if not all_files:
            print(f"âŒ {self.upload_dir}ì— ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ğŸ“‹ ë°œê²¬ëœ íŒŒì¼: {len(all_files)}ê°œ")
        
        for i, file_path in enumerate(all_files, 1):
            print(f"\nğŸ”„ [{i}/{len(all_files)}] ì²˜ë¦¬ ì¤‘: {file_path.name}")
            
            try:
                if file_path.suffix.lower() in self.image_extensions:
                    self._process_single_image(file_path)
                else:
                    self._process_single_video(file_path)
            except Exception as e:
                logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ {file_path}: {str(e)}")
                print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    def _process_single_image(self, image_path: Path):
        """ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬"""
        print(f"\nğŸ” ì´ë¯¸ì§€ ë¶„ì„ ì¤‘: {image_path.name}")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(str(image_path))
        if image is None:
            print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
            return
        
        # ì–¼êµ´ ê²€ì¶œ
        detection_result = self.detection_service.detect_faces(image)
        detected_faces = detection_result.faces
        
        if not detected_faces:
            print("âŒ ê²€ì¶œëœ ì–¼êµ´ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"âœ… {len(detected_faces)}ê°œì˜ ì–¼êµ´ì´ ê²€ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì‚¬ìš©ìì—ê²Œ ì–¼êµ´ í‘œì‹œ
        self._show_detected_faces(image, detected_faces, image_path.stem)
        
        # ì‚¬ìš©ì ì„ íƒ ì²˜ë¦¬
        self._handle_face_selection(image, detected_faces, str(image_path))
    
    def _process_single_video(self, video_path: Path):
        """ë‹¨ì¼ ë™ì˜ìƒ ì²˜ë¦¬"""
        print(f"\nğŸ¥ ë™ì˜ìƒ ë¶„ì„ ì¤‘: {video_path.name}")
        
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            print(f"âŒ ë™ì˜ìƒ ë¡œë“œ ì‹¤íŒ¨: {video_path}")
            return
        
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        print(f"ğŸ“Š ë™ì˜ìƒ ì •ë³´: {total_frames}í”„ë ˆì„, {fps:.1f}FPS")
        
        # í”„ë ˆì„ ìƒ˜í”Œë§ (ë§¤ 30í”„ë ˆì„ë§ˆë‹¤)
        frame_skip = 30
        all_detected_faces = []
        processed_frames = 0
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_number = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
            
            if frame_number % frame_skip == 0:
                # ì–¼êµ´ ê²€ì¶œ
                detection_result = self.detection_service.detect_faces(frame)
                detected_faces = detection_result.faces
                
                if detected_faces:
                    for face in detected_faces:
                        face_info = {
                            'frame': frame.copy(),
                            'face': face,
                            'frame_number': frame_number,
                            'timestamp': frame_number / fps
                        }
                        all_detected_faces.append(face_info)
                
                processed_frames += 1
                
                if processed_frames % 10 == 0:
                    progress = frame_number / total_frames * 100
                    print(f"   ì§„í–‰ë¥ : {progress:.1f}% - ê²€ì¶œëœ ì–¼êµ´: {len(all_detected_faces)}ê°œ")
        
        cap.release()
        
        if not all_detected_faces:
            print("âŒ ë™ì˜ìƒì—ì„œ ì–¼êµ´ì´ ê²€ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        print(f"âœ… ì´ {len(all_detected_faces)}ê°œì˜ ì–¼êµ´ì´ ê²€ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # í’ˆì§ˆ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ ë° ìƒ˜í”Œë§
        self._process_video_faces(all_detected_faces, video_path.stem)
    
    def _show_detected_faces(self, image: np.ndarray, faces: List, source_name: str):
        """ê²€ì¶œëœ ì–¼êµ´ë“¤ì„ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œ"""
        display_image = image.copy()
        
        # ëª¨ë“  ì–¼êµ´ì— ë°”ìš´ë”© ë°•ìŠ¤ì™€ ë²ˆí˜¸ í‘œì‹œ
        for i, face in enumerate(faces):
            x, y, w, h = face.bbox.to_list()
            
            # ë°”ìš´ë”© ë°•ìŠ¤
            cv2.rectangle(display_image, (x, y), (x + w, y + h), (0, 255, 0), 2)
            
            # ë²ˆí˜¸ í‘œì‹œ
            cv2.putText(display_image, str(i + 1), (x + 10, y + 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
            
            # ì‹ ë¢°ë„ í‘œì‹œ
            cv2.putText(display_image, f"{face.confidence.value:.2f}", (x + 10, y + h - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        # ìœˆë„ìš° í¬ê¸° ì¡°ì •
        height, width = display_image.shape[:2]
        if height > 800 or width > 1200:
            scale = min(800/height, 1200/width)
            new_width = int(width * scale)
            new_height = int(height * scale)
            display_image = cv2.resize(display_image, (new_width, new_height))
        
        cv2.imshow(f'ê²€ì¶œëœ ì–¼êµ´ - {source_name}', display_image)
        print("ğŸ–¼ï¸ ì–¼êµ´ í™•ì¸ì°½ì´ ì—´ë ¸ìŠµë‹ˆë‹¤. ì•„ë¬´ í‚¤ë‚˜ ëˆŒëŸ¬ ê³„ì†...")
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    
    def _handle_face_selection(self, image: np.ndarray, faces: List, source_path: str):
        """ì–¼êµ´ ì„ íƒ ë° ì´ë¦„ ì§€ì • ì²˜ë¦¬"""
        print("\nğŸ‘¤ ì–¼êµ´ ì„ íƒ ë° ì´ë¦„ ì§€ì •")
        print("=" * 30)
        
        for i, face in enumerate(faces):
            print(f"{i + 1}. ì–¼êµ´ #{i + 1} (ì‹ ë¢°ë„: {face.confidence.value:.3f})")
        
        # ì²˜ë¦¬í•  ì–¼êµ´ ì„ íƒ
        while True:
            try:
                selections = input(f"\nì²˜ë¦¬í•  ì–¼êµ´ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-{len(faces)}, ì—¬ëŸ¬ ê°œëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„, ì „ì²´: all): ").strip()
                
                if selections.lower() == 'all':
                    selected_indices = list(range(len(faces)))
                    break
                elif selections:
                    selected_indices = [int(x.strip()) - 1 for x in selections.split(',')]
                    if all(0 <= idx < len(faces) for idx in selected_indices):
                        break
                    else:
                        print(f"âŒ ì˜ëª»ëœ ë²ˆí˜¸ì…ë‹ˆë‹¤. 1-{len(faces)} ë²”ìœ„ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
                else:
                    print("âŒ ì„ íƒì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            except ValueError:
                print("âŒ ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        
        # ì„ íƒëœ ì–¼êµ´ë“¤ ì²˜ë¦¬
        for idx in selected_indices:
            face = faces[idx]
            print(f"\nğŸ“· ì–¼êµ´ #{idx + 1} ì²˜ë¦¬ ì¤‘...")
            
            # ì¸ë¬¼ ì´ë¦„ ì…ë ¥
            person_name = input(f"ì´ ì–¼êµ´ì˜ ì¸ë¬¼ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            
            if not person_name:
                print("âŒ ì´ë¦„ì´ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
            
            # ğŸ¯ í•µì‹¬: temp/face_stagingë¡œ ì´ë™ (ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ë™ì¼)
            self._move_to_face_staging(image, face, person_name, source_path, idx)
    
    def _move_to_face_staging(self, image: np.ndarray, face, person_name: str, source_path: str, face_index: int):
        """ğŸ¯ ê³µí†µ í—ˆë¸Œë¡œ ì´ë™: temp/face_staging (ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ë™ì¼)"""
        timestamp = int(time.time())
        
        # ì „ì²´ ì´ë¯¸ì§€ ì €ì¥
        frame_filename = f"{person_name}_{timestamp}_frame_{face_index}.jpg"
        frame_path = self.face_staging_dir / frame_filename
        cv2.imwrite(str(frame_path), image)
        
        # ì–¼êµ´ í¬ë¡­ ì €ì¥
        x, y, w, h = face.bbox.to_list()
        face_crop = image[y:y+h, x:x+w]
        face_filename = f"{person_name}_{timestamp}_face_{face_index}.jpg"
        face_path = self.face_staging_dir / face_filename
        cv2.imwrite(str(face_path), face_crop)
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'person_name': person_name,
            'timestamp': timestamp,
            'face_index': face_index,
            'bbox': face.bbox.to_list(),
            'confidence': face.confidence.value,
            'source_path': source_path,
            'source_type': 'batch_upload',
            'frame_path': str(frame_path),
            'face_path': str(face_path),
            'created_at': datetime.now().isoformat()
        }
        
        metadata_filename = f"{person_name}_{timestamp}_meta_{face_index}.json"
        metadata_path = self.face_staging_dir / metadata_filename
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ê³µí†µ í—ˆë¸Œë¡œ ì´ë™ ì™„ë£Œ: {face_filename}")
        print(f"   ğŸ“‚ ì €ì¥ ìœ„ì¹˜: {self.face_staging_dir}")
        print(f"   ğŸ‘¤ ì¸ë¬¼ ì´ë¦„: {person_name}")
        print("   ğŸ¯ ì´ì œ ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ë™ì¼í•œ ë¶„ê¸° ì²˜ë¦¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤!")
        
        return face_path
    
    def _process_video_faces(self, face_infos: List[Dict], video_name: str):
        """ë™ì˜ìƒì—ì„œ ê²€ì¶œëœ ì–¼êµ´ë“¤ ì²˜ë¦¬"""
        print(f"\nğŸ¥ ë™ì˜ìƒ '{video_name}'ì—ì„œ ê²€ì¶œëœ ì–¼êµ´ ì²˜ë¦¬")
        
        # í’ˆì§ˆ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        face_infos.sort(key=lambda x: x['face'].confidence.value, reverse=True)
        
        # ìƒìœ„ ì–¼êµ´ë“¤ë§Œ í‘œì‹œ (ìµœëŒ€ 20ê°œ)
        display_count = min(20, len(face_infos))
        
        print(f"ğŸ“‹ ìƒìœ„ {display_count}ê°œ ì–¼êµ´ (í’ˆì§ˆ ìˆœ):")
        for i in range(display_count):
            face_info = face_infos[i]
            print(f"  {i+1}. í”„ë ˆì„ {face_info['frame_number']} "
                  f"({face_info['timestamp']:.1f}ì´ˆ) - "
                  f"ì‹ ë¢°ë„: {face_info['face'].confidence.value:.3f}")
        
        # ëŒ€í‘œ ì–¼êµ´ë“¤ ì‹œê°ì  í‘œì‹œ
        self._show_video_sample_faces(face_infos[:display_count], video_name)
        
        # ì‚¬ìš©ì ì„ íƒ ì²˜ë¦¬
        while True:
            try:
                selections = input(f"\nì²˜ë¦¬í•  ì–¼êµ´ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-{display_count}, ì—¬ëŸ¬ ê°œëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„): ").strip()
                
                if not selections:
                    print("âŒ ì„ íƒì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    continue
                
                selected_indices = [int(x.strip()) - 1 for x in selections.split(',')]
                if all(0 <= idx < display_count for idx in selected_indices):
                    break
                else:
                    print(f"âŒ ì˜ëª»ëœ ë²ˆí˜¸ì…ë‹ˆë‹¤. 1-{display_count} ë²”ìœ„ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            except ValueError:
                print("âŒ ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        
        # ì¸ë¬¼ ì´ë¦„ ì…ë ¥
        person_name = input(f"ì„ íƒëœ ì–¼êµ´ë“¤ì˜ ì¸ë¬¼ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        
        if not person_name:
            print("âŒ ì´ë¦„ì´ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # ì„ íƒëœ ì–¼êµ´ë“¤ì„ ê³µí†µ í—ˆë¸Œë¡œ ì´ë™
        for idx in selected_indices:
            face_info = face_infos[idx]
            self._move_to_face_staging(
                face_info['frame'], 
                face_info['face'], 
                person_name, 
                f"video_frame_{face_info['frame_number']}", 
                idx
            )
    
    def _show_video_sample_faces(self, face_infos: List[Dict], video_name: str):
        """ë™ì˜ìƒ ìƒ˜í”Œ ì–¼êµ´ë“¤ í‘œì‹œ"""
        if not face_infos:
            return
        
        # ê·¸ë¦¬ë“œë¡œ í‘œì‹œí•  ìˆ˜ ìˆëŠ” ë§Œí¼ë§Œ
        display_count = min(12, len(face_infos))
        
        # ê° ì–¼êµ´ì„ 150x150ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        face_images = []
        for i in range(display_count):
            face_info = face_infos[i]
            face = face_info['face']
            frame = face_info['frame']
            
            x, y, w, h = face.bbox.to_list()
            face_crop = frame[y:y+h, x:x+w]
            
            if face_crop.size > 0:
                face_resized = cv2.resize(face_crop, (150, 150))
                
                # ì •ë³´ ì˜¤ë²„ë ˆì´
                cv2.putText(face_resized, f"#{i+1}", (5, 20), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                cv2.putText(face_resized, f"F{face_info['frame_number']}", (5, 40), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
                cv2.putText(face_resized, f"{face.confidence.value:.2f}", (5, 145), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
                
                face_images.append(face_resized)
        
        if face_images:
            # ê·¸ë¦¬ë“œë¡œ ë°°ì¹˜ (4x3)
            cols = 4
            rows = (len(face_images) + cols - 1) // cols
            
            grid_width = cols * 150
            grid_height = rows * 150
            grid_image = np.zeros((grid_height, grid_width, 3), dtype=np.uint8)
            
            for i, face_img in enumerate(face_images):
                row = i // cols
                col = i % cols
                y_start = row * 150
                x_start = col * 150
                grid_image[y_start:y_start+150, x_start:x_start+150] = face_img
            
            cv2.imshow(f'ë™ì˜ìƒ ì–¼êµ´ ìƒ˜í”Œ - {video_name}', grid_image)
            print("ğŸ–¼ï¸ ë™ì˜ìƒ ì–¼êµ´ ìƒ˜í”Œì°½ì´ ì—´ë ¸ìŠµë‹ˆë‹¤. ì•„ë¬´ í‚¤ë‚˜ ëˆŒëŸ¬ ê³„ì†...")
            cv2.waitKey(0)
            cv2.destroyAllWindows()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ë¡œê¹… ì„¤ì •
    setup_logging()
    
    print("ğŸ¯ ë°°ì¹˜ ì–¼êµ´ ì²˜ë¦¬ ì‹œìŠ¤í…œ")
    print("ì‚¬ì§„/ë™ì˜ìƒ ì—…ë¡œë“œ â†’ ì–¼êµ´ ê²€ì¶œ â†’ ê³µí†µ ì²˜ë¦¬ (temp/face_staging)")
    print("=" * 60)
    
    try:
        processor = BatchFaceProcessor()
        processor.run_interactive_mode()
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    main() 