#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ğŸ§  ìŠ¤ë§ˆíŠ¸ ë°°ì¹˜ ì²˜ë¦¬ê¸° (ìë™ ê·¸ë£¹í•‘)

data/temp/uploads/ â†’ ëª¨ë“  ì–¼êµ´ ê²€ì¶œ â†’ ìë™ ê·¸ë£¹í•‘ â†’ ê·¸ë£¹ë³„ ì´ë¦„ ì§€ì • â†’ face_staging

ì˜ˆì‹œ:
uploads/ì— 10ê°œ íŒŒì¼ â†’ ì´ 25ê°œ ì–¼êµ´ ê²€ì¶œ 
â†’ 3ê°œ ê·¸ë£¹ìœ¼ë¡œ ìë™ ë¶„ë¥˜:
   ê·¸ë£¹1: í™ê¸¸ë™ (8ê°œ ì–¼êµ´)
   ê·¸ë£¹2: ê¹€ì² ìˆ˜ (12ê°œ ì–¼êµ´)  
   ê·¸ë£¹3: ì´ì˜í¬ (5ê°œ ì–¼êµ´)
â†’ 3ë²ˆë§Œ ì´ë¦„ ì…ë ¥í•˜ë©´ ë!
"""

import os
import sys
import cv2
import json
import time
import logging
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Tuple
from collections import defaultdict

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent.parent.parent
sys.path.append(str(project_root))

from common.logging import setup_logging
from domains.face_recognition.infrastructure.detection_engines.retinaface_detection_engine import RetinaFaceDetectionEngine
from domains.face_recognition.infrastructure.models.arcface_recognizer import ArcFaceRecognizer

# sklearn import ì‹œë„
try:
    from sklearn.cluster import DBSCAN
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    print("âš ï¸ sklearnì´ ì—†ì–´ì„œ ê°„ë‹¨í•œ ê±°ë¦¬ ê¸°ë°˜ ê·¸ë£¹í•‘ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

logger = logging.getLogger(__name__)


class SmartBatchProcessor:
    """ğŸ§  ìŠ¤ë§ˆíŠ¸ ë°°ì¹˜ ì²˜ë¦¬ê¸° - ìë™ ê·¸ë£¹í•‘ ì§€ì›"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        # ğŸ¯ í´ë” ì„¤ì •
        self.upload_dir = Path("data/temp/uploads")
        self.face_staging_dir = Path("data/temp/face_staging")
        
        # í´ë” ìƒì„±
        self.upload_dir.mkdir(parents=True, exist_ok=True)
        self.face_staging_dir.mkdir(parents=True, exist_ok=True)
        
        # AI ëª¨ë¸ ì´ˆê¸°í™”
        print("ğŸ¤– AI ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.face_detector = RetinaFaceDetectionEngine()
        self.face_recognizer = ArcFaceRecognizer()
        
        # ì²˜ë¦¬ ê²°ê³¼ ì €ì¥
        self.all_faces = []  # ëª¨ë“  ê²€ì¶œëœ ì–¼êµ´ ì •ë³´
        self.face_groups = []  # ê·¸ë£¹í•‘ ê²°ê³¼
        
        print("âœ… ìŠ¤ë§ˆíŠ¸ ë°°ì¹˜ ì²˜ë¦¬ê¸° ì¤€ë¹„ ì™„ë£Œ!")
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰"""
        print("\n" + "="*60)
        print("ğŸ§  ìŠ¤ë§ˆíŠ¸ ë°°ì¹˜ ì²˜ë¦¬ê¸° (ìë™ ê·¸ë£¹í•‘)")
        print("="*60)
        print("ğŸ“‚ ì—…ë¡œë“œ í´ë”:", self.upload_dir)
        print("ğŸ¯ ê²°ê³¼ ì €ì¥ì†Œ:", self.face_staging_dir)
        print()
        
        # 1ë‹¨ê³„: ì—…ë¡œë“œ íŒŒì¼ ìŠ¤ìº”
        files = self._scan_upload_files()
        if not files:
            print("âŒ ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            print(f"   ğŸ“ {self.upload_dir} í´ë”ì— ì´ë¯¸ì§€ë‚˜ ë™ì˜ìƒì„ ë„£ì–´ì£¼ì„¸ìš”.")
            return
        
        print(f"ğŸ“‹ ë°œê²¬ëœ íŒŒì¼: {len(files)}ê°œ")
        for i, file_path in enumerate(files, 1):
            print(f"  {i}. {file_path.name}")
        
        # ì‚¬ìš©ì í™•ì¸
        if not self._confirm_processing(files):
            print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return
        
        try:
            # 2ë‹¨ê³„: ëª¨ë“  íŒŒì¼ì—ì„œ ì–¼êµ´ ê²€ì¶œ
            print("\nğŸ” 1ë‹¨ê³„: ëª¨ë“  íŒŒì¼ì—ì„œ ì–¼êµ´ ê²€ì¶œ ì¤‘...")
            self._detect_all_faces(files)
            
            if not self.all_faces:
                print("âŒ ê²€ì¶œëœ ì–¼êµ´ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            print(f"âœ… ì´ {len(self.all_faces)}ê°œ ì–¼êµ´ ê²€ì¶œ ì™„ë£Œ!")
            
            # 3ë‹¨ê³„: ì„ë² ë”© ìƒì„± ë° ìë™ ê·¸ë£¹í•‘
            print("\nğŸ§  2ë‹¨ê³„: AI ê¸°ë°˜ ìë™ ê·¸ë£¹í•‘ ì¤‘...")
            self._auto_group_faces()
            
            print(f"âœ… {len(self.face_groups)}ê°œ ê·¸ë£¹ìœ¼ë¡œ ìë™ ë¶„ë¥˜ ì™„ë£Œ!")
            
            # 4ë‹¨ê³„: ê·¸ë£¹ í™•ì¸ ë° ì´ë¦„ ì§€ì •
            print("\nğŸ‘¥ 3ë‹¨ê³„: ê·¸ë£¹ë³„ ì´ë¦„ ì§€ì •...")
            if not self._assign_group_names():
                return
            
            # 5ë‹¨ê³„: face_stagingìœ¼ë¡œ ì´ë™
            print("\nğŸ“‚ 4ë‹¨ê³„: ê³µí†µ í—ˆë¸Œë¡œ ì´ë™...")
            self._move_to_face_staging()
            
            print("\nğŸ‰ ìŠ¤ë§ˆíŠ¸ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")
            print(f"   ğŸ“‚ ê²°ê³¼: {self.face_staging_dir}")
            print("   ğŸ¯ ì´ì œ ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ë™ì¼í•œ ë¶„ê¸° ì²˜ë¦¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤!")
            
        except Exception as e:
            logger.error(f"ìŠ¤ë§ˆíŠ¸ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    def _scan_upload_files(self) -> List[Path]:
        """ì—…ë¡œë“œ í´ë” ìŠ¤ìº”"""
        supported_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.mp4', '.avi', '.mov'}
        files = []
        
        for file_path in self.upload_dir.iterdir():
            if file_path.is_file() and file_path.suffix.lower() in supported_extensions:
                files.append(file_path)
        
        return sorted(files)
    
    def _confirm_processing(self, files: List[Path]) -> bool:
        """ì²˜ë¦¬ í™•ì¸"""
        print(f"\nğŸ“‹ {len(files)}ê°œ íŒŒì¼ì„ ìŠ¤ë§ˆíŠ¸ ë°°ì¹˜ ì²˜ë¦¬í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
        print("   ğŸ§  AIê°€ ìë™ìœ¼ë¡œ ê°™ì€ ì‚¬ëŒë¼ë¦¬ ê·¸ë£¹í•‘í•©ë‹ˆë‹¤")
        print("   ğŸ·ï¸ ê·¸ë£¹ë³„ë¡œ í•œ ë²ˆë§Œ ì´ë¦„ì„ ì…ë ¥í•˜ë©´ ë©ë‹ˆë‹¤")
        
        while True:
            choice = input("\nê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
            if choice in ['y', 'yes']:
                return True
            elif choice in ['n', 'no']:
                return False
            else:
                print("y ë˜ëŠ” nì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    def _detect_all_faces(self, files: List[Path]):
        """ëª¨ë“  íŒŒì¼ì—ì„œ ì–¼êµ´ ê²€ì¶œ"""
        total_files = len(files)
        
        for i, file_path in enumerate(files, 1):
            print(f"  [{i}/{total_files}] {file_path.name} ì²˜ë¦¬ ì¤‘...")
            
            try:
                if file_path.suffix.lower() in {'.mp4', '.avi', '.mov'}:
                    self._detect_faces_in_video(file_path)
                else:
                    self._detect_faces_in_image(file_path)
                    
            except Exception as e:
                logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ {file_path}: {str(e)}")
                print(f"    âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    def _detect_faces_in_image(self, image_path: Path):
        """ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ê²€ì¶œ"""
        image = cv2.imread(str(image_path))
        if image is None:
            print(f"    âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
            return
        
        # ì–¼êµ´ ê²€ì¶œ
        faces = self.face_detector.detect_faces(image)
        
        for j, face in enumerate(faces):
            face_info = {
                'source_path': str(image_path),
                'source_type': 'image',
                'face_index': j,
                'face_data': face,
                'image': image,
                'timestamp': time.time()
            }
            self.all_faces.append(face_info)
        
        print(f"    âœ… {len(faces)}ê°œ ì–¼êµ´ ê²€ì¶œ")
    
    def _detect_faces_in_video(self, video_path: Path):
        """ë™ì˜ìƒì—ì„œ ì–¼êµ´ ê²€ì¶œ (ìƒ˜í”Œë§)"""
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            print(f"    âŒ ë™ì˜ìƒ ë¡œë“œ ì‹¤íŒ¨: {video_path}")
            return
        
        # ë™ì˜ìƒ ì •ë³´
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        # 5ì´ˆë§ˆë‹¤ ìƒ˜í”Œë§ (ë„ˆë¬´ ë§ìœ¼ë©´ ëŠë ¤ì§)
        sample_interval = max(1, int(fps * 5))
        frame_count = 0
        detected_faces = 0
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # ìƒ˜í”Œë§ ê°„ê²©ì— ë§ëŠ” í”„ë ˆì„ë§Œ ì²˜ë¦¬
            if frame_count % sample_interval == 0:
                faces = self.face_detector.detect_faces(frame)
                
                for j, face in enumerate(faces):
                    face_info = {
                        'source_path': str(video_path),
                        'source_type': 'video',
                        'face_index': f"{frame_count}_{j}",
                        'frame_number': frame_count,
                        'timestamp_video': frame_count / fps,
                        'face_data': face,
                        'image': frame.copy(),
                        'timestamp': time.time()
                    }
                    self.all_faces.append(face_info)
                    detected_faces += 1
            
            frame_count += 1
        
        cap.release()
        print(f"    âœ… {detected_faces}ê°œ ì–¼êµ´ ê²€ì¶œ (ì´ {total_frames}í”„ë ˆì„ ì¤‘ ìƒ˜í”Œë§)")
    
    def _auto_group_faces(self):
        """AI ê¸°ë°˜ ìë™ ê·¸ë£¹í•‘"""
        if len(self.all_faces) < 2:
            # ì–¼êµ´ì´ 1ê°œë©´ ê·¸ë£¹í•‘ ë¶ˆê°€
            self.face_groups = [{'faces': self.all_faces, 'representative': self.all_faces[0]}]
            return
        
        print("  ğŸ§  ì–¼êµ´ ì„ë² ë”© ìƒì„± ì¤‘...")
        embeddings = []
        valid_faces = []
        
        # ëª¨ë“  ì–¼êµ´ì˜ ì„ë² ë”© ìƒì„±
        for i, face_info in enumerate(self.all_faces):
            try:
                face_data = face_info['face_data']
                image = face_info['image']
                
                # ì–¼êµ´ í¬ë¡­
                x, y, w, h = face_data.bbox.to_list()
                face_crop = image[y:y+h, x:x+w]
                
                if face_crop.size > 0:
                    # ì„ë² ë”© ìƒì„±
                    embedding = self.face_recognizer.extract_embedding(face_crop)
                    embeddings.append(embedding)
                    valid_faces.append(face_info)
                    
            except Exception as e:
                logger.warning(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ (face {i}): {str(e)}")
        
        if len(embeddings) < 2:
            self.face_groups = [{'faces': valid_faces, 'representative': valid_faces[0]}]
            return
        
        print(f"  ğŸ“Š {len(embeddings)}ê°œ ì„ë² ë”© ìƒì„± ì™„ë£Œ")
        print("  ğŸ”— ìœ ì‚¬ë„ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§ ì¤‘...")
        
        # ê·¸ë£¹í•‘ ìˆ˜í–‰
        if SKLEARN_AVAILABLE:
            self._group_with_sklearn(embeddings, valid_faces)
        else:
            self._group_with_simple_clustering(embeddings, valid_faces)
        
        # í¬ê¸° ìˆœìœ¼ë¡œ ì •ë ¬ (í° ê·¸ë£¹ë¶€í„°)
        self.face_groups.sort(key=lambda g: g['size'], reverse=True)
        
        print(f"  âœ… {len(self.face_groups)}ê°œ ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜ ì™„ë£Œ!")
        for i, group in enumerate(self.face_groups):
            print(f"    ê·¸ë£¹ {i+1}: {group['size']}ê°œ ì–¼êµ´")
    
    def _group_with_sklearn(self, embeddings: List, valid_faces: List):
        """sklearnì„ ì‚¬ìš©í•œ ê³ ê¸‰ í´ëŸ¬ìŠ¤í„°ë§"""
        embeddings_array = np.array(embeddings)
        
        # DBSCAN í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ê·¸ë£¹í•‘ (ê±°ë¦¬ ì„ê³„ê°’ 0.4 = 60% ìœ ì‚¬ë„)
        clustering = DBSCAN(eps=0.4, min_samples=1, metric='cosine')
        cluster_labels = clustering.fit_predict(embeddings_array)
        
        # ê·¸ë£¹ë³„ë¡œ ì–¼êµ´ë“¤ ë¶„ë¥˜
        groups_dict = defaultdict(list)
        for i, label in enumerate(cluster_labels):
            groups_dict[label].append((valid_faces[i], embeddings[i]))
        
        # ê·¸ë£¹ ì •ë³´ êµ¬ì„±
        self.face_groups = []
        for group_id, faces_with_embeddings in groups_dict.items():
            faces = [item[0] for item in faces_with_embeddings]
            
            # ëŒ€í‘œ ì–¼êµ´ ì„ íƒ (ê°€ì¥ ë†’ì€ í’ˆì§ˆ ì ìˆ˜)
            best_face = max(faces, key=lambda f: f['face_data'].confidence.value)
            
            group_info = {
                'group_id': group_id,
                'faces': faces,
                'representative': best_face,
                'size': len(faces)
            }
            self.face_groups.append(group_info)
    
    def _group_with_simple_clustering(self, embeddings: List, valid_faces: List):
        """ê°„ë‹¨í•œ ê±°ë¦¬ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§"""
        groups = []
        used_indices = set()
        threshold = 0.4  # ì½”ì‚¬ì¸ ê±°ë¦¬ ì„ê³„ê°’
        
        for i, embedding in enumerate(embeddings):
            if i in used_indices:
                continue
            
            # ìƒˆ ê·¸ë£¹ ì‹œì‘
            group_faces = [valid_faces[i]]
            used_indices.add(i)
            
            # ìœ ì‚¬í•œ ì–¼êµ´ë“¤ ì°¾ê¸°
            for j, other_embedding in enumerate(embeddings):
                if j in used_indices:
                    continue
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                cosine_sim = np.dot(embedding, other_embedding) / (
                    np.linalg.norm(embedding) * np.linalg.norm(other_embedding)
                )
                cosine_distance = 1 - cosine_sim
                
                if cosine_distance < threshold:
                    group_faces.append(valid_faces[j])
                    used_indices.add(j)
            
            # ëŒ€í‘œ ì–¼êµ´ ì„ íƒ
            best_face = max(group_faces, key=lambda f: f['face_data'].confidence.value)
            
            group_info = {
                'group_id': len(groups),
                'faces': group_faces,
                'representative': best_face,
                'size': len(group_faces)
            }
            groups.append(group_info)
        
        self.face_groups = groups
    
    def _assign_group_names(self) -> bool:
        """ê·¸ë£¹ë³„ ì´ë¦„ ì§€ì •"""
        print(f"\nğŸ‘¥ {len(self.face_groups)}ê°œ ê·¸ë£¹ì— ì´ë¦„ì„ ì§€ì •í•´ì£¼ì„¸ìš”:")
        print("   'skip' ì…ë ¥ì‹œ ê±´ë„ˆë›°ê¸°, 'quit' ì…ë ¥ì‹œ ì¤‘ë‹¨")
        
        for i, group in enumerate(self.face_groups):
            print(f"\n--- ê·¸ë£¹ {i+1}/{len(self.face_groups)} ({group['size']}ê°œ ì–¼êµ´) ---")
            
            # ëŒ€í‘œ ì–¼êµ´ í‘œì‹œ
            self._show_group_representative(group, i+1)
            
            # ì „ì²´ ê·¸ë£¹ ì–¼êµ´ë“¤ í‘œì‹œ ì—¬ë¶€ í™•ì¸
            if group['size'] > 1:
                show_all = input(f"ê·¸ë£¹ì˜ ëª¨ë“  ì–¼êµ´ì„ ë³´ì‹œê² ìŠµë‹ˆê¹Œ? (y/n, ê¸°ë³¸ê°’: n): ").strip().lower()
                if show_all in ['y', 'yes']:
                    self._show_group_faces(group, i+1)
            
            # ì´ë¦„ ì…ë ¥
            while True:
                group_name = input(f"ê·¸ë£¹ {i+1} ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
                
                if group_name.lower() == 'quit':
                    print("ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    return False
                elif group_name.lower() == 'skip':
                    print(f"ê·¸ë£¹ {i+1}ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                    group['name'] = None
                    break
                elif group_name:
                    group['name'] = group_name
                    print(f"âœ… '{group_name}' ì´ë¦„ì´ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    break
                else:
                    print("ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”. (skipìœ¼ë¡œ ê±´ë„ˆë›°ê¸° ê°€ëŠ¥)")
        
        return True
    
    def _show_group_representative(self, group: Dict, group_num: int):
        """ê·¸ë£¹ ëŒ€í‘œ ì–¼êµ´ í‘œì‹œ"""
        rep_face = group['representative']
        face_data = rep_face['face_data']
        image = rep_face['image']
        
        # ì–¼êµ´ í¬ë¡­
        x, y, w, h = face_data.bbox.to_list()
        face_crop = image[y:y+h, x:x+w]
        
        if face_crop.size > 0:
            # ë¦¬ì‚¬ì´ì¦ˆ ë° ì •ë³´ í‘œì‹œ
            display_size = (200, 200)
            face_display = cv2.resize(face_crop, display_size)
            
            # ì •ë³´ ì˜¤ë²„ë ˆì´
            cv2.putText(face_display, f"Group {group_num}", (5, 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            cv2.putText(face_display, f"{group['size']} faces", (5, 40), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            cv2.putText(face_display, f"Conf: {face_data.confidence.value:.2f}", (5, 190), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
            
            window_name = f"Group {group_num} Representative"
            cv2.imshow(window_name, face_display)
            
            print(f"ğŸ“· ê·¸ë£¹ {group_num} ëŒ€í‘œ ì–¼êµ´ì´ í‘œì‹œë©ë‹ˆë‹¤. ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ë©´ ê³„ì†...")
            cv2.waitKey(0)
            cv2.destroyWindow(window_name)
    
    def _show_group_faces(self, group: Dict, group_num: int):
        """ê·¸ë£¹ì˜ ëª¨ë“  ì–¼êµ´ í‘œì‹œ"""
        faces = group['faces']
        faces_per_row = 4
        rows = (len(faces) + faces_per_row - 1) // faces_per_row
        
        # ì–¼êµ´ ì´ë¯¸ì§€ë“¤ ì¤€ë¹„
        face_images = []
        for face_info in faces:
            face_data = face_info['face_data']
            image = face_info['image']
            
            x, y, w, h = face_data.bbox.to_list()
            face_crop = image[y:y+h, x:x+w]
            
            if face_crop.size > 0:
                face_resized = cv2.resize(face_crop, (120, 120))
                
                # ì •ë³´ í‘œì‹œ
                cv2.putText(face_resized, f"{face_data.confidence.value:.2f}", (5, 15), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
                
                face_images.append(face_resized)
        
        # ê·¸ë¦¬ë“œ ìƒì„±
        if face_images:
            grid_rows = []
            for row in range(rows):
                start_idx = row * faces_per_row
                end_idx = min(start_idx + faces_per_row, len(face_images))
                row_images = face_images[start_idx:end_idx]
                
                # ë¹ˆ ê³µê°„ ì±„ìš°ê¸°
                while len(row_images) < faces_per_row:
                    row_images.append(np.zeros((120, 120, 3), dtype=np.uint8))
                
                row_img = np.hstack(row_images)
                grid_rows.append(row_img)
            
            grid_img = np.vstack(grid_rows)
            
            window_name = f"Group {group_num} All Faces ({len(faces)} faces)"
            cv2.imshow(window_name, grid_img)
            
            print(f"ğŸ“· ê·¸ë£¹ {group_num}ì˜ ëª¨ë“  ì–¼êµ´ì´ í‘œì‹œë©ë‹ˆë‹¤. ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ë©´ ê³„ì†...")
            cv2.waitKey(0)
            cv2.destroyWindow(window_name)
    
    def _move_to_face_staging(self):
        """face_stagingìœ¼ë¡œ ì´ë™"""
        moved_count = 0
        
        for group in self.face_groups:
            group_name = group.get('name')
            if not group_name:
                print(f"âš ï¸ ì´ë¦„ì´ ì—†ëŠ” ê·¸ë£¹ {group['group_id']} (ì–¼êµ´ {group['size']}ê°œ)ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
            
            # ê·¸ë£¹ì˜ ëª¨ë“  ì–¼êµ´ì„ face_stagingìœ¼ë¡œ ì´ë™
            for face_info in group['faces']:
                self._save_face_to_staging(face_info, group_name)
                moved_count += 1
        
        print(f"âœ… ì´ {moved_count}ê°œ ì–¼êµ´ì´ face_stagingìœ¼ë¡œ ì´ë™ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _save_face_to_staging(self, face_info: Dict, person_name: str):
        """ê°œë³„ ì–¼êµ´ì„ face_stagingì— ì €ì¥"""
        timestamp = int(time.time())
        face_index = face_info['face_index']
        
        face_data = face_info['face_data']
        image = face_info['image']
        
        # ì „ì²´ ì´ë¯¸ì§€ ì €ì¥
        frame_filename = f"{person_name}_{timestamp}_frame_{face_index}.jpg"
        frame_path = self.face_staging_dir / frame_filename
        cv2.imwrite(str(frame_path), image)
        
        # ì–¼êµ´ í¬ë¡­ ì €ì¥
        x, y, w, h = face_data.bbox.to_list()
        face_crop = image[y:y+h, x:x+w]
        face_filename = f"{person_name}_{timestamp}_face_{face_index}.jpg"
        face_path = self.face_staging_dir / face_filename
        cv2.imwrite(str(face_path), face_crop)
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'person_name': person_name,
            'timestamp': timestamp,
            'face_index': face_index,
            'bbox': face_data.bbox.to_list(),
            'confidence': face_data.confidence.value,
            'source_path': face_info['source_path'],
            'source_type': face_info['source_type'],
            'processing_type': 'smart_batch',
            'frame_path': str(frame_path),
            'face_path': str(face_path),
            'created_at': datetime.now().isoformat()
        }
        
        # ë™ì˜ìƒì¸ ê²½ìš° ì¶”ê°€ ì •ë³´
        if face_info['source_type'] == 'video':
            metadata['frame_number'] = face_info.get('frame_number')
            metadata['timestamp_video'] = face_info.get('timestamp_video')
        
        metadata_filename = f"{person_name}_{timestamp}_meta_{face_index}.json"
        metadata_path = self.face_staging_dir / metadata_filename
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ë¡œê¹… ì„¤ì •
    setup_logging()
    
    try:
        processor = SmartBatchProcessor()
        processor.run()
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ìŠ¤ë§ˆíŠ¸ ë°°ì¹˜ ì²˜ë¦¬ê¸° ì˜¤ë¥˜: {str(e)}")
        print(f"\nâŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        raise


if __name__ == "__main__":
    main() 