#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ê°œì„ ëœ ì–¼êµ´ ìº¡ì²˜ ì‹œìŠ¤í…œ v2

GUI ê¸°ë°˜ ì–¼êµ´ ê´€ë¦¬ìê°€ í¬í•¨ëœ ê³ ê¸‰ ì–¼êµ´ ìº¡ì²˜ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
- ì¹´ë©”ë¼ í™”ë©´ì´ ë©ˆì¶”ì§€ ì•ŠëŠ” ì‚­ì œ/í¸ì§‘ ê¸°ëŠ¥
- ë¯¸ë¦¬ë³´ê¸° ê¸°ëŠ¥
- ì´ë¦„ ì§€ì • ë° ê·¸ë£¹ ì§€ì • ê¸°ëŠ¥
- ê°œì„ ëœ ì–¼êµ´ ì¸ì‹ ì„±ëŠ¥
"""

import os
import sys
import json
import time
import threading
import tkinter as tk
from tkinter import ttk, messagebox, filedialog
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Tuple
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent.parent.parent
sys.path.append(str(project_root))

from common.logging import setup_logging, get_logger
from common.config import load_config

class FaceManagerGUI:
    """GUI ê¸°ë°˜ ì–¼êµ´ ê´€ë¦¬ì"""
    
    def __init__(self, paths: Dict[str, Path]):
        self.paths = paths
        self.window = None
        self.selected_files = []
        
    def open_face_manager(self):
        """ì–¼êµ´ ê´€ë¦¬ ì°½ ì—´ê¸°"""
        if self.window and self.window.winfo_exists():
            self.window.lift()
            return
            
        self.window = tk.Toplevel()
        self.window.title("ì–¼êµ´ ê´€ë¦¬ì")
        self.window.geometry("1000x700")
        self.window.configure(bg='white')
        
        # ë©”ì¸ í”„ë ˆì„
        main_frame = ttk.Frame(self.window)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # ì¢Œì¸¡: í´ë” íŠ¸ë¦¬
        left_frame = ttk.Frame(main_frame)
        left_frame.pack(side=tk.LEFT, fill=tk.Y, padx=(0, 10))
        
        ttk.Label(left_frame, text="í´ë” ì„ íƒ", font=('Arial', 12, 'bold')).pack(pady=(0, 10))
        
        # í´ë” ë¦¬ìŠ¤íŠ¸ë°•ìŠ¤
        self.folder_listbox = tk.Listbox(left_frame, width=25, height=15)
        self.folder_listbox.pack(fill=tk.Y)
        self.folder_listbox.bind('<<ListboxSelect>>', self.on_folder_select)
        
        # í´ë” ëª©ë¡ ì¶”ê°€
        folders = {
            'detected_manual': 'ìˆ˜ë™ ìº¡ì²˜',
            'detected_auto': 'ìë™ ìˆ˜ì§‘',
            'staging_named': 'ì´ë¦„ ì§€ì •ë¨'
        }
        
        for key, display_name in folders.items():
            file_count = len(list(self.paths[key].glob('*.jpg')))
            self.folder_listbox.insert(tk.END, f"{display_name} ({file_count}ê°œ)")
        
        # ìš°ì¸¡: ì´ë¯¸ì§€ ê·¸ë¦¬ë“œ
        right_frame = ttk.Frame(main_frame)
        right_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)
        
        ttk.Label(right_frame, text="ì–¼êµ´ ì´ë¯¸ì§€", font=('Arial', 12, 'bold')).pack(pady=(0, 10))
        
        # ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•œ ìº”ë²„ìŠ¤
        canvas_frame = ttk.Frame(right_frame)
        canvas_frame.pack(fill=tk.BOTH, expand=True)
        
        self.canvas = tk.Canvas(canvas_frame, bg='white')
        scrollbar = ttk.Scrollbar(canvas_frame, orient="vertical", command=self.canvas.yview)
        self.scrollable_frame = ttk.Frame(self.canvas)
        
        self.scrollable_frame.bind(
            "<Configure>",
            lambda e: self.canvas.configure(scrollregion=self.canvas.bbox("all"))
        )
        
        self.canvas.create_window((0, 0), window=self.scrollable_frame, anchor="nw")
        self.canvas.configure(yscrollcommand=scrollbar.set)
        
        self.canvas.pack(side="left", fill="both", expand=True)
        scrollbar.pack(side="right", fill="y")
        
        # í•˜ë‹¨: ë²„íŠ¼ë“¤
        button_frame = ttk.Frame(self.window)
        button_frame.pack(fill=tk.X, padx=10, pady=10)
        
        ttk.Button(button_frame, text="ì„ íƒ ì‚­ì œ", command=self.delete_selected).pack(side=tk.LEFT, padx=5)
        ttk.Button(button_frame, text="ì´ë¦„ ì§€ì •", command=self.assign_name).pack(side=tk.LEFT, padx=5)
        ttk.Button(button_frame, text="ê·¸ë£¹ ì§€ì •", command=self.assign_group).pack(side=tk.LEFT, padx=5)
        ttk.Button(button_frame, text="ìƒˆë¡œê³ ì¹¨", command=self.refresh_view).pack(side=tk.LEFT, padx=5)
        ttk.Button(button_frame, text="ë‹«ê¸°", command=self.window.destroy).pack(side=tk.RIGHT, padx=5)
        
        self.image_widgets = []
        
    def on_folder_select(self, event):
        """í´ë” ì„ íƒ ì‹œ ì´ë¯¸ì§€ ë¡œë“œ"""
        selection = self.folder_listbox.curselection()
        if not selection:
            return
            
        folder_index = selection[0]
        folder_keys = list(['detected_manual', 'detected_auto', 'staging_named'])
        
        if folder_index < len(folder_keys):
            self.current_folder = folder_keys[folder_index]
            self.load_images()
    
    def load_images(self):
        """í˜„ì¬ í´ë”ì˜ ì´ë¯¸ì§€ë“¤ ë¡œë“œ"""
        # ê¸°ì¡´ ìœ„ì ¯ë“¤ ì œê±°
        for widget in self.image_widgets:
            widget.destroy()
        self.image_widgets.clear()
        self.selected_files.clear()
        
        folder_path = self.paths[self.current_folder]
        image_files = list(folder_path.glob('*.jpg'))
        
        if not image_files:
            ttk.Label(self.scrollable_frame, text="ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.").pack(pady=20)
            return
        
        # ê·¸ë¦¬ë“œ ë ˆì´ì•„ì›ƒìœ¼ë¡œ ì´ë¯¸ì§€ í‘œì‹œ
        cols = 5
        for i, img_file in enumerate(image_files):
            row = i // cols
            col = i % cols
            
            # ì´ë¯¸ì§€ í”„ë ˆì„
            img_frame = ttk.Frame(self.scrollable_frame)
            img_frame.grid(row=row, column=col, padx=5, pady=5, sticky="nsew")
            
            try:
                # ì´ë¯¸ì§€ ë¡œë“œ ë° ë¦¬ì‚¬ì´ì¦ˆ
                pil_image = Image.open(img_file)
                pil_image.thumbnail((120, 120), Image.Resampling.LANCZOS)
                photo = ImageTk.PhotoImage(pil_image)
                
                # ì²´í¬ë°•ìŠ¤
                var = tk.BooleanVar()
                checkbox = ttk.Checkbutton(img_frame, variable=var)
                checkbox.pack()
                
                # ì´ë¯¸ì§€ ë¼ë²¨
                img_label = tk.Label(img_frame, image=photo, bg='white')
                img_label.image = photo  # ì°¸ì¡° ìœ ì§€
                img_label.pack()
                
                # íŒŒì¼ëª… ë¼ë²¨
                filename_label = ttk.Label(img_frame, text=img_file.name[:20], font=('Arial', 8))
                filename_label.pack()
                
                self.image_widgets.extend([img_frame, checkbox, img_label, filename_label])
                self.selected_files.append((img_file, var))
                
            except Exception as e:
                print(f"ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜: {img_file.name} - {e}")
    
    def delete_selected(self):
        """ì„ íƒëœ ì´ë¯¸ì§€ë“¤ ì‚­ì œ"""
        selected = [f for f, var in self.selected_files if var.get()]
        
        if not selected:
            messagebox.showwarning("ì„ íƒ ì—†ìŒ", "ì‚­ì œí•  ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            return
        
        if messagebox.askyesno("ì‚­ì œ í™•ì¸", f"{len(selected)}ê°œ ì´ë¯¸ì§€ë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?"):
            for img_file in selected:
                try:
                    img_file.unlink()
                    # ë©”íƒ€ë°ì´í„°ë„ ì‚­ì œ
                    metadata_file = img_file.with_suffix('.json')
                    if metadata_file.exists():
                        metadata_file.unlink()
                except Exception as e:
                    print(f"ì‚­ì œ ì˜¤ë¥˜: {img_file.name} - {e}")
            
            messagebox.showinfo("ì™„ë£Œ", f"{len(selected)}ê°œ ì´ë¯¸ì§€ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
            self.load_images()
    
    def assign_name(self):
        """ì„ íƒëœ ì´ë¯¸ì§€ë“¤ì— ì´ë¦„ ì§€ì •"""
        selected = [f for f, var in self.selected_files if var.get()]
        
        if not selected:
            messagebox.showwarning("ì„ íƒ ì—†ìŒ", "ì´ë¦„ì„ ì§€ì •í•  ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            return
        
        name = simpledialog.askstring("ì´ë¦„ ì…ë ¥", "ì¸ë¬¼ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”:")
        if not name:
            return
        
        # staging/named/{name} í´ë”ì— ì´ë™
        target_dir = self.paths['staging_named'] / name
        target_dir.mkdir(exist_ok=True)
        
        moved_count = 0
        for img_file in selected:
            try:
                new_path = target_dir / img_file.name
                img_file.rename(new_path)
                
                # ë©”íƒ€ë°ì´í„°ë„ ì´ë™
                metadata_file = img_file.with_suffix('.json')
                if metadata_file.exists():
                    new_metadata_path = target_dir / metadata_file.name
                    metadata_file.rename(new_metadata_path)
                
                moved_count += 1
            except Exception as e:
                print(f"ì´ë™ ì˜¤ë¥˜: {img_file.name} - {e}")
        
        messagebox.showinfo("ì™„ë£Œ", f"{moved_count}ê°œ ì´ë¯¸ì§€ê°€ '{name}' í´ë”ë¡œ ì´ë™ë˜ì—ˆìŠµë‹ˆë‹¤.")
        self.load_images()
        self.refresh_folder_counts()
    
    def assign_group(self):
        """ì„ íƒëœ ì´ë¯¸ì§€ë“¤ì— ê·¸ë£¹ ì§€ì •"""
        selected = [f for f, var in self.selected_files if var.get()]
        
        if not selected:
            messagebox.showwarning("ì„ íƒ ì—†ìŒ", "ê·¸ë£¹ì„ ì§€ì •í•  ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            return
        
        group_name = simpledialog.askstring("ê·¸ë£¹ ì…ë ¥", "ê·¸ë£¹ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”:")
        if not group_name:
            return
        
        # staging/grouped/{group_name} í´ë”ì— ì´ë™
        target_dir = self.paths.get('staging_grouped')
        if not target_dir:
            # staging_grouped ê²½ë¡œ ì¶”ê°€
            self.paths['staging_grouped'] = self.paths['staging_named'].parent / 'grouped'
            target_dir = self.paths['staging_grouped']
        
        target_dir = target_dir / group_name
        target_dir.mkdir(parents=True, exist_ok=True)
        
        moved_count = 0
        for img_file in selected:
            try:
                new_path = target_dir / img_file.name
                img_file.rename(new_path)
                
                # ë©”íƒ€ë°ì´í„°ë„ ì´ë™
                metadata_file = img_file.with_suffix('.json')
                if metadata_file.exists():
                    new_metadata_path = target_dir / metadata_file.name
                    metadata_file.rename(new_metadata_path)
                
                moved_count += 1
            except Exception as e:
                print(f"ì´ë™ ì˜¤ë¥˜: {img_file.name} - {e}")
        
        messagebox.showinfo("ì™„ë£Œ", f"{moved_count}ê°œ ì´ë¯¸ì§€ê°€ '{group_name}' ê·¸ë£¹ìœ¼ë¡œ ì´ë™ë˜ì—ˆìŠµë‹ˆë‹¤.")
        self.load_images()
    
    def refresh_view(self):
        """í™”ë©´ ìƒˆë¡œê³ ì¹¨"""
        self.refresh_folder_counts()
        if hasattr(self, 'current_folder'):
            self.load_images()
    
    def refresh_folder_counts(self):
        """í´ë” ê°œìˆ˜ ìƒˆë¡œê³ ì¹¨"""
        self.folder_listbox.delete(0, tk.END)
        folders = {
            'detected_manual': 'ìˆ˜ë™ ìº¡ì²˜',
            'detected_auto': 'ìë™ ìˆ˜ì§‘',
            'staging_named': 'ì´ë¦„ ì§€ì •ë¨'
        }
        
        for key, display_name in folders.items():
            file_count = len(list(self.paths[key].glob('*.jpg')))
            self.folder_listbox.insert(tk.END, f"{display_name} ({file_count}ê°œ)")

class ImprovedFaceDetector:
    """ê°œì„ ëœ ì–¼êµ´ ê²€ì¶œê¸°"""
    
    def __init__(self, model_config: Dict):
        self.model_config = model_config
        self.model_type = model_config.get('type', 'haar')
        self.confidence_threshold = 0.5
        
        # Haar Cascade ì„¤ì • ê°œì„ 
        self.scale_factor = 1.1  # ë” ì„¸ë°€í•œ ê²€ì¶œ
        self.min_neighbors = 3   # ë” ë¯¼ê°í•œ ê²€ì¶œ
        self.min_size = (30, 30)  # ë” ì‘ì€ ì–¼êµ´ë„ ê²€ì¶œ
        
        self._initialize_model()
    
    def _initialize_model(self):
        """ëª¨ë¸ ì´ˆê¸°í™”"""
        if self.model_type in ['haar', 'haar_default']:
            self.detector = cv2.CascadeClassifier(self.model_config['path'])
            if self.detector.empty():
                # ê¸°ë³¸ Haar Cascade ì‚¬ìš©
                self.detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        
        # í”„ë¡œíŒŒì¼ ì–¼êµ´ ê²€ì¶œê¸°ë„ ì¶”ê°€
        self.profile_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_profileface.xml')
    
    def detect_faces(self, image: np.ndarray) -> List[Dict]:
        """ê°œì„ ëœ ì–¼êµ´ ê²€ì¶œ"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”ë¡œ ì¡°ëª… ê°œì„ 
        gray = cv2.equalizeHist(gray)
        
        detections = []
        
        # ì •ë©´ ì–¼êµ´ ê²€ì¶œ
        frontal_faces = self.detector.detectMultiScale(
            gray,
            scaleFactor=self.scale_factor,
            minNeighbors=self.min_neighbors,
            minSize=self.min_size,
            flags=cv2.CASCADE_SCALE_IMAGE
        )
        
        for (x, y, w, h) in frontal_faces:
            detections.append({
                'bbox': (x, y, w, h),
                'confidence': 1.0,
                'type': 'frontal',
                'quality_score': self._calculate_quality_score(x, y, w, h, image.shape)
            })
        
        # í”„ë¡œíŒŒì¼ ì–¼êµ´ ê²€ì¶œ (ì •ë©´ì—ì„œ ê²€ì¶œë˜ì§€ ì•Šì€ ê²½ìš°)
        if len(detections) == 0:
            profile_faces = self.profile_detector.detectMultiScale(
                gray,
                scaleFactor=1.2,
                minNeighbors=4,
                minSize=self.min_size
            )
            
            for (x, y, w, h) in profile_faces:
                detections.append({
                    'bbox': (x, y, w, h),
                    'confidence': 0.8,  # í”„ë¡œíŒŒì¼ì€ ì‹ ë¢°ë„ ë‚®ê²Œ
                    'type': 'profile',
                    'quality_score': self._calculate_quality_score(x, y, w, h, image.shape)
                })
        
        return detections
    
    def _calculate_quality_score(self, x: int, y: int, w: int, h: int, image_shape: Tuple) -> float:
        """ì–¼êµ´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        # í¬ê¸° ì ìˆ˜ (ë” í° ì–¼êµ´ì´ ë†’ì€ ì ìˆ˜)
        face_area = w * h
        image_area = image_shape[0] * image_shape[1]
        size_ratio = face_area / image_area if image_area > 0 else 0
        size_score = min(size_ratio * 20, 1.0)  # ë” ë†’ì€ ê°€ì¤‘ì¹˜
        
        # ìœ„ì¹˜ ì ìˆ˜ (ì¤‘ì•™ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
        center_x, center_y = x + w//2, y + h//2
        img_center_x, img_center_y = image_shape[1]//2, image_shape[0]//2
        distance = ((center_x - img_center_x)**2 + (center_y - img_center_y)**2)**0.5
        max_distance = (img_center_x**2 + img_center_y**2)**0.5
        position_score = 1.0 - (distance / max_distance) if max_distance > 0 else 1.0
        
        # ì¢…íš¡ë¹„ ì ìˆ˜ (ì •ì‚¬ê°í˜•ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
        aspect_ratio = w / h if h > 0 else 0
        aspect_score = 1.0 - abs(aspect_ratio - 1.0)
        
        return (size_score * 0.5 + position_score * 0.3 + aspect_score * 0.2)

class EnhancedFaceCaptureSystemV2:
    """ê°œì„ ëœ ì–¼êµ´ ìº¡ì²˜ ì‹œìŠ¤í…œ v2"""
    
    def __init__(self, camera_id: int = 0):
        # ë¡œê¹… ì„¤ì •
        setup_logging()
        self.logger = get_logger(__name__)
        
        # ì¹´ë©”ë¼ ì„¤ì •
        self.camera_id = camera_id
        self.cap = None
        
        # ëª¨ë¸ ì„¤ì • (ê°œì„ ëœ Haar Cascade ì‚¬ìš©)
        model_config = {
            'name': 'Improved Haar Cascade',
            'type': 'haar',
            'path': cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        }
        
        # ê°œì„ ëœ ì–¼êµ´ ê²€ì¶œê¸°
        self.face_detector = ImprovedFaceDetector(model_config)
        
        # GUI ê´€ë¦¬ì
        self.face_manager = None
        
        # ê²½ë¡œ ì„¤ì •
        self.domain_root = project_root / 'data' / 'domains' / 'face_recognition'
        self.paths = {
            'raw_captured': self.domain_root / 'raw_input' / 'captured',
            'detected_manual': self.domain_root / 'detected_faces' / 'from_manual',
            'detected_auto': self.domain_root / 'detected_faces' / 'auto_collected',
            'staging_named': self.domain_root / 'staging' / 'named',
            'staging_grouped': self.domain_root / 'staging' / 'grouped'
        }
        
        # í´ë” ìƒì„±
        for path in self.paths.values():
            path.mkdir(parents=True, exist_ok=True)
        
        # ìƒíƒœ ë³€ìˆ˜
        self.is_auto_mode = False
        self.show_info = True
        self.current_fps = 0
        self.fps_counter = 0
        self.fps_timer = time.time()
        
        # ì„¸ì…˜ í†µê³„
        self.session_stats = {
            'auto_saved': 0,
            'manual_captured': 0,
            'named_saved': 0
        }
        
        self.logger.info("âœ… ê°œì„ ëœ ì–¼êµ´ ìº¡ì²˜ ì‹œìŠ¤í…œ v2 ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _adjust_confidence_threshold(self, delta: float):
        """ì‹ ë¢°ë„ ì„ê³„ê°’ ì¡°ì ˆ"""
        self.face_detector.confidence_threshold = max(0.1, min(1.0, self.face_detector.confidence_threshold + delta))
        print(f"ğŸ¯ ì‹ ë¢°ë„ ì„ê³„ê°’: {self.face_detector.confidence_threshold:.2f}")
    
    def _adjust_scale_factor(self, delta: float):
        """ìŠ¤ì¼€ì¼ íŒ©í„° ì¡°ì ˆ"""
        self.face_detector.scale_factor = max(1.01, min(2.0, self.face_detector.scale_factor + delta))
        print(f"ğŸ“ ìŠ¤ì¼€ì¼ íŒ©í„°: {self.face_detector.scale_factor:.2f}")
    
    def _adjust_min_neighbors(self, delta: int):
        """ìµœì†Œ ì´ì›ƒ ìˆ˜ ì¡°ì ˆ"""
        self.face_detector.min_neighbors = max(1, min(10, self.face_detector.min_neighbors + delta))
        print(f"ğŸ‘¥ ìµœì†Œ ì´ì›ƒ ìˆ˜: {self.face_detector.min_neighbors}")
    
    def _switch_to_next_model(self):
        """ë‹¤ìŒ ëª¨ë¸ë¡œ ë³€ê²½"""
        self._switch_model(1)
    
    def _switch_to_previous_model(self):
        """ì´ì „ ëª¨ë¸ë¡œ ë³€ê²½"""
        self._switch_model(-1)
    
    def _switch_model(self, direction: int):
        """ëª¨ë¸ ì „í™˜"""
        # í˜„ì¬ëŠ” Haar Cascadeë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ ë©”ì‹œì§€ë§Œ ì¶œë ¥
        print("ğŸ”„ í˜„ì¬ëŠ” ê°œì„ ëœ Haar Cascade ëª¨ë¸ë§Œ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤")
        print("   ë‹¤ë¥¸ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ ëª¨ë¸ íŒŒì¼ì„ ì¶”ê°€í•˜ì„¸ìš”")
    
    def start_capture(self):
        """ìº¡ì²˜ ì‹œì‘"""
        try:
            if not self._initialize_camera():
                return
            
            self.logger.info("ğŸš€ ê°œì„ ëœ ì–¼êµ´ ìº¡ì²˜ ì‹œìŠ¤í…œ v2 ì‹œì‘")
            self._print_help()
            self._capture_loop()
            
        except KeyboardInterrupt:
            self.logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        except Exception as e:
            self.logger.error(f"ìº¡ì²˜ ì˜¤ë¥˜: {e}")
        finally:
            self._cleanup()
    
    def _initialize_camera(self) -> bool:
        """ì¹´ë©”ë¼ ì´ˆê¸°í™”"""
        try:
            self.cap = cv2.VideoCapture(self.camera_id)
            if not self.cap.isOpened():
                self.logger.error(f"ì¹´ë©”ë¼ {self.camera_id} ì—°ê²° ì‹¤íŒ¨")
                return False
            
            # ì¹´ë©”ë¼ ì„¤ì •
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.cap.set(cv2.CAP_PROP_FPS, 30)
            
            width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            print(f"âœ… ì¹´ë©”ë¼ {self.camera_id} ì—°ê²° ì„±ê³µ ({width}x{height})")
            return True
            
        except Exception as e:
            self.logger.error(f"ì¹´ë©”ë¼ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            return False
    
    def _capture_loop(self):
        """ë©”ì¸ ìº¡ì²˜ ë£¨í”„"""
        while True:
            ret, frame = self.cap.read()
            if not ret:
                self.logger.error("í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                break
            
            # ì–¼êµ´ ê²€ì¶œ
            detections = self.face_detector.detect_faces(frame)
            
            # ìë™ ëª¨ë“œì—ì„œ ì–¼êµ´ ìë™ ì €ì¥
            if self.is_auto_mode and detections:
                self._handle_auto_save(frame, detections)
            
            # ì‹œê°í™”
            display_frame = self._visualize_detections(frame, detections)
            
            if self.show_info:
                display_frame = self._draw_info_overlay(display_frame, detections)
            
            cv2.imshow('Enhanced Face Capture v2', display_frame)
            
            # FPS ì—…ë°ì´íŠ¸
            self._update_fps()
            
            # í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬
            action = self._handle_keyboard_input(cv2.waitKey(1) & 0xFF, frame, detections)
            if action == 'quit':
                break
    
    def _handle_keyboard_input(self, key: int, frame: np.ndarray, detections: List[Dict]) -> str:
        """í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬"""
        if key == ord('q'):
            return 'quit'
        elif key == ord('i'):
            self.show_info = not self.show_info
            status = "ON" if self.show_info else "OFF"
            print(f"â„¹ï¸  ì •ë³´ í‘œì‹œ: {status}")
        elif key == ord('a'):
            self.is_auto_mode = not self.is_auto_mode
            mode = "ğŸ¤– ìë™" if self.is_auto_mode else "ğŸ‘¤ ìˆ˜ë™"
            print(f"ğŸ”„ ëª¨ë“œ ë³€ê²½: {mode}")
        elif key == ord('s'):
            self._save_full_frame(frame)
        elif key == ord('c'):
            self._handle_manual_face_capture(frame, detections)
        elif key == ord('e'):  # í¸ì§‘ ëª¨ë“œ (ìƒˆë¡œìš´ ê¸°ëŠ¥)
            self._open_face_manager()
        elif key == ord('h'):
            self._print_help()
        # ëª¨ë¸ ì„¤ì • ì¡°ì ˆ í‚¤ ì¶”ê°€
        elif key == ord('+') or key == ord('='):
            self._adjust_confidence_threshold(0.05)
        elif key == ord('-') or key == ord('_'):
            self._adjust_confidence_threshold(-0.05)
        elif key == ord('['):
            self._adjust_scale_factor(-0.05)
        elif key == ord(']'):
            self._adjust_scale_factor(0.05)
        elif key == ord(','):
            self._adjust_min_neighbors(-1)
        elif key == ord('.'):
            self._adjust_min_neighbors(1)
        # ëª¨ë¸ ë³€ê²½ í‚¤ ì¶”ê°€
        elif key == ord('n'):
            self._switch_to_next_model()
        elif key == ord('m'):
            self._switch_to_previous_model()
        
        return 'continue'
    
    def _open_face_manager(self):
        """ì–¼êµ´ ê´€ë¦¬ì ì—´ê¸°"""
        def open_manager():
            try:
                face_manager = FaceManagerGUI(self.paths)
                face_manager.open_face_manager()
                print("\n" + "="*60)
                print("ğŸ¯ ì–¼êµ´ ê´€ë¦¬ì ì‚¬ìš©ë²•")
                print("="*60)
                print("ğŸ“ í´ë” ì„ íƒ:")
                print("   - from_manual: ìˆ˜ë™ìœ¼ë¡œ ìº¡ì²˜í•œ ì–¼êµ´ë“¤")
                print("   - from_captured: ì „ì²´ í”„ë ˆì„ì—ì„œ ê²€ì¶œëœ ì–¼êµ´ë“¤")
                print("   - from_uploads: ì—…ë¡œë“œëœ ì´ë¯¸ì§€ì—ì„œ ê²€ì¶œëœ ì–¼êµ´ë“¤")
                print("   - auto_collected: ìë™ ëª¨ë“œì—ì„œ ì €ì¥ëœ ì–¼êµ´ë“¤")
                print()
                print("ğŸ–±ï¸  ë§ˆìš°ìŠ¤ ì¡°ì‘:")
                print("   - í´ë¦­: ì´ë¯¸ì§€ ì„ íƒ/í•´ì œ")
                print("   - Ctrl+í´ë¦­: ì—¬ëŸ¬ ì´ë¯¸ì§€ ì„ íƒ")
                print("   - Shift+í´ë¦­: ë²”ìœ„ ì„ íƒ")
                print()
                print("ğŸ”§ ê¸°ëŠ¥ ë²„íŠ¼:")
                print("   - [Delete Selected]: ì„ íƒëœ ì´ë¯¸ì§€ë“¤ ì‚­ì œ")
                print("   - [Assign Name]: ì´ë¦„ ì§€ì • (staging/named/ í´ë”ë¡œ ì´ë™)")
                print("   - [Assign Group]: ê·¸ë£¹ ì§€ì • (staging/grouped/ í´ë”ë¡œ ì´ë™)")
                print("   - [Refresh]: ëª©ë¡ ìƒˆë¡œê³ ì¹¨")
                print()
                print("ğŸ’¡ íŒ:")
                print("   - ì´ë¦„ ì§€ì • ì‹œ: staging/named/{ì´ë¦„}/ í´ë”ì— ì €ì¥")
                print("   - ê·¸ë£¹ ì§€ì • ì‹œ: staging/grouped/{ê·¸ë£¹}/ í´ë”ì— ì €ì¥")
                print("   - ì‚­ì œ ì‹œ: ì˜êµ¬ì ìœ¼ë¡œ ì‚­ì œë˜ë¯€ë¡œ ì£¼ì˜")
                print("="*60)
            except Exception as e:
                print(f"ì–¼êµ´ ê´€ë¦¬ì ì˜¤ë¥˜: {e}")
        
        # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        manager_thread = threading.Thread(target=open_manager, daemon=True)
        manager_thread.start()
    
    def _save_full_frame(self, frame: np.ndarray):
        """ì „ì²´ í”„ë ˆì„ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]
        frame_filename = f"captured_frame_{timestamp}.jpg"
        frame_path = self.paths['raw_captured'] / frame_filename
        cv2.imwrite(str(frame_path), frame)
        
        metadata = {
            'timestamp': timestamp,
            'capture_type': 'manual_frame',
            'frame_path': str(frame_path),
            'frame_size': list(frame.shape)
        }
        
        metadata_path = frame_path.with_suffix('.json')
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ì „ì²´ í”„ë ˆì„ ì €ì¥: {frame_filename}")
        self.session_stats['manual_captured'] += 1
    
    def _handle_manual_face_capture(self, frame: np.ndarray, detections: List[Dict]):
        """ìˆ˜ë™ ì–¼êµ´ ìº¡ì²˜"""
        if not detections:
            print("âŒ ê²€ì¶œëœ ì–¼êµ´ì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]
        
        for i, detection in enumerate(detections):
            bbox = detection['bbox']
            x, y, w, h = bbox
            face_crop = frame[y:y+h, x:x+w]
            
            face_filename = f"manual_face_{timestamp}_{i:02d}_conf{detection['confidence']:.2f}.jpg"
            face_path = self.paths['detected_manual'] / face_filename
            cv2.imwrite(str(face_path), face_crop)
            
            metadata = {
                'timestamp': timestamp,
                'capture_type': 'manual',
                'bbox': [int(x), int(y), int(w), int(h)],
                'confidence': float(detection['confidence']),
                'quality_score': float(detection['quality_score']),
                'face_type': detection.get('type', 'frontal')
            }
            
            metadata_path = face_path.with_suffix('.json')
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… {len(detections)}ê°œ ì–¼êµ´ì„ detected_faces/from_manualì— ì €ì¥")
        self.session_stats['manual_captured'] += len(detections)
    
    def _handle_auto_save(self, frame: np.ndarray, detections: List[Dict]):
        """ìë™ ëª¨ë“œì—ì„œ ì–¼êµ´ ì €ì¥"""
        for detection in detections:
            if detection['quality_score'] > 0.3:  # í’ˆì§ˆ ì„ê³„ê°’
                self._auto_save_detected_face(frame, detection)
    
    def _auto_save_detected_face(self, frame: np.ndarray, detection: Dict):
        """ìë™ ì–¼êµ´ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]
        
        bbox = detection['bbox']
        x, y, w, h = bbox
        face_crop = frame[y:y+h, x:x+w]
        
        face_filename = f"auto_face_{timestamp}_conf{detection['confidence']:.2f}_qual{detection['quality_score']:.2f}.jpg"
        face_path = self.paths['detected_auto'] / face_filename
        cv2.imwrite(str(face_path), face_crop)
        
        metadata = {
            'timestamp': timestamp,
            'capture_type': 'auto',
            'bbox': [int(x), int(y), int(w), int(h)],
            'confidence': float(detection['confidence']),
            'quality_score': float(detection['quality_score']),
            'face_type': detection.get('type', 'frontal')
        }
        
        metadata_path = face_path.with_suffix('.json')
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        self.session_stats['auto_saved'] += 1
    
    def _visualize_detections(self, frame: np.ndarray, detections: List[Dict]) -> np.ndarray:
        """ê²€ì¶œ ê²°ê³¼ ì‹œê°í™”"""
        display_frame = frame.copy()
        
        for detection in detections:
            bbox = detection['bbox']
            x, y, w, h = bbox
            confidence = detection['confidence']
            quality = detection['quality_score']
            face_type = detection.get('type', 'frontal')
            
            # ì–¼êµ´ íƒ€ì…ì— ë”°ë¥¸ ìƒ‰ìƒ
            color = (0, 255, 0) if face_type == 'frontal' else (0, 255, 255)
            
            # ë°”ìš´ë”© ë°•ìŠ¤
            cv2.rectangle(display_frame, (x, y), (x + w, y + h), color, 2)
            
            # ì •ë³´ í…ìŠ¤íŠ¸
            info_text = f"{face_type} {confidence:.2f} Q:{quality:.2f}"
            cv2.putText(display_frame, info_text, (x, y - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        
        return display_frame
    
    def _draw_info_overlay(self, frame: np.ndarray, detections: List[Dict]) -> np.ndarray:
        """ì •ë³´ ì˜¤ë²„ë ˆì´"""
        overlay_frame = frame.copy()
        height, width = overlay_frame.shape[:2]
        
        # ìƒë‹¨ ìƒíƒœ ì •ë³´ (ì˜ë¬¸ìœ¼ë¡œ ë³€ê²½)
        mode_text = "AUTO" if self.is_auto_mode else "MANUAL"
        cv2.putText(overlay_frame, f"Mode: {mode_text}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.putText(overlay_frame, f"FPS: {self.current_fps:.1f}", (10, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.putText(overlay_frame, f"Faces: {len(detections)}", (10, 90), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.putText(overlay_frame, f"Auto: {self.session_stats['auto_saved']}", (10, 120), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # ëª¨ë¸ ì •ë³´ (ì˜ë¬¸ìœ¼ë¡œ ë³€ê²½)
        model_name = self.face_detector.model_config.get('name', 'Unknown')
        # ëª¨ë¸ ì´ë¦„ì´ ê¸¸ë©´ ì¶•ì•½
        if len(model_name) > 30:
            model_name = model_name[:27] + "..."
        cv2.putText(overlay_frame, f"Model: {model_name}", (10, 150), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        # í•˜ë‹¨ í† ê¸€í‚¤ ì •ë³´
        self._draw_toggle_keys(overlay_frame, width, height)
        
        return overlay_frame
    
    def _draw_toggle_keys(self, frame: np.ndarray, width: int, height: int):
        """í† ê¸€í‚¤ ì •ë³´ë¥¼ í™”ë©´ í•˜ë‹¨ì— í‘œì‹œ"""
        # ë°°ê²½ ë°•ìŠ¤ (ë°˜íˆ¬ëª…)
        box_height = 140
        box_y = height - box_height - 10
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, box_y), (width, height), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # í† ê¸€í‚¤ ì •ë³´ (ì˜ë¬¸ìœ¼ë¡œ ë³€ê²½)
        y_start = box_y + 20
        line_height = 25
        
        # ì²« ë²ˆì§¸ ì¤„: ê¸°ë³¸ ëª…ë ¹ì–´
        cv2.putText(frame, "Toggle Keys:", (10, y_start), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        # ë‘ ë²ˆì§¸ ì¤„: ëª¨ë“œ ë° ì •ë³´
        cv2.putText(frame, "A: Auto/Manual  I: Info  H: Help  Q: Quit", (10, y_start + line_height), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # ì„¸ ë²ˆì§¸ ì¤„: ìº¡ì²˜ ëª…ë ¹ì–´
        cv2.putText(frame, "S: Save Frame  C: Capture Face  E: Face Manager", (10, y_start + line_height * 2), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # ë„¤ ë²ˆì§¸ ì¤„: ëª¨ë¸ ì„¤ì •
        cv2.putText(frame, "Model Settings: +/- Confidence  [/] Scale  ,/. Neighbors  N/M: Model", (10, y_start + line_height * 3), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # ë‹¤ì„¯ ë²ˆì§¸ ì¤„: í˜„ì¬ ì„¤ì •ê°’
        current_settings = f"Current: Conf={self.face_detector.confidence_threshold:.2f} Scale={self.face_detector.scale_factor:.2f} Neighbors={self.face_detector.min_neighbors}"
        cv2.putText(frame, current_settings, (10, y_start + line_height * 4), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
    
    def _put_korean_text(self, frame: np.ndarray, text: str, position: Tuple[int, int], font_size: int = 20, color: Tuple[int, int, int] = (255, 255, 255)):
        """í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ ì´ë¯¸ì§€ì— ì¶”ê°€ (PIL ì‚¬ìš©)"""
        try:
            # OpenCV ì´ë¯¸ì§€ë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(frame_rgb)
            
            # í°íŠ¸ ì„¤ì • (ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©)
            try:
                font = ImageFont.truetype("arial.ttf", font_size)
            except:
                font = ImageFont.load_default()
            
            # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
            draw = ImageDraw.Draw(pil_image)
            draw.text(position, text, font=font, fill=color)
            
            # PIL ì´ë¯¸ì§€ë¥¼ OpenCV ì´ë¯¸ì§€ë¡œ ë³€í™˜
            frame_rgb = np.array(pil_image)
            frame_bgr = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)
            
            return frame_bgr
        except Exception as e:
            # ì˜¤ë¥˜ ì‹œ ì˜ë¬¸ìœ¼ë¡œ ëŒ€ì²´
            cv2.putText(frame, text, position, cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            return frame
    
    def _update_fps(self):
        """FPS ì—…ë°ì´íŠ¸"""
        self.fps_counter += 1
        current_time = time.time()
        
        if current_time - self.fps_timer >= 1.0:
            self.current_fps = self.fps_counter / (current_time - self.fps_timer)
            self.fps_counter = 0
            self.fps_timer = current_time
    
    def _print_help(self):
        """ë„ì›€ë§ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“‹ ê°œì„ ëœ ì–¼êµ´ ìº¡ì²˜ ì‹œìŠ¤í…œ v2 - í‚¤ë³´ë“œ ëª…ë ¹ì–´")
        print("="*60)
        print("ğŸ”§ ê³µí†µ ëª…ë ¹ì–´:")
        print("   i  - ì •ë³´ í‘œì‹œ í† ê¸€")
        print("   a  - ìë™/ìˆ˜ë™ ëª¨ë“œ ì „í™˜")
        print("   h  - ë„ì›€ë§ í‘œì‹œ")
        print("   q  - ì¢…ë£Œ")
        print()
        print("ğŸ‘¤ ìº¡ì²˜ ëª…ë ¹ì–´:")
        print("   s  - ì „ì²´ í”„ë ˆì„ ì €ì¥ (raw_input/captured/)")
        print("   c  - ì–¼êµ´ ìº¡ì²˜ (detected_faces/from_manual/)")
        print("   e  - ì–¼êµ´ ê´€ë¦¬ì ì—´ê¸° (ë¯¸ë¦¬ë³´ê¸°, í¸ì§‘, ì‚­ì œ)")
        print()
        print("ğŸ›ï¸  ëª¨ë¸ ì„¤ì • ì¡°ì ˆ:")
        print("   +/- - ì‹ ë¢°ë„ ì„ê³„ê°’ ì¡°ì ˆ")
        print("   [/] - ìŠ¤ì¼€ì¼ íŒ©í„° ì¡°ì ˆ")
        print("   ,/. - ìµœì†Œ ì´ì›ƒ ìˆ˜ ì¡°ì ˆ")
        print("   n/m - ëª¨ë¸ ë³€ê²½ (ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ìˆì„ ë•Œ)")
        print()
        print("ğŸ¨ ì–¼êµ´ ê´€ë¦¬ì ê¸°ëŠ¥:")
        print("   - ë¯¸ë¦¬ë³´ê¸°: ì €ì¥ëœ ì–¼êµ´ ì´ë¯¸ì§€ í™•ì¸")
        print("   - ì´ë¦„ ì§€ì •: staging/named/{ì´ë¦„}/ í´ë”ë¡œ ì´ë™")
        print("   - ê·¸ë£¹ ì§€ì •: staging/grouped/{ê·¸ë£¹}/ í´ë”ë¡œ ì´ë™")
        print("   - ì‚­ì œ: ì„ íƒí•œ ì´ë¯¸ì§€ë“¤ ì‚­ì œ")
        print()
        print("ğŸ“ ë°ì´í„° í”Œë¡œìš°:")
        print("   1. sí‚¤: raw_input/captured/ (ì „ì²´ í”„ë ˆì„)")
        print("   2. cí‚¤: detected_faces/from_manual/ (ì–¼êµ´ë§Œ)")
        print("   3. ìë™ëª¨ë“œ: detected_faces/auto_collected/ (ì–¼êµ´ë§Œ)")
        print("   4. eí‚¤: ì–¼êµ´ ê´€ë¦¬ìë¡œ í¸ì§‘/ì´ë™/ì‚­ì œ")
        print("="*60)
    
    def _cleanup(self):
        """ì •ë¦¬ ì‘ì—…"""
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()
        
        print("\nğŸ“Š ì„¸ì…˜ í†µê³„:")
        print(f"   ìë™ ì €ì¥: {self.session_stats['auto_saved']}ê°œ")
        print(f"   ìˆ˜ë™ ìº¡ì²˜: {self.session_stats['manual_captured']}ê°œ")
        
        self.logger.info("ê°œì„ ëœ ì–¼êµ´ ìº¡ì²˜ ì‹œìŠ¤í…œ v2 ì¢…ë£Œ")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        system = EnhancedFaceCaptureSystemV2()
        system.start_capture()
    except Exception as e:
        print(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main() 