#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ìë™ ì–¼êµ´ ìˆ˜ì§‘ê¸° (ì‚¬ìš©ì ì œì•ˆ íë¦„ 1ë‹¨ê³„-1)

ì¹´ë©”ë¼ì—ì„œ ìë™ìœ¼ë¡œ ì–¼êµ´ì„ ê°ì§€í•˜ì—¬ data/temp/auto_collectedì— ì €ì¥í•˜ëŠ” ê¸°ëŠ¥ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
"""

import cv2
import time
import json
import uuid
import logging
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import List, Dict
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent.parent.parent
sys.path.append(str(project_root))

from domains.face_recognition.core.services.face_detection_service import FaceDetectionService
from shared.vision_core.quality.face_quality_assessor import CustomFaceQualityAssessor
from common.logging import setup_logging

logger = logging.getLogger(__name__)


class AutoFaceCollector:
    """ìë™ ì–¼êµ´ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.detection_service = FaceDetectionService()
        self.quality_assessor = CustomFaceQualityAssessor()
        
        # ìë™ ìˆ˜ì§‘ ì €ì¥ ê²½ë¡œ
        self.auto_collected_dir = Path("data/temp/auto_collected")
        self.auto_collected_dir.mkdir(parents=True, exist_ok=True)
        
        # ìˆ˜ì§‘ ì„¤ì •
        self.collection_settings = {
            'min_face_size': (80, 80),           # ìµœì†Œ ì–¼êµ´ í¬ê¸°
            'collection_interval': 2.0,          # ìˆ˜ì§‘ ê°„ê²© (ì´ˆ)
            'quality_threshold': 0.6,            # í’ˆì§ˆ ì„ê³„ê°’
            'max_collections_per_person': 20,    # ì¸ë¬¼ë‹¹ ìµœëŒ€ ìˆ˜ì§‘ ìˆ˜
            'confidence_threshold': 0.7          # ê²€ì¶œ ì‹ ë¢°ë„ ì„ê³„ê°’
        }
        
        # ìƒíƒœ ê´€ë¦¬
        self.last_collection_time = 0
        self.collected_faces = []
        self.current_session_id = str(uuid.uuid4())
        
    def run_auto_collection(self, camera_id: int = 0):
        """
        ğŸ¤– ìë™ ì–¼êµ´ ìˆ˜ì§‘ ì‹¤í–‰
        
        ì¹´ë©”ë¼ì—ì„œ ìë™ìœ¼ë¡œ ì–¼êµ´ì„ ê°ì§€í•˜ê³  í’ˆì§ˆ ì¢‹ì€ ê²ƒë“¤ì„ ìˆ˜ì§‘
        """
        print("ğŸ¤– ìë™ ì–¼êµ´ ìˆ˜ì§‘ê¸° ì‹œì‘")
        print("=" * 50)
        print("ğŸ“‹ ìë™ ìˆ˜ì§‘ ì„¤ì •:")
        print(f"  â€¢ ìˆ˜ì§‘ ê°„ê²©: {self.collection_settings['collection_interval']}ì´ˆ")
        print(f"  â€¢ í’ˆì§ˆ ì„ê³„ê°’: {self.collection_settings['quality_threshold']}")
        print(f"  â€¢ ìµœì†Œ ì–¼êµ´ í¬ê¸°: {self.collection_settings['min_face_size']}")
        print("ğŸ“‹ ì¡°ì‘ë²•:")
        print("  'p' â†’ ì¼ì‹œì •ì§€/ì¬ê°œ")
        print("  'r' â†’ ìˆ˜ì§‘ ë¦¬ì…‹")
        print("  'q' â†’ ì¢…ë£Œ ë° ì´ë¦„ ì„¤ì • ë‹¨ê³„ë¡œ")
        print("=" * 50)
        
        cap = cv2.VideoCapture(camera_id)
        if not cap.isOpened():
            logger.error(f"ì¹´ë©”ë¼ {camera_id} ì—´ê¸° ì‹¤íŒ¨")
            return
        
        is_paused = False
        
        try:
            while True:
                if not is_paused:
                    ret, frame = cap.read()
                    if not ret:
                        logger.warning("í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                        continue
                    
                    # ğŸ” ì–¼êµ´ ê²€ì¶œ
                    detections = self.detection_service.detect_faces(frame)
                    
                    # ğŸ¤– ìë™ ìˆ˜ì§‘ ì²˜ë¦¬
                    current_time = time.time()
                    if (current_time - self.last_collection_time >= self.collection_settings['collection_interval'] 
                        and len(detections) > 0):
                        
                        self._auto_collect_faces(frame, detections)
                        self.last_collection_time = current_time
                    
                    # ğŸ¨ í™”ë©´ í‘œì‹œ
                    display_frame = self._draw_auto_collection_ui(frame.copy(), detections)
                else:
                    # ì¼ì‹œì •ì§€ ìƒíƒœì—ì„œëŠ” ë§ˆì§€ë§‰ í”„ë ˆì„ ìœ ì§€
                    display_frame = self._draw_pause_message(frame.copy())
                
                cv2.imshow('ìë™ ì–¼êµ´ ìˆ˜ì§‘ê¸°', display_frame)
                
                # âŒ¨ï¸ í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                
                if key == ord('q'):
                    break
                elif key == ord('p'):
                    is_paused = not is_paused
                    status = "ì¼ì‹œì •ì§€" if is_paused else "ì¬ê°œ"
                    print(f"ğŸ”„ ìë™ ìˆ˜ì§‘ {status}")
                elif key == ord('r'):
                    self._reset_collection()
                    print("ğŸ”„ ìˆ˜ì§‘ ë°ì´í„° ë¦¬ì…‹")
                    
        finally:
            cap.release()
            cv2.destroyAllWindows()
            
            # ìˆ˜ì§‘ëœ ì–¼êµ´ì´ ìˆìœ¼ë©´ ì´ë¦„ ì„¤ì • ë‹¨ê³„ë¡œ
            if self.collected_faces:
                self._proceed_to_naming_stage()
            else:
                print("âŒ ìˆ˜ì§‘ëœ ì–¼êµ´ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    def _auto_collect_faces(self, frame: np.ndarray, detections: List):
        """ğŸ¤– ìë™ìœ¼ë¡œ ì–¼êµ´ ìˆ˜ì§‘"""
        for detection in detections:
            # ì‹ ë¢°ë„ í™•ì¸
            if detection.confidence.value < self.collection_settings['confidence_threshold']:
                continue
            
            # ì–¼êµ´ í¬ê¸° í™•ì¸
            bbox = detection.bbox.to_list()
            face_w, face_h = bbox[2], bbox[3]
            min_w, min_h = self.collection_settings['min_face_size']
            
            if face_w < min_w or face_h < min_h:
                continue
            
            # í’ˆì§ˆ í‰ê°€
            quality_result = self.quality_assessor.assess_face_quality(frame, bbox)
            
            if quality_result['quality_score'] < self.collection_settings['quality_threshold']:
                continue
            
            # ì–¼êµ´ í¬ë¡­ ë° ì €ì¥
            x, y, w, h = bbox
            face_crop = frame[y:y+h, x:x+w]
            
            # íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
            face_id = str(uuid.uuid4())[:8]
            filename = f"auto_{timestamp}_{face_id}.jpg"
            
            # ì €ì¥
            file_path = self.auto_collected_dir / filename
            cv2.imwrite(str(file_path), face_crop)
            
            # ë©”íƒ€ë°ì´í„° ìƒì„±
            metadata = {
                'face_id': face_id,
                'session_id': self.current_session_id,
                'collection_timestamp': datetime.now().isoformat(),
                'file_path': str(file_path),
                'bbox': bbox,
                'detection_confidence': detection.confidence.value,
                'quality_assessment': quality_result,
                'collection_method': 'auto_collection'
            }
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            metadata_path = self.auto_collected_dir / f"auto_{timestamp}_{face_id}.json"
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            self.collected_faces.append({
                'face_id': face_id,
                'file_path': file_path,
                'metadata_path': metadata_path,
                'quality_score': quality_result['quality_score']
            })
            
            print(f"âœ… ìë™ ìˆ˜ì§‘: {filename} (í’ˆì§ˆ: {quality_result['quality_score']:.3f})")
            
            # ìµœëŒ€ ìˆ˜ì§‘ ìˆ˜ í™•ì¸
            if len(self.collected_faces) >= self.collection_settings['max_collections_per_person']:
                print(f"ğŸ“Š ìµœëŒ€ ìˆ˜ì§‘ ìˆ˜({self.collection_settings['max_collections_per_person']})ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                return
    
    def _draw_auto_collection_ui(self, frame: np.ndarray, detections: List) -> np.ndarray:
        """ğŸ¨ ìë™ ìˆ˜ì§‘ UI í‘œì‹œ"""
        # ê²€ì¶œëœ ì–¼êµ´ í‘œì‹œ
        for i, detection in enumerate(detections):
            bbox = detection.bbox.to_list()
            x, y, w, h = bbox
            
            # ì–¼êµ´ ë°•ìŠ¤ (í’ˆì§ˆì— ë”°ë¼ ìƒ‰ìƒ ë³€ê²½)
            confidence = detection.confidence.value
            if confidence >= self.collection_settings['confidence_threshold']:
                color = (0, 255, 0)  # ë…¹ìƒ‰ (ìˆ˜ì§‘ ê°€ëŠ¥)
            else:
                color = (0, 255, 255)  # ë…¸ë€ìƒ‰ (í’ˆì§ˆ ë¶€ì¡±)
            
            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
            
            # ì‹ ë¢°ë„ í‘œì‹œ
            conf_text = f'{confidence:.2f}'
            cv2.putText(frame, conf_text, (x, y-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        # ìƒíƒœ ì •ë³´ í‘œì‹œ
        info_lines = [
            f"Auto Collection: ON",
            f"Collected: {len(self.collected_faces)}",
            f"Session: {self.current_session_id[:8]}",
            f"Next collection in: {max(0, self.collection_settings['collection_interval'] - (time.time() - self.last_collection_time)):.1f}s"
        ]
        
        for i, line in enumerate(info_lines):
            y = 30 + i * 25
            cv2.putText(frame, line, (10, y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        return frame
    
    def _draw_pause_message(self, frame: np.ndarray) -> np.ndarray:
        """ì¼ì‹œì •ì§€ ë©”ì‹œì§€ í‘œì‹œ"""
        cv2.putText(frame, "PAUSED", (frame.shape[1]//2 - 50, frame.shape[0]//2),
                   cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3)
        return frame
    
    def _reset_collection(self):
        """ìˆ˜ì§‘ ë°ì´í„° ë¦¬ì…‹"""
        self.collected_faces = []
        self.current_session_id = str(uuid.uuid4())
        self.last_collection_time = 0
    
    def _proceed_to_naming_stage(self):
        """ì´ë¦„ ì„¤ì • ë‹¨ê³„ë¡œ ì§„í–‰"""
        print(f"\nğŸ·ï¸ ì´ë¦„ ì„¤ì • ë‹¨ê³„ - ìˆ˜ì§‘ëœ ì–¼êµ´: {len(self.collected_faces)}ê°œ")
        print("=" * 50)
        
        # ìˆ˜ì§‘ëœ ì–¼êµ´ë“¤ì„ í’ˆì§ˆ ìˆœìœ¼ë¡œ ì •ë ¬
        self.collected_faces.sort(key=lambda x: x['quality_score'], reverse=True)
        
        # ëŒ€í‘œ ì–¼êµ´ë“¤ í‘œì‹œ (ìƒìœ„ 5ê°œ)
        print("ğŸ“· ìˆ˜ì§‘ëœ ì–¼êµ´ë“¤ (í’ˆì§ˆ ìˆœ):")
        display_count = min(5, len(self.collected_faces))
        
        for i in range(display_count):
            face_info = self.collected_faces[i]
            print(f"  {i+1}. {face_info['face_id']} (í’ˆì§ˆ: {face_info['quality_score']:.3f})")
        
        if len(self.collected_faces) > 5:
            print(f"  ... ì™¸ {len(self.collected_faces) - 5}ê°œ")
        
        # ì¸ë¬¼ ì´ë¦„ ì…ë ¥
        while True:
            person_name = input("\nğŸ‘¤ ì´ ì¸ë¬¼ì˜ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            
            if person_name:
                # data/temp/face_stagingë¡œ ì´ë™
                self._move_to_face_staging(person_name)
                break
            else:
                print("âŒ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    def _move_to_face_staging(self, person_name: str):
        """data/temp/face_stagingë¡œ ì´ë™ (ì‚¬ìš©ì ì œì•ˆ íë¦„)"""
        face_staging_dir = Path("data/temp/face_staging")
        face_staging_dir.mkdir(parents=True, exist_ok=True)
        
        moved_count = 0
        
        for face_info in self.collected_faces:
            try:
                # íŒŒì¼ ì´ë™
                old_path = face_info['file_path']
                new_filename = f"{person_name}_{old_path.stem}.jpg"
                new_path = face_staging_dir / new_filename
                
                # ì´ë¯¸ì§€ íŒŒì¼ ë³µì‚¬
                import shutil
                shutil.copy2(str(old_path), str(new_path))
                
                # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ë° ì´ë™
                with open(face_info['metadata_path'], 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                
                metadata['person_name'] = person_name
                metadata['moved_to_face_staging'] = datetime.now().isoformat()
                metadata['original_auto_collected_path'] = str(old_path)
                
                new_metadata_path = face_staging_dir / f"{person_name}_{old_path.stem}.json"
                with open(new_metadata_path, 'w', encoding='utf-8') as f:
                    json.dump(metadata, f, ensure_ascii=False, indent=2)
                
                moved_count += 1
                
            except Exception as e:
                logger.error(f"íŒŒì¼ ì´ë™ ì‹¤íŒ¨ {old_path}: {str(e)}")
        
        print(f"\nâœ… ìë™ ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"   ğŸ“ ì´ë™ëœ ì–¼êµ´: {moved_count}ê°œ")
        print(f"   ğŸ“‚ ì €ì¥ ìœ„ì¹˜: data/temp/face_staging/")
        print(f"   ğŸ‘¤ ì¸ë¬¼ ì´ë¦„: {person_name}")
        print("\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
        print("   1ï¸âƒ£ ê¸°ì¡´ ëª¨ë¸ë¡œ ì¦‰ì‹œ ë“±ë¡í•˜ë ¤ë©´ â†’ í†µí•© ìº¡ì²˜ ì‹œìŠ¤í…œ ì‹¤í–‰")
        print("   2ï¸âƒ£ í›ˆë ¨ìš© ë°ì´í„°ë¡œ ì‚¬ìš©í•˜ë ¤ë©´ â†’ ë°ì´í„° ìˆ˜ì§‘ ë„êµ¬ ì‹¤í–‰")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        setup_logging()
        logger.info("Starting Auto Face Collector")
        
        collector = AutoFaceCollector()
        collector.run_auto_collection()
        
    except KeyboardInterrupt:
        print("\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"Error in main: {str(e)}")
        print(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    finally:
        cv2.destroyAllWindows()
        logger.info("Auto Face Collector finished")


if __name__ == "__main__":
    main() 