#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì‹¤ì‹œê°„ ì–¼êµ´ ìº¡ì²˜ ë° ë“±ë¡ ì‹œìŠ¤í…œ.

ì¹´ë©”ë¼ì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ì–¼êµ´ì„ ê°ì§€í•˜ê³ , ì‚¬ìš©ìê°€ ì„ íƒí•œ ì–¼êµ´ì„ ë°”ë¡œ ë“±ë¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

import os
import sys
import time
import cv2
import uuid
import logging
import argparse
import numpy as np
from pathlib import Path
from typing import Optional, List, Dict

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent.parent.parent
sys.path.append(str(project_root))

from common.logging import setup_logging, get_logger
from domains.face_recognition.core.services.face_detection_service import FaceDetectionService
from domains.face_recognition.core.services.face_recognition_service import FaceRecognitionService
from domains.face_recognition.core.entities.person import Person
from domains.face_recognition.core.entities.face import Face

logger = get_logger(__name__)


class SimpleFPSCounter:
    """ê°„ë‹¨í•œ FPS ì¹´ìš´í„°"""
    
    def __init__(self):
        self.frame_count = 0
        self.start_time = time.time()
        self.fps = 0.0
    
    def tick(self) -> float:
        """í”„ë ˆì„ ì¹´ìš´íŠ¸ ì¦ê°€ ë° FPS ê³„ì‚°"""
        self.frame_count += 1
        elapsed = time.time() - self.start_time
        if elapsed > 1.0:  # 1ì´ˆë§ˆë‹¤ FPS ì—…ë°ì´íŠ¸
            self.fps = self.frame_count / elapsed
            self.frame_count = 0
            self.start_time = time.time()
        return self.fps
    
    def get_fps(self) -> float:
        """í˜„ì¬ FPS ë°˜í™˜"""
        return self.fps


class RealTimeFaceCaptureAndRegister:
    """ì‹¤ì‹œê°„ ì–¼êµ´ ìº¡ì²˜ ë° ë“±ë¡ ì‹œìŠ¤í…œ"""
    
    def __init__(self, camera_id: int = 0):
        """ì´ˆê¸°í™”"""
        self.camera_id = camera_id
        self.camera = None
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.detection_service = FaceDetectionService(
            config={
                'min_confidence': 0.5,
                'min_face_size': (80, 80),
                'max_faces': 5
            }
        )
        self.recognition_service = FaceRecognitionService()
        
        # ìº¡ì²˜ ê´€ë ¨ ì„¤ì •
        self.face_staging = []  # ìº¡ì²˜ëœ ì–¼êµ´ë“¤
        self.current_frame = None
        self.current_detections = []
        
        # UI ìƒíƒœ
        self.fps_counter = SimpleFPSCounter()
        self.show_help = True
        self.capture_mode = False  # Trueì´ë©´ ìº¡ì²˜ ëª¨ë“œ
        self.selected_person_name = None
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬
        self.output_dir = Path("data/temp/face_staging")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def initialize_camera(self) -> bool:
        """ì¹´ë©”ë¼ ì´ˆê¸°í™”"""
        try:
            logger.info(f"ğŸ“¹ ì¹´ë©”ë¼ {self.camera_id} ì´ˆê¸°í™” ì¤‘...")
            
            self.camera = cv2.VideoCapture(self.camera_id)
            
            if not self.camera.isOpened():
                logger.error(f"âŒ ì¹´ë©”ë¼ {self.camera_id} ì—´ê¸° ì‹¤íŒ¨")
                return False
            
            # ì¹´ë©”ë¼ ì„¤ì •
            self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.camera.set(cv2.CAP_PROP_FPS, 30)
            
            logger.info("âœ… ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            return False
    
    def get_person_name(self) -> Optional[str]:
        """ì‚¬ìš©ìë¡œë¶€í„° ì¸ë¬¼ ì´ë¦„ ì…ë ¥ë°›ê¸°"""
        print("\n" + "="*50)
        print("ğŸ§‘â€ğŸ’¼ ìƒˆë¡œìš´ ì¸ë¬¼ ë“±ë¡")
        print("="*50)
        
        while True:
            name = input("ë“±ë¡í•  ì¸ë¬¼ì˜ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (ì·¨ì†Œ: 'cancel'): ").strip()
            
            if name.lower() == 'cancel':
                return None
            
            if not name:
                print("âŒ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue
            
            if len(name) < 2:
                print("âŒ ì´ë¦„ì€ ìµœì†Œ 2ê¸€ì ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
                continue
            
            # ê¸°ì¡´ ì¸ë¬¼ê³¼ ì¤‘ë³µ í™•ì¸
            try:
                existing_persons = self.recognition_service.get_all_persons()
                existing_names = [p.name for p in existing_persons]
                
                if name in existing_names:
                    print(f"âŒ '{name}'ì€ ì´ë¯¸ ë“±ë¡ëœ ì¸ë¬¼ì…ë‹ˆë‹¤.")
                    print(f"ê¸°ì¡´ ë“±ë¡ëœ ì¸ë¬¼ë“¤: {', '.join(existing_names)}")
                    continue
            except Exception as e:
                logger.warning(f"ê¸°ì¡´ ì¸ë¬¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            
            confirm = input(f"'{name}'ìœ¼ë¡œ ë“±ë¡í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
            if confirm in ['y', 'yes']:
                return name
    
    def process_frame(self, frame: np.ndarray) -> np.ndarray:
        """í”„ë ˆì„ ì²˜ë¦¬ ë° UI ê·¸ë¦¬ê¸°"""
        self.current_frame = frame.copy()
        
        # ì–¼êµ´ ê²€ì¶œ
        try:
            detection_result = self.detection_service.detect_faces(frame)
            self.current_detections = detection_result.faces
        except Exception as e:
            logger.error(f"ì–¼êµ´ ê²€ì¶œ ì˜¤ë¥˜: {str(e)}")
            self.current_detections = []
        
        # í™”ë©´ì— ê·¸ë¦¬ê¸°
        display_frame = frame.copy()
        
        # ê²€ì¶œëœ ì–¼êµ´ë“¤ í‘œì‹œ
        for i, face in enumerate(self.current_detections):
            x, y, w, h = face.bbox.x, face.bbox.y, face.bbox.width, face.bbox.height
            
            # ìƒ‰ìƒ ê²°ì •
            if self.capture_mode:
                color = (0, 255, 255)  # ë…¸ë€ìƒ‰ - ìº¡ì²˜ ëª¨ë“œ
                thickness = 3
            else:
                color = (0, 255, 0)    # ì´ˆë¡ìƒ‰ - ì¼ë°˜ ëª¨ë“œ
                thickness = 2
            
            # ë°”ìš´ë”© ë°•ìŠ¤
            cv2.rectangle(display_frame, (x, y), (x + w, y + h), color, thickness)
            
            # ë¼ë²¨
            label = f"Face {i+1}: {face.confidence.value:.2f}"
            if self.capture_mode:
                label = f"[CAPTURE] {label}"
            
            # ë¼ë²¨ ë°°ê²½
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
            cv2.rectangle(display_frame, (x, y - label_size[1] - 10), 
                         (x + label_size[0], y), color, -1)
            
            # ë¼ë²¨ í…ìŠ¤íŠ¸
            cv2.putText(display_frame, label, (x, y - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
            
            # ë²ˆí˜¸ í‘œì‹œ (ìº¡ì²˜ ëª¨ë“œì—ì„œ)
            if self.capture_mode:
                cv2.putText(display_frame, str(i+1), (x + w//2 - 10, y + h//2), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 3)
        
        # ì •ë³´ ì˜¤ë²„ë ˆì´
        self._draw_info_overlay(display_frame)
        
        return display_frame
    
    def _draw_info_overlay(self, frame: np.ndarray):
        """ì •ë³´ ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸°"""
        height, width = frame.shape[:2]
        
        # FPS í‘œì‹œ
        fps = self.fps_counter.get_fps()
        cv2.putText(frame, f"FPS: {fps:.1f}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # ì–¼êµ´ ìˆ˜ í‘œì‹œ
        face_count = len(self.current_detections)
        cv2.putText(frame, f"Faces: {face_count}", (10, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # ëª¨ë“œ í‘œì‹œ
        if self.capture_mode:
            mode_text = f"CAPTURE MODE: {self.selected_person_name}"
            cv2.putText(frame, mode_text, (10, 90), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            
            # ìº¡ì²˜ ì•ˆë‚´
            cv2.putText(frame, "Press 1-9 to capture face, ESC to exit capture mode", 
                       (10, height - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        else:
            cv2.putText(frame, "Normal Mode", (10, 90), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # ë„ì›€ë§ í‘œì‹œ
        if self.show_help:
            help_lines = [
                "Controls:",
                "c: Enter capture mode",
                "h: Toggle help",
                "q: Quit",
                "Space: Pause"
            ]
            
            for i, line in enumerate(help_lines):
                y_pos = height - 150 + (i * 25)
                cv2.putText(frame, line, (10, y_pos), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    
    def enter_capture_mode(self):
        """ìº¡ì²˜ ëª¨ë“œ ì§„ì…"""
        if not self.current_detections:
            print("âŒ ê²€ì¶œëœ ì–¼êµ´ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì¸ë¬¼ ì´ë¦„ ì…ë ¥
        person_name = self.get_person_name()
        if not person_name:
            print("âŒ ìº¡ì²˜ ëª¨ë“œ ì·¨ì†Œë¨")
            return
        
        self.selected_person_name = person_name
        self.capture_mode = True
        self.show_help = False
        
        print(f"\nâœ… ìº¡ì²˜ ëª¨ë“œ í™œì„±í™” - ëŒ€ìƒ: {person_name}")
        print("ğŸ“· 1-9ë²ˆ í‚¤ë¥¼ ëˆŒëŸ¬ í•´ë‹¹ ë²ˆí˜¸ì˜ ì–¼êµ´ì„ ìº¡ì²˜í•˜ì„¸ìš”")
        print("ğŸšª ESC í‚¤ë¡œ ìº¡ì²˜ ëª¨ë“œ ì¢…ë£Œ")
    
    def capture_face(self, face_index: int) -> bool:
        """íŠ¹ì • ì–¼êµ´ ìº¡ì²˜ ë° ë“±ë¡"""
        if not self.capture_mode or not self.current_detections:
            return False
        
        if face_index >= len(self.current_detections):
            print(f"âŒ ì–¼êµ´ ë²ˆí˜¸ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. (1-{len(self.current_detections)} ì‚¬ìš©)")
            return False
        
        try:
            face = self.current_detections[face_index]
            x, y, w, h = face.bbox.x, face.bbox.y, face.bbox.width, face.bbox.height
            
            # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
            face_image = self.current_frame[y:y+h, x:x+w]
            
            # í’ˆì§ˆ ê²€ì‚¬
            if face_image.size == 0 or min(face_image.shape[:2]) < 80:
                print("âŒ ì–¼êµ´ ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ì‘ê±°ë‚˜ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤.")
                return False
            
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            timestamp = int(time.time())
            temp_filename = f"captured_{self.selected_person_name}_{timestamp}.jpg"
            temp_path = self.output_dir / temp_filename
            
            cv2.imwrite(str(temp_path), face_image)
            
            # ì¸ë¬¼ ë“±ë¡ ë˜ëŠ” ì–¼êµ´ ì¶”ê°€
            person = self.register_face_to_person(str(temp_path), self.selected_person_name)
            
            if person:
                print(f"âœ… ì–¼êµ´ ë“±ë¡ ì„±ê³µ: {self.selected_person_name}")
                print(f"   ì €ì¥ ìœ„ì¹˜: {temp_path}")
                
                # ë“±ë¡ëœ ì–¼êµ´ ìˆ˜ í‘œì‹œ
                person_faces = self.recognition_service.face_repository.find_faces_by_person(person.person_id)
                print(f"   ì´ ë“±ë¡ëœ ì–¼êµ´ ìˆ˜: {len(person_faces)}")
                
                return True
            else:
                print("âŒ ì–¼êµ´ ë“±ë¡ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            logger.error(f"ì–¼êµ´ ìº¡ì²˜ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            print(f"âŒ ì–¼êµ´ ìº¡ì²˜ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def register_face_to_person(self, image_path: str, person_name: str) -> Optional[Person]:
        """ì–¼êµ´ì„ ì¸ë¬¼ì— ë“±ë¡"""
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = cv2.imread(image_path)
            if image is None:
                print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
                return None
            
            # ì„ë² ë”© ì¶”ì¶œ
            embedding = self.recognition_service.extract_embedding(image)
            
            # ê¸°ì¡´ ì¸ë¬¼ í™•ì¸ ë˜ëŠ” ìƒˆ ì¸ë¬¼ ìƒì„±
            existing_persons = self.recognition_service.person_repository.list_all_persons()
            person = None
            
            for p in existing_persons:
                if p.name == person_name:
                    person = p
                    break
            
            if not person:
                # ìƒˆ ì¸ë¬¼ ìƒì„±
                person = Person(name=person_name)
                saved_person = self.recognition_service.person_repository.save(person)
                person = saved_person
            
            # ì–¼êµ´ ì—”í‹°í‹° ìƒì„±
            face = Face(
                face_id=str(uuid.uuid4()),
                person_id=person.person_id,
                embedding=embedding,
                image_path=image_path,
                quality_score=0.8  # ì„ì‹œ í’ˆì§ˆ ì ìˆ˜
            )
            
            # ì–¼êµ´ ì €ì¥
            saved_face = self.recognition_service.face_repository.save(face)
            
            return person
            
        except Exception as e:
            logger.error(f"ì–¼êµ´ ë“±ë¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def exit_capture_mode(self):
        """ìº¡ì²˜ ëª¨ë“œ ì¢…ë£Œ"""
        self.capture_mode = False
        self.selected_person_name = None
        self.show_help = True
        print("\nğŸšª ìº¡ì²˜ ëª¨ë“œ ì¢…ë£Œ")
    
    def handle_key_input(self, key: int) -> str:
        """í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬"""
        if key == ord('q'):
            return 'quit'
        elif key == ord('h'):
            self.show_help = not self.show_help
            return 'toggle_help'
        elif key == ord('c') and not self.capture_mode:
            self.enter_capture_mode()
            return 'enter_capture'
        elif key == 27:  # ESC
            if self.capture_mode:
                self.exit_capture_mode()
            return 'exit_capture'
        elif self.capture_mode and ord('1') <= key <= ord('9'):
            face_index = key - ord('1')  # 0-based index
            success = self.capture_face(face_index)
            return 'capture_face' if success else 'capture_failed'
        elif key == ord(' '):
            return 'pause'
        
        return None
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
        if not self.initialize_camera():
            return False
        
        print("\n" + "="*60)
        print("ğŸ¥ ì‹¤ì‹œê°„ ì–¼êµ´ ìº¡ì²˜ ë° ë“±ë¡ ì‹œìŠ¤í…œ")
        print("="*60)
        print("ğŸ“‹ ì‚¬ìš©ë²•:")
        print("  c: ìº¡ì²˜ ëª¨ë“œ ì§„ì… (ì¸ë¬¼ ì´ë¦„ ì…ë ¥ í›„ ì–¼êµ´ ì„ íƒ)")
        print("  h: ë„ì›€ë§ í‘œì‹œ/ìˆ¨ê¹€")
        print("  q: í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
        print("="*60)
        
        try:
            paused = False
            
            while True:
                if not paused:
                    ret, frame = self.camera.read()
                    if not ret:
                        logger.warning("í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                        continue
                    
                    # í”„ë ˆì„ ì²˜ë¦¬
                    display_frame = self.process_frame(frame)
                    
                    # FPS ì—…ë°ì´íŠ¸
                    self.fps_counter.tick()
                else:
                    # ì¼ì‹œì •ì§€ ìƒíƒœì—ì„œëŠ” ë§ˆì§€ë§‰ í”„ë ˆì„ ìœ ì§€
                    display_frame = self.current_frame if self.current_frame is not None else frame
                
                # í™”ë©´ í‘œì‹œ
                cv2.imshow('Face Capture & Register', display_frame)
                
                # í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                if key != 255:
                    action = self.handle_key_input(key)
                    
                    if action == 'quit':
                        break
                    elif action == 'pause':
                        paused = not paused
                        print(f"â¸ï¸ {'ì¼ì‹œì •ì§€' if paused else 'ì¬ìƒ'}")
        
        except KeyboardInterrupt:
            print("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        except Exception as e:
            logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        finally:
            self.cleanup()
        
        return True
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        logger.info("ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
        
        if self.camera is not None:
            self.camera.release()
        
        cv2.destroyAllWindows()
        
        print("\nâœ… í”„ë¡œê·¸ë¨ ì¢…ë£Œ")


def parse_args():
    """ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(description="ì‹¤ì‹œê°„ ì–¼êµ´ ìº¡ì²˜ ë° ë“±ë¡ ì‹œìŠ¤í…œ")
    parser.add_argument("--camera", type=int, default=0, help="ì¹´ë©”ë¼ ID (ê¸°ë³¸ê°’: 0)")
    parser.add_argument("--verbose", "-v", action="store_true", help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")
    
    return parser.parse_args()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    args = parse_args()
    
    # ë¡œê¹… ì„¤ì •
    setup_logging(level="DEBUG" if args.verbose else "INFO")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs("data/temp/face_staging", exist_ok=True)
    os.makedirs("data/output", exist_ok=True)
    
    try:
        # ìº¡ì²˜ ì‹œìŠ¤í…œ ì‹¤í–‰
        capture_system = RealTimeFaceCaptureAndRegister(camera_id=args.camera)
        success = capture_system.run()
        
        return 0 if success else 1
        
    except Exception as e:
        logger.error(f"ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return 1


if __name__ == "__main__":
    sys.exit(main()) 