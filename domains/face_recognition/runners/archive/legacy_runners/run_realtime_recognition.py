#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì‹¤ì‹œê°„ ì–¼êµ´ì¸ì‹ ì‹œìŠ¤í…œ.

ì›¹ìº ì„ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì–¼êµ´ì„ ê²€ì¶œí•˜ê³  ì¸ì‹í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
"""

import cv2
import numpy as np
import argparse
import time
import sys
import os
from pathlib import Path
from typing import List, Dict, Optional, Tuple

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent.parent.parent
sys.path.append(str(project_root))

# í•˜ë“œì›¨ì–´ ê²€ì¦ ì„í¬íŠ¸
from scripts.core.validation.validate_hardware_connection import validate_hardware_for_runtime

from domains.face_recognition.core.services.face_recognition_service import FaceRecognitionService
from domains.face_recognition.core.services.face_detection_service import FaceDetectionService
from shared.vision_core.detection.face_detector import FaceDetector
from common.logging import setup_logging, get_logger

# ë¡œê¹… ì„¤ì •
setup_logging()
logger = get_logger(__name__)


class RealTimeFaceRecognition:
    """ì‹¤ì‹œê°„ ì–¼êµ´ì¸ì‹ ì‹œìŠ¤í…œ"""
    
    def __init__(self, 
                 camera_id: int = 0,
                 detection_confidence: float = 0.5,
                 recognition_threshold: float = 0.6):
        """
        ì´ˆê¸°í™”
        
        Args:
            camera_id: ì¹´ë©”ë¼ ID
            detection_confidence: ê²€ì¶œ ì‹ ë¢°ë„ ì„ê³„ê°’
            recognition_threshold: ì¸ì‹ ì‹ ë¢°ë„ ì„ê³„ê°’
        """
        self.camera_id = camera_id
        self.detection_confidence = detection_confidence
        self.recognition_threshold = recognition_threshold
        
        # ğŸ”§ í•˜ë“œì›¨ì–´ ê²€ì¦ (í•„ìˆ˜)
        if not self._validate_hardware():
            raise RuntimeError("í•˜ë“œì›¨ì–´ ê²€ì¦ ì‹¤íŒ¨. ì‹¤ì œ ì¹´ë©”ë¼ë¥¼ ì—°ê²°í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.detection_service = FaceDetectionService()
        self.recognition_service = FaceRecognitionService()
        
        # ê²€ì¶œê¸° ì´ˆê¸°í™”
        self.detector = FaceDetector(
            detector_type="opencv",
            confidence_threshold=detection_confidence
        )
        
        # ì„±ëŠ¥ ì¶”ì 
        self.fps_counter = FPSCounter()
        self.frame_count = 0
        
        # ìƒíƒœ
        self.is_running = False
        self.camera = None
        self.show_info = True
        self.recording = False
        
        logger.info("ì‹¤ì‹œê°„ ì–¼êµ´ì¸ì‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _validate_hardware(self) -> bool:
        """í•˜ë“œì›¨ì–´ ê²€ì¦"""
        logger.info("ğŸ” í•˜ë“œì›¨ì–´ ì—°ê²° ìƒíƒœ ê²€ì¦ ì¤‘...")
        
        # ì‹œë®¬ë ˆì´ì…˜ ë°©ì§€ ì²´í¬
        if os.environ.get("USE_SIMULATION", "False").lower() in ["true", "1", "yes"]:
            logger.error("âŒ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œëŠ” ê¸ˆì§€ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            return False
        
        if os.environ.get("USE_MOCK", "False").lower() in ["true", "1", "yes"]:
            logger.error("âŒ Mock ëª¨ë“œëŠ” ì‹¤í–‰ ì‹œ ê¸ˆì§€ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            return False
        
        # í•˜ë“œì›¨ì–´ ê²€ì¦ ì‹¤í–‰
        validation_result = validate_hardware_for_runtime()
        
        if not validation_result:
            logger.error("âŒ í•˜ë“œì›¨ì–´ ê²€ì¦ ì‹¤íŒ¨")
            return False
        
        logger.info("âœ… í•˜ë“œì›¨ì–´ ê²€ì¦ ì™„ë£Œ")
        return True
    
    def initialize_camera(self) -> bool:
        """ì¹´ë©”ë¼ ì´ˆê¸°í™”"""
        try:
            logger.info(f"ğŸ“¹ ì¹´ë©”ë¼ {self.camera_id} ì´ˆê¸°í™” ì¤‘...")
            
            self.camera = cv2.VideoCapture(self.camera_id)
            
            if not self.camera.isOpened():
                logger.error(f"âŒ ì¹´ë©”ë¼ {self.camera_id} ì—´ê¸° ì‹¤íŒ¨")
                return False
            
            # ì¹´ë©”ë¼ ì„¤ì •
            self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.camera.set(cv2.CAP_PROP_FPS, 30)
            
            # ì¹´ë©”ë¼ í…ŒìŠ¤íŠ¸
            ret, test_frame = self.camera.read()
            if not ret or test_frame is None:
                logger.error("âŒ ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            if test_frame.shape[0] < 100 or test_frame.shape[1] < 100:
                logger.error(f"âŒ ì¹´ë©”ë¼ í•´ìƒë„ê°€ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤: {test_frame.shape}")
                return False
            
            logger.info(f"âœ… ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ - í•´ìƒë„: {test_frame.shape}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            return False
    
    def process_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, List[Dict]]:
        """
        í”„ë ˆì„ ì²˜ë¦¬
        
        Args:
            frame: ì…ë ¥ í”„ë ˆì„
            
        Returns:
            Tuple[np.ndarray, List[Dict]]: (ì²˜ë¦¬ëœ í”„ë ˆì„, ì¸ì‹ ê²°ê³¼)
        """
        results = []
        
        try:
            # ì–¼êµ´ ê²€ì¶œ
            detection_result = self.detection_service.detect_faces(frame)
            
            for face in detection_result.faces:
                # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
                face_region = self._extract_face_region(frame, face.bbox)
                
                # ì–¼êµ´ ì¸ì‹
                if face_region is not None and face_region.size > 0:
                    # ì„ë² ë”© ì¶”ì¶œ
                    embedding = self.recognition_service.extract_embedding(face_region)
                    face.embedding = embedding
                    
                    # ì¸ë¬¼ ì‹ë³„
                    identified_person = self.recognition_service.identify_face(face)
                    
                    # ê²°ê³¼ ì €ì¥
                    result = {
                        'face': face,
                        'person': identified_person,
                        'face_region': face_region
                    }
                    results.append(result)
            
            # í”„ë ˆì„ì— ê²°ê³¼ ê·¸ë¦¬ê¸°
            annotated_frame = self._draw_results(frame, results)
            
            return annotated_frame, results
            
        except Exception as e:
            logger.error(f"í”„ë ˆì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return frame, []
    
    def _extract_face_region(self, frame: np.ndarray, bbox: List[int]) -> Optional[np.ndarray]:
        """ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ"""
        try:
            x, y, w, h = bbox
            
            # ë§ˆì§„ ì¶”ê°€ (20%)
            margin = 0.2
            margin_x = int(w * margin)
            margin_y = int(h * margin)
            
            # í™•ì¥ëœ ì˜ì—­ ê³„ì‚°
            x1 = max(0, x - margin_x)
            y1 = max(0, y - margin_y)
            x2 = min(frame.shape[1], x + w + margin_x)
            y2 = min(frame.shape[0], y + h + margin_y)
            
            # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
            face_region = frame[y1:y2, x1:x2]
            
            if face_region.size == 0:
                return None
            
            return face_region
            
        except Exception as e:
            logger.warning(f"ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def _draw_results(self, frame: np.ndarray, results: List[Dict]) -> np.ndarray:
        """ê²°ê³¼ë¥¼ í”„ë ˆì„ì— ê·¸ë¦¬ê¸°"""
        annotated_frame = frame.copy()
        
        for result in results:
            face = result['face']
            person = result['person']
            
            x, y, w, h = face.bbox
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ìƒ‰ìƒ ê²°ì •
            if person is not None:
                color = (0, 255, 0)  # ì´ˆë¡ìƒ‰ - ì¸ì‹ë¨
                label = f"{person.name} ({face.confidence:.2f})"
            else:
                color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ - ë¯¸ì¸ì‹
                label = f"Unknown ({face.confidence:.2f})"
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(annotated_frame, (x, y), (x + w, y + h), color, 2)
            
            # ë¼ë²¨ ë°°ê²½ ê·¸ë¦¬ê¸°
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
            cv2.rectangle(annotated_frame, (x, y - label_size[1] - 10), 
                         (x + label_size[0], y), color, -1)
            
            # ë¼ë²¨ í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
            cv2.putText(annotated_frame, label, (x, y - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # ì •ë³´ ì˜¤ë²„ë ˆì´
        if self.show_info:
            annotated_frame = self._draw_info_overlay(annotated_frame, len(results))
        
        return annotated_frame
    
    def _draw_info_overlay(self, frame: np.ndarray, face_count: int) -> np.ndarray:
        """ì •ë³´ ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸°"""
        height, width = frame.shape[:2]
        
        # FPS í‘œì‹œ
        current_fps = self.fps_counter.get_fps()
        fps_text = f"FPS: {current_fps:.1f}"
        cv2.putText(frame, fps_text, (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # ì–¼êµ´ ìˆ˜ í‘œì‹œ
        face_text = f"Faces: {face_count}"
        cv2.putText(frame, face_text, (10, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # í”„ë ˆì„ ì¹´ìš´íŠ¸ í‘œì‹œ
        frame_text = f"Frame: {self.frame_count}"
        cv2.putText(frame, frame_text, (10, 90), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # ë„ì›€ë§ í‘œì‹œ
        help_text = "Press 'h' for help, 'q' to quit"
        help_size = cv2.getTextSize(help_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
        cv2.putText(frame, help_text, (width - help_size[0] - 10, height - 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        return frame
    
    def handle_key_input(self, key: int) -> str:
        """í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬"""
        if key == ord('q'):
            return 'quit'
        elif key == ord('i'):
            self.show_info = not self.show_info
            logger.info(f"ì •ë³´ í‘œì‹œ: {'ON' if self.show_info else 'OFF'}")
            return 'toggle_info'
        elif key == ord('s'):
            timestamp = int(time.time())
            filename = f"data/output/capture_{timestamp}.jpg"
            return 'save_frame'
        elif key == ord('r'):
            self.recording = not self.recording
            logger.info(f"ë…¹í™”: {'ì‹œì‘' if self.recording else 'ì¤‘ì§€'}")
            return 'toggle_record'
        elif key == ord('h'):
            return 'show_help'
        return None
    
    def show_help(self):
        """ë„ì›€ë§ í‘œì‹œ"""
        print("\n" + "="*50)
        print("ğŸ“‹ ì‹¤ì‹œê°„ ì–¼êµ´ì¸ì‹ ì‹œìŠ¤í…œ ë‹¨ì¶•í‚¤")
        print("="*50)
        print("q: í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
        print("i: ì •ë³´ í‘œì‹œ í† ê¸€")
        print("s: í˜„ì¬ í”„ë ˆì„ ì €ì¥")
        print("r: ë…¹í™” ì‹œì‘/ì¤‘ì§€")
        print("h: ì´ ë„ì›€ë§ í‘œì‹œ")
        print("="*50 + "\n")
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
        if not self.initialize_camera():
            logger.error("ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨")
            return
        
        logger.info("ğŸš€ ì‹¤ì‹œê°„ ì–¼êµ´ì¸ì‹ ì‹œì‘")
        logger.info("Press 'h' for help, 'q' to quit")
        
        self.is_running = True
        
        try:
            while self.is_running:
                ret, frame = self.camera.read()
                
                if not ret:
                    logger.warning("í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                    break
                
                # í”„ë ˆì„ ì²˜ë¦¬
                processed_frame, results = self.process_frame(frame)
                
                # í”„ë ˆì„ í‘œì‹œ
                cv2.imshow('Real-time Face Recognition', processed_frame)
                
                # FPS ì¹´ìš´í„° ì—…ë°ì´íŠ¸
                self.fps_counter.tick()
                self.frame_count += 1
                
                # í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                if key != 255:  # í‚¤ê°€ ëˆŒë ¸ì„ ë•Œ
                    action = self.handle_key_input(key)
                    
                    if action == 'quit':
                        break
                    elif action == 'show_help':
                        self.show_help()
                    elif action == 'save_frame':
                        timestamp = int(time.time())
                        filename = f"data/output/capture_{timestamp}.jpg"
                        cv2.imwrite(filename, processed_frame)
                        logger.info(f"í”„ë ˆì„ ì €ì¥: {filename}")
                
        except KeyboardInterrupt:
            logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        except Exception as e:
            logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        finally:
            self.cleanup()
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        logger.info("ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
        
        if self.camera is not None:
            self.camera.release()
        
        cv2.destroyAllWindows()
        
        logger.info("âœ… ì •ë¦¬ ì™„ë£Œ")


class FPSCounter:
    """FPS ì¹´ìš´í„°"""
    
    def __init__(self, window_size: int = 30):
        self.window_size = window_size
        self.timestamps = []
    
    def tick(self) -> float:
        """FPS ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸"""
        current_time = time.time()
        self.timestamps.append(current_time)
        
        # ìœˆë„ìš° í¬ê¸° ìœ ì§€
        if len(self.timestamps) > self.window_size:
            self.timestamps.pop(0)
        
        return self.get_fps()
    
    def get_fps(self) -> float:
        """í˜„ì¬ FPS ë°˜í™˜"""
        if len(self.timestamps) < 2:
            return 0.0
        
        time_span = self.timestamps[-1] - self.timestamps[0]
        if time_span == 0:
            return 0.0
        
        return (len(self.timestamps) - 1) / time_span


def parse_args():
    """ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(description="ì‹¤ì‹œê°„ ì–¼êµ´ì¸ì‹ ì‹œìŠ¤í…œ")
    parser.add_argument("--camera", type=int, default=0, help="ì¹´ë©”ë¼ ID (ê¸°ë³¸ê°’: 0)")
    parser.add_argument("--detection-conf", type=float, default=0.5, help="ê²€ì¶œ ì‹ ë¢°ë„ (ê¸°ë³¸ê°’: 0.5)")
    parser.add_argument("--recognition-threshold", type=float, default=0.6, help="ì¸ì‹ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.6)")
    parser.add_argument("--no-hardware-check", action="store_true", help="í•˜ë“œì›¨ì–´ ê²€ì¦ ê±´ë„ˆë›°ê¸° (ê°œë°œìš©)")
    
    return parser.parse_args()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    args = parse_args()
    
    print("=" * 60)
    print("ğŸ¥ ì‹¤ì‹œê°„ ì–¼êµ´ì¸ì‹ ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    # ê°œë°œìš© ì˜µì…˜ì´ ì•„ë‹Œ ê²½ìš° í•˜ë“œì›¨ì–´ ê²€ì¦ í•„ìˆ˜
    if not args.no_hardware_check:
        logger.info("ğŸ” í•˜ë“œì›¨ì–´ ê²€ì¦ ìˆ˜í–‰ ì¤‘...")
        if not validate_hardware_for_runtime():
            logger.error("âŒ í•˜ë“œì›¨ì–´ ê²€ì¦ ì‹¤íŒ¨. ì‹¤ì œ ì¹´ë©”ë¼ë¥¼ ì—°ê²°í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            return 1
    
    try:
        # ì‹¤ì‹œê°„ ì–¼êµ´ì¸ì‹ ì‹œìŠ¤í…œ ì‹œì‘
        system = RealTimeFaceRecognition(
            camera_id=args.camera,
            detection_confidence=args.detection_conf,
            recognition_threshold=args.recognition_threshold
        )
        
        system.run()
        
        logger.info("âœ… í”„ë¡œê·¸ë¨ ì •ìƒ ì¢…ë£Œ")
        return 0
        
    except Exception as e:
        logger.error(f"âŒ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code) 