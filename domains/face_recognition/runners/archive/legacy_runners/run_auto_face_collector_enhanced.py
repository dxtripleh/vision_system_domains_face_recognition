#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
í–¥ìƒëœ ìë™ ì–¼êµ´ ìˆ˜ì§‘ê¸°

ì¹´ë©”ë¼ë¡œ ì–¼êµ´ì„ ìë™ ê²€ì¶œí•˜ì—¬ ìˆ˜ì§‘í•˜ê³ , ìœ ì‚¬í•œ ì–¼êµ´ë“¤ì„ ìë™ ê·¸ë£¹í•‘í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
"""

import os
import sys
import cv2
import time
import uuid
import json
import numpy as np
from pathlib import Path
from datetime import datetime
from collections import defaultdict

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent.parent.parent
sys.path.append(str(project_root))

from common.logging import setup_logging
from domains.face_recognition.infrastructure.detection_engines.opencv_detection_engine import OpenCVDetectionEngine
from domains.face_recognition.infrastructure.models.arcface_recognizer import ArcFaceRecognizer
from shared.vision_core.utils.fps_counter import FPSCounter

class AutoFaceCollector:
    """í–¥ìƒëœ ìë™ ì–¼êµ´ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.logger = setup_logging()
        
        # AI ëª¨ë¸ ì´ˆê¸°í™”
        self.detector = OpenCVDetectionEngine()
        self.recognizer = ArcFaceRecognizer()
        self.fps_counter = FPSCounter()
        
        # ì €ì¥ ê²½ë¡œ ì„¤ì •
        self.auto_collected_dir = project_root / 'data' / 'temp' / 'auto_collected'
        self.face_staging_dir = project_root / 'data' / 'temp' / 'face_staging'
        self.auto_collected_dir.mkdir(parents=True, exist_ok=True)
        self.face_staging_dir.mkdir(parents=True, exist_ok=True)
        
        # ìˆ˜ì§‘ ì„¤ì •
        self.collection_interval = 2.0  # 2ì´ˆë§ˆë‹¤ ìˆ˜ì§‘
        self.last_collection_time = 0
        self.collected_faces = []
        self.face_groups = defaultdict(list)
        self.group_counter = 0
        
        # ê·¸ë£¹í•‘ ì„¤ì •
        self.similarity_threshold = 0.6  # ìœ ì‚¬ë„ ì„ê³„ê°’
        self.min_group_size = 3  # ìµœì†Œ ê·¸ë£¹ í¬ê¸°
        
        self.logger.info("ìë™ ì–¼êµ´ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def start_collection(self, camera_id: int = 0, duration_minutes: int = 5):
        """ìë™ ìˆ˜ì§‘ ì‹œì‘"""
        # ì¹´ë©”ë¼ ì´ˆê¸°í™”
        cap = cv2.VideoCapture(camera_id)
        if not cap.isOpened():
            self.logger.error(f"ì¹´ë©”ë¼ {camera_id}ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        # ì¹´ë©”ë¼ ì„¤ì •
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv2.CAP_PROP_FPS, 30)
        
        start_time = time.time()
        end_time = start_time + (duration_minutes * 60)
        
        self.logger.info(f"ìë™ ìˆ˜ì§‘ ì‹œì‘ ({duration_minutes}ë¶„ê°„)")
        self._show_instructions(duration_minutes)
        
        try:
            while time.time() < end_time:
                ret, frame = cap.read()
                if not ret:
                    self.logger.error("í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    break
                
                current_time = time.time()
                
                # ì£¼ê¸°ì  ì–¼êµ´ ìˆ˜ì§‘
                if current_time - self.last_collection_time > self.collection_interval:
                    self._collect_faces_from_frame(frame)
                    self.last_collection_time = current_time
                
                # í™”ë©´ í‘œì‹œ
                display_frame = self._create_display_frame(frame, end_time - current_time)
                cv2.imshow('Auto Face Collector', display_frame)
                
                # í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('g'):
                    self._start_grouping_process()
                    
        except KeyboardInterrupt:
            self.logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        finally:
            cap.release()
            cv2.destroyAllWindows()
            
            # ìˆ˜ì§‘ ì™„ë£Œ í›„ ìë™ ê·¸ë£¹í•‘
            if self.collected_faces:
                self._start_grouping_process()
            
            self.logger.info("ìë™ ìˆ˜ì§‘ ì¢…ë£Œ")
    
    def _show_instructions(self, duration_minutes):
        """ì‚¬ìš©ë²• ì•ˆë‚´"""
        print("\n" + "="*60)
        print("ğŸ¤– ìë™ ì–¼êµ´ ìˆ˜ì§‘ê¸°")
        print("="*60)
        print(f"â±ï¸  ìˆ˜ì§‘ ì‹œê°„: {duration_minutes}ë¶„")
        print(f"ğŸ“¸ ìˆ˜ì§‘ ê°„ê²©: {self.collection_interval}ì´ˆ")
        print("ğŸ“‹ ì‚¬ìš©ë²•:")
        print("  [G] - ì¦‰ì‹œ ê·¸ë£¹í•‘ ì‹œì‘")
        print("  [Q] - ìˆ˜ì§‘ ì¢…ë£Œ")
        print("="*60)
        print("ğŸ¯ ìë™ìœ¼ë¡œ ì–¼êµ´ì„ ê²€ì¶œí•˜ê³  ìˆ˜ì§‘í•©ë‹ˆë‹¤...")
        print()
    
    def _collect_faces_from_frame(self, frame):
        """í”„ë ˆì„ì—ì„œ ì–¼êµ´ ìˆ˜ì§‘"""
        detections = self.detector.detect_faces(frame)
        
        for detection in detections:
            bbox = detection['bbox']
            confidence = detection['confidence']
            
            # ì‹ ë¢°ë„ê°€ ë†’ì€ ì–¼êµ´ë§Œ ìˆ˜ì§‘
            if confidence < 0.8:
                continue
            
            # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
            face_crop = self._extract_face_crop(frame, bbox)
            if face_crop is None:
                continue
            
            # ì„ë² ë”© ì¶”ì¶œ
            try:
                embedding = self.recognizer.extract_embedding(face_crop)
                if embedding is None:
                    continue
                
                # ìˆ˜ì§‘ëœ ì–¼êµ´ ì •ë³´ ì €ì¥
                face_info = {
                    'timestamp': time.time(),
                    'bbox': bbox,
                    'confidence': confidence,
                    'embedding': embedding.tolist(),
                    'face_crop': face_crop,
                    'id': str(uuid.uuid4())
                }
                
                self.collected_faces.append(face_info)
                
                # íŒŒì¼ë¡œ ì €ì¥
                self._save_collected_face(face_info)
                
                print(f"ğŸ“¸ ì–¼êµ´ ìˆ˜ì§‘: {len(self.collected_faces)}ê°œ (ì‹ ë¢°ë„: {confidence:.2f})")
                
            except Exception as e:
                self.logger.error(f"ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
    
    def _extract_face_crop(self, frame, bbox):
        """ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ"""
        x, y, w, h = bbox
        
        # ì—¬ìœ ë¥¼ ë‘ê³  ìë¥´ê¸°
        margin = 20
        x1 = max(0, x - margin)
        y1 = max(0, y - margin)
        x2 = min(frame.shape[1], x + w + margin)
        y2 = min(frame.shape[0], y + h + margin)
        
        face_crop = frame[y1:y2, x1:x2]
        
        if face_crop.size == 0 or face_crop.shape[0] < 50 or face_crop.shape[1] < 50:
            return None
        
        return face_crop
    
    def _save_collected_face(self, face_info):
        """ìˆ˜ì§‘ëœ ì–¼êµ´ ì €ì¥"""
        timestamp = datetime.fromtimestamp(face_info['timestamp']).strftime("%Y%m%d_%H%M%S_%f")[:-3]
        filename = f"auto_face_{timestamp}_{face_info['id'][:8]}.jpg"
        
        file_path = self.auto_collected_dir / filename
        success = cv2.imwrite(str(file_path), face_info['face_crop'])
        
        if success:
            # ë©”íƒ€ë°ì´í„°ë„ ì €ì¥
            metadata_file = file_path.with_suffix('.json')
            metadata = {
                'id': face_info['id'],
                'timestamp': face_info['timestamp'],
                'bbox': face_info['bbox'],
                'confidence': face_info['confidence'],
                'embedding': face_info['embedding']
            }
            
            with open(metadata_file, 'w') as f:
                json.dump(metadata, f)
        
        return success
    
    def _create_display_frame(self, frame, remaining_time):
        """í™”ë©´ í‘œì‹œìš© í”„ë ˆì„ ìƒì„±"""
        display_frame = frame.copy()
        
        # ì–¼êµ´ ê²€ì¶œ í‘œì‹œ
        detections = self.detector.detect_faces(frame)
        for detection in detections:
            bbox = detection['bbox']
            confidence = detection['confidence']
            
            color = (0, 255, 0) if confidence >= 0.8 else (0, 255, 255)
            cv2.rectangle(display_frame, 
                         (bbox[0], bbox[1]), 
                         (bbox[0] + bbox[2], bbox[1] + bbox[3]), 
                         color, 2)
            
            cv2.putText(display_frame, f"{confidence:.2f}", 
                       (bbox[0], bbox[1] - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        
        # ìƒíƒœ ì •ë³´ í‘œì‹œ
        self._draw_status_info(display_frame, remaining_time)
        
        # FPS í‘œì‹œ
        current_fps = self.fps_counter.tick()
        cv2.putText(display_frame, f"FPS: {current_fps:.1f}", 
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        return display_frame
    
    def _draw_status_info(self, frame, remaining_time):
        """ìƒíƒœ ì •ë³´ ê·¸ë¦¬ê¸°"""
        height, width = frame.shape[:2]
        
        # ë°°ê²½ ë°•ìŠ¤
        cv2.rectangle(frame, (10, height - 100), (400, height - 10), (0, 0, 0), -1)
        cv2.rectangle(frame, (10, height - 100), (400, height - 10), (255, 255, 255), 2)
        
        # ìƒíƒœ í…ìŠ¤íŠ¸
        y_offset = height - 80
        cv2.putText(frame, f"Collected: {len(self.collected_faces)} faces", 
                   (15, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        minutes = int(remaining_time // 60)
        seconds = int(remaining_time % 60)
        cv2.putText(frame, f"Time left: {minutes:02d}:{seconds:02d}", 
                   (15, y_offset + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        cv2.putText(frame, "Press 'G' to group now", 
                   (15, y_offset + 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
    
    def _start_grouping_process(self):
        """ê·¸ë£¹í•‘ í”„ë¡œì„¸ìŠ¤ ì‹œì‘"""
        if len(self.collected_faces) < 2:
            print("âŒ ê·¸ë£¹í•‘í•˜ê¸°ì— ì¶©ë¶„í•œ ì–¼êµ´ì´ ì—†ìŠµë‹ˆë‹¤ (ìµœì†Œ 2ê°œ í•„ìš”)")
            return
        
        print(f"\nğŸ§  {len(self.collected_faces)}ê°œ ì–¼êµ´ ê·¸ë£¹í•‘ ì‹œì‘...")
        
        # ìœ ì‚¬ë„ ê¸°ë°˜ ê·¸ë£¹í•‘
        groups = self._group_faces_by_similarity()
        
        if not groups:
            print("âŒ ê·¸ë£¹í•‘ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        print(f"âœ… {len(groups)}ê°œ ê·¸ë£¹ ìƒì„±ë¨")
        
        # ê·¸ë£¹ë³„ ì²˜ë¦¬
        for group_id, faces in groups.items():
            self._process_face_group(group_id, faces)
    
    def _group_faces_by_similarity(self):
        """ìœ ì‚¬ë„ ê¸°ë°˜ ì–¼êµ´ ê·¸ë£¹í•‘"""
        if not self.collected_faces:
            return {}
        
        # ì„ë² ë”© ë°°ì—´ ìƒì„±
        embeddings = []
        for face in self.collected_faces:
            embeddings.append(np.array(face['embedding']))
        
        embeddings = np.array(embeddings)
        
        # ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
        similarities = np.dot(embeddings, embeddings.T)
        
        # ê·¸ë£¹í•‘
        groups = {}
        used_indices = set()
        group_id = 0
        
        for i in range(len(self.collected_faces)):
            if i in used_indices:
                continue
            
            # ìƒˆ ê·¸ë£¹ ì‹œì‘
            current_group = [i]
            used_indices.add(i)
            
            # ìœ ì‚¬í•œ ì–¼êµ´ë“¤ ì°¾ê¸°
            for j in range(i + 1, len(self.collected_faces)):
                if j in used_indices:
                    continue
                
                if similarities[i][j] >= self.similarity_threshold:
                    current_group.append(j)
                    used_indices.add(j)
            
            # ìµœì†Œ ê·¸ë£¹ í¬ê¸° í™•ì¸
            if len(current_group) >= self.min_group_size:
                groups[f"group_{group_id:03d}"] = [self.collected_faces[idx] for idx in current_group]
                group_id += 1
        
        return groups
    
    def _process_face_group(self, group_id, faces):
        """ê·¸ë£¹ ì²˜ë¦¬ ë° ì´ë¦„ ì…ë ¥"""
        print(f"\nğŸ“Š ê·¸ë£¹ {group_id}: {len(faces)}ê°œ ì–¼êµ´")
        
        # ëŒ€í‘œ ì–¼êµ´ í‘œì‹œ
        representative_face = faces[0]['face_crop']
        cv2.imshow(f'Group {group_id} - Representative Face', representative_face)
        cv2.waitKey(1)
        
        # ì´ë¦„ ì…ë ¥ ë°›ê¸°
        person_name = input(f"ğŸ‘¤ ê·¸ë£¹ {group_id}ì˜ ì¸ë¬¼ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (Enter=ê±´ë„ˆë›°ê¸°): ").strip()
        
        cv2.destroyWindow(f'Group {group_id} - Representative Face')
        
        if not person_name:
            print(f"â­ï¸  ê·¸ë£¹ {group_id} ê±´ë„ˆë›°ê¸°")
            return
        
        # face_stagingìœ¼ë¡œ ì´ë™
        self._move_group_to_staging(group_id, person_name, faces)
    
    def _move_group_to_staging(self, group_id, person_name, faces):
        """ê·¸ë£¹ì„ face_stagingìœ¼ë¡œ ì´ë™"""
        # ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
        safe_name = "".join(c for c in person_name if c.isalnum() or c in (' ', '-', '_')).strip()
        safe_name = safe_name.replace(' ', '_')
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        folder_name = f"{safe_name}_{timestamp}_auto"
        staging_dir = self.face_staging_dir / folder_name
        staging_dir.mkdir(exist_ok=True)
        
        # ë©”íƒ€ë°ì´í„° ìƒì„±
        metadata = {
            'person_name': person_name,
            'safe_name': safe_name,
            'created_at': timestamp,
            'source': 'auto_collector',
            'group_id': group_id,
            'face_count': len(faces),
            'collection_session_id': str(uuid.uuid4())
        }
        
        metadata_file = staging_dir / 'metadata.json'
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        # ì–¼êµ´ë“¤ ë³µì‚¬
        copied_count = 0
        for i, face in enumerate(faces):
            timestamp_str = datetime.fromtimestamp(face['timestamp']).strftime("%Y%m%d_%H%M%S_%f")[:-3]
            filename = f"face_{timestamp_str}_{i:02d}_conf{face['confidence']:.2f}.jpg"
            
            dest_path = staging_dir / filename
            success = cv2.imwrite(str(dest_path), face['face_crop'])
            
            if success:
                copied_count += 1
        
        print(f"âœ… {person_name}: {copied_count}ê°œ ì–¼êµ´ì„ face_stagingìœ¼ë¡œ ì´ë™")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {staging_dir}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ìë™ ì–¼êµ´ ìˆ˜ì§‘ê¸° ì‹œì‘")
    
    # í•˜ë“œì›¨ì–´ ì—°ê²° í™•ì¸
    try:
        test_cap = cv2.VideoCapture(0)
        if not test_cap.isOpened():
            print("âŒ ì¹´ë©”ë¼ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•˜ë“œì›¨ì–´ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return
        test_cap.release()
        print("âœ… ì¹´ë©”ë¼ ì—°ê²° í™•ì¸ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ í•˜ë“œì›¨ì–´ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return
    
    # ìˆ˜ì§‘ ì‹œê°„ ì„¤ì •
    try:
        duration = int(input("ğŸ“… ìˆ˜ì§‘ ì‹œê°„ì„ ë¶„ ë‹¨ìœ„ë¡œ ì…ë ¥í•˜ì„¸ìš” (ê¸°ë³¸ê°’: 5): ") or "5")
        if duration <= 0:
            duration = 5
    except ValueError:
        duration = 5
    
    # ì‹œìŠ¤í…œ ì‹œì‘
    collector = AutoFaceCollector()
    collector.start_collection(duration_minutes=duration)

if __name__ == "__main__":
    main() 