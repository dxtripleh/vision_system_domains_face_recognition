#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ê°„ë‹¨í•œ ì–¼êµ´ ìº¡ì²˜ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸

ìš”ì²­ì‚¬í•­ êµ¬í˜„:
1. ií‚¤ë¡œ ì •ë³´ í† ê¸€ (ì¹´ë©”ë¼, ëª¨ë¸ ì •ë³´ í‘œì‹œ)
2. sí‚¤ë¡œ captured_frames í´ë”ì— ì €ì¥ (ìë™ ì–¼êµ´ ê²€ì¶œ ë° ê·¸ë£¹í•‘)
3. aí‚¤ë¡œ ìë™/ìˆ˜ë™ ëª¨ë“œ ì „í™˜
"""

import os
import sys
import cv2
import time
import json
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent.parent.parent
sys.path.append(str(project_root))

class SimpleFaceCaptureSystem:
    """ê°„ë‹¨í•œ ì–¼êµ´ ìº¡ì²˜ ì‹œìŠ¤í…œ"""
    
    def __init__(self, camera_id: int = 0):
        # ì¹´ë©”ë¼ ì„¤ì •
        self.camera_id = camera_id
        self.cap = None
        
        # ê²½ë¡œ ì„¤ì •
        self.captured_frames_dir = project_root / 'data' / 'temp' / 'captured_frames'
        self.face_staging_dir = project_root / 'data' / 'temp' / 'face_staging'
        
        # í´ë” ìƒì„±
        for directory in [self.captured_frames_dir, self.face_staging_dir]:
            directory.mkdir(parents=True, exist_ok=True)
        
        # ëª¨ë“œ ì„¤ì •
        self.is_auto_mode = False  # ê¸°ë³¸ê°’: ìˆ˜ë™ ëª¨ë“œ
        self.show_info = True
        
        # ì–¼êµ´ ê²€ì¶œê¸° (OpenCV Haar Cascade)
        cascade_path = project_root / 'models' / 'weights' / 'face_detection_opencv_haarcascade_20250628.xml'
        if cascade_path.exists():
            self.face_cascade = cv2.CascadeClassifier(str(cascade_path))
        else:
            # ê¸°ë³¸ OpenCV Haar Cascade ì‚¬ìš©
            self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.fps_counter = 0
        self.fps_timer = time.time()
        self.current_fps = 0
        
        # ìº¡ì²˜ í†µê³„
        self.captured_faces = []
        
        print("âœ… ê°„ë‹¨í•œ ì–¼êµ´ ìº¡ì²˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def start_capture(self):
        """ìº¡ì²˜ ì‹œì‘"""
        print("ğŸš€ ê°„ë‹¨í•œ ì–¼êµ´ ìº¡ì²˜ ì‹œìŠ¤í…œ ì‹œì‘")
        print("="*60)
        
        # í™˜ê²½ ì •ë³´ ì¶œë ¥
        self._print_environment_info()
        
        # ì¹´ë©”ë¼ ì´ˆê¸°í™”
        if not self._initialize_camera():
            return False
        
        print("\nğŸ“¹ ì¹´ë©”ë¼ ì‹œì‘ë¨. í‚¤ë³´ë“œ ëª…ë ¹ì–´:")
        self._print_help()
        
        try:
            # ë©”ì¸ ìº¡ì²˜ ë£¨í”„
            self._capture_loop()
            
        except KeyboardInterrupt:
            print("\nâš ï¸  ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        finally:
            self._cleanup()
        
        return True
    
    def _print_environment_info(self):
        """í™˜ê²½ ì •ë³´ ì¶œë ¥"""
        print(f"ğŸ” í™˜ê²½ ì •ë³´:")
        print(f"   ì¹´ë©”ë¼ ID: {self.camera_id}")
        print(f"   ê²€ì¶œ ëª¨ë¸: OpenCV Haar Cascade")
        print(f"   ëª¨ë“œ: {'ğŸ¤– ìë™' if self.is_auto_mode else 'ğŸ‘¤ ìˆ˜ë™'}")
        print(f"   ì •ë³´ í‘œì‹œ: {'ON' if self.show_info else 'OFF'}")
    
    def _initialize_camera(self) -> bool:
        """ì¹´ë©”ë¼ ì´ˆê¸°í™”"""
        try:
            self.cap = cv2.VideoCapture(self.camera_id, cv2.CAP_DSHOW)
            if not self.cap.isOpened():
                print(f"âŒ ì¹´ë©”ë¼ {self.camera_id} ì—°ê²° ì‹¤íŒ¨")
                return False
            
            # ì¹´ë©”ë¼ ì„¤ì •
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.cap.set(cv2.CAP_PROP_FPS, 30)
            
            # í…ŒìŠ¤íŠ¸ í”„ë ˆì„ ì½ê¸°
            ret, frame = self.cap.read()
            if not ret:
                print("âŒ ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            print(f"âœ… ì¹´ë©”ë¼ {self.camera_id} ì—°ê²° ì„±ê³µ ({frame.shape[1]}x{frame.shape[0]})")
            return True
            
        except Exception as e:
            print(f"âŒ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            return False
    
    def _capture_loop(self):
        """ë©”ì¸ ìº¡ì²˜ ë£¨í”„"""
        while True:
            ret, frame = self.cap.read()
            if not ret:
                print("âŒ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                break
            
            # ì–¼êµ´ ê²€ì¶œ
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(
                gray, 
                scaleFactor=1.1, 
                minNeighbors=5, 
                minSize=(30, 30)
            )
            
            # ê²€ì¶œ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜
            detections = []
            for (x, y, w, h) in faces:
                detections.append({
                    'bbox': (x, y, w, h),
                    'confidence': 0.8  # Haar CascadeëŠ” ì‹ ë¢°ë„ë¥¼ ì œê³µí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ê³ ì •ê°’
                })
            
            # ê²€ì¶œ ê²°ê³¼ ì‹œê°í™”
            display_frame = self._visualize_detections(frame, detections)
            
            # ì •ë³´ ì˜¤ë²„ë ˆì´
            if self.show_info:
                display_frame = self._draw_info_overlay(display_frame, detections)
            
            # ê°„ë‹¨í•œ í‚¤ ì •ë³´ í‘œì‹œ (í•˜ë‹¨)
            display_frame = self._draw_key_info(display_frame)
            
            # í™”ë©´ í‘œì‹œ (ê³ ì •ëœ ì°½ ì´ë¦„ ì‚¬ìš©)
            window_title = "Face Capture System"
            cv2.imshow(window_title, display_frame)
            
            # í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬
            action = self._handle_keyboard_input()
            if action == 'quit':
                break
            elif action == 'save_frame':
                self._save_frame_for_processing(frame, detections)
            elif action == 'capture_face':
                self._capture_face_with_name(frame, detections)
            elif action == 'toggle_info':
                self.show_info = not self.show_info
                print(f"ğŸ’¡ ì •ë³´ í‘œì‹œ: {'ON' if self.show_info else 'OFF'}")
            elif action == 'toggle_mode':
                self._toggle_auto_manual_mode()
            elif action == 'show_help':
                self._print_help()
            
            # FPS ê³„ì‚°
            self._update_fps()
    
    def _visualize_detections(self, frame: np.ndarray, detections: List[Dict]) -> np.ndarray:
        """ê²€ì¶œ ê²°ê³¼ ì‹œê°í™”"""
        display_frame = frame.copy()
        
        for detection in detections:
            x, y, w, h = detection['bbox']
            confidence = detection['confidence']
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ëª¨ë“œì— ë”°ë¼ ìƒ‰ìƒ ë³€ê²½)
            if self.is_auto_mode:
                color = (255, 165, 0)  # ì˜¤ë Œì§€ (ìë™)
            else:
                color = (0, 255, 0)    # ì´ˆë¡ (ìˆ˜ë™)
            
            cv2.rectangle(display_frame, (x, y), (x + w, y + h), color, 2)
            
            # ì‹ ë¢°ë„ í…ìŠ¤íŠ¸
            text = f"{confidence:.2f}"
            cv2.putText(display_frame, text, (x, y - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        
        return display_frame
    
    def _draw_info_overlay(self, frame: np.ndarray, detections: List[Dict]) -> np.ndarray:
        """ì •ë³´ ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸°"""
        # ë°˜íˆ¬ëª… ë°°ê²½
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (400, 120), (0, 0, 0), -1)
        frame = cv2.addWeighted(frame, 0.7, overlay, 0.3, 0)
        
        # ì •ë³´ í…ìŠ¤íŠ¸
        y_offset = 30
        line_height = 18
        
        texts = [
            f"Camera: {self.camera_id} | Model: OpenCV Haar Cascade",
            f"Mode: {'AUTO' if self.is_auto_mode else 'MANUAL'} | FPS: {self.current_fps:.1f}",
            f"Faces: {len(detections)} | Captured: {len(self.captured_faces)}",
        ]
        
        for i, text in enumerate(texts):
            cv2.putText(frame, text, (20, y_offset + i * line_height), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 255, 255), 1)
        
        return frame
    
    def _draw_key_info(self, frame: np.ndarray) -> np.ndarray:
        """ê°„ë‹¨í•œ í‚¤ ì •ë³´ í‘œì‹œ (í•˜ë‹¨)"""
        if not self.show_info:
            return frame
        
        # í•˜ë‹¨ì— ê°„ë‹¨í•œ í‚¤ ì •ë³´ í‘œì‹œ
        height, width = frame.shape[:2]
        
        # ë°˜íˆ¬ëª… ë°°ê²½
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, height - 50), (width - 10, height - 10), (0, 0, 0), -1)
        frame = cv2.addWeighted(frame, 0.8, overlay, 0.2, 0)
        
        # í‚¤ ì •ë³´ í…ìŠ¤íŠ¸
        key_info = "i:Info | a:Auto/Manual | s:Save Frame | c:Capture | h:Help | q:Quit"
        
        cv2.putText(frame, key_info, (20, height - 25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)
        
        return frame
    
    def _handle_keyboard_input(self) -> Optional[str]:
        """í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬"""
        key = cv2.waitKey(1) & 0xFF
        
        if key == ord('q'):
            return 'quit'
        elif key == ord('i'):
            return 'toggle_info'
        elif key == ord('s'):
            return 'save_frame'
        elif key == ord('c'):
            return 'capture_face'
        elif key == ord('a'):
            return 'toggle_mode'
        elif key == ord('h'):
            return 'show_help'
        
        return None
    
    def _toggle_auto_manual_mode(self):
        """ìë™/ìˆ˜ë™ ëª¨ë“œ ì „í™˜"""
        self.is_auto_mode = not self.is_auto_mode
        mode_name = "ìë™" if self.is_auto_mode else "ìˆ˜ë™"
        icon = "ğŸ¤–" if self.is_auto_mode else "ğŸ‘¤"
        
        print(f"{icon} {mode_name} ëª¨ë“œë¡œ ì „í™˜")
        
        if self.is_auto_mode:
            print("   ğŸ’¡ ìë™ ëª¨ë“œ: sí‚¤ë¡œ í”„ë ˆì„ì„ ì €ì¥í•˜ë©´ ìë™ ì²˜ë¦¬ë©ë‹ˆë‹¤")
        else:
            print("   ğŸ’¡ ìˆ˜ë™ ëª¨ë“œ: cí‚¤ë¡œ ì–¼êµ´ì„ ìˆ˜ë™ ìº¡ì²˜í•©ë‹ˆë‹¤")
    
    def _save_frame_for_processing(self, frame: np.ndarray, detections: List[Dict]):
        """í”„ë ˆì„ì„ captured_frames í´ë”ì— ì €ì¥í•˜ê³  ìë™ ì²˜ë¦¬"""
        if not detections:
            print("âš ï¸  ì €ì¥í•  ì–¼êµ´ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # captured_frames í´ë”ì— ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
        filename = f"captured_frame_{timestamp}.jpg"
        dest_path = self.captured_frames_dir / filename
        
        success = cv2.imwrite(str(dest_path), frame)
        if not success:
            print("âŒ í”„ë ˆì„ ì €ì¥ ì‹¤íŒ¨")
            return
        
        print(f"ğŸ“¸ í”„ë ˆì„ ì €ì¥: {dest_path}")
        print(f"ğŸ” {len(detections)}ê°œ ì–¼êµ´ ë°œê²¬, ìë™ ì²˜ë¦¬ ì‹œì‘...")
        
        # ê°„ë‹¨í•œ ìë™ ê·¸ë£¹í•‘ ë° ì´ë¦„ ì§€ì •
        self._process_saved_frame(frame, detections, timestamp)
    
    def _process_saved_frame(self, frame: np.ndarray, detections: List[Dict], timestamp: str):
        """ì €ì¥ëœ í”„ë ˆì„ì˜ ì–¼êµ´ ìë™ ì²˜ë¦¬"""
        print(f"\nğŸ“Š {len(detections)}ê°œ ì–¼êµ´ ì²˜ë¦¬ ì¤‘...")
        
        # ì–¼êµ´ ê²©ì ìƒì„± ë° í‘œì‹œ
        face_crops = []
        for detection in detections:
            x, y, w, h = detection['bbox']
            
            # ì—¬ìœ ë¥¼ ë‘ê³  ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
            margin = 20
            x1 = max(0, x - margin)
            y1 = max(0, y - margin)
            x2 = min(frame.shape[1], x + w + margin)
            y2 = min(frame.shape[0], y + h + margin)
            
            face_crop = frame[y1:y2, x1:x2]
            if face_crop.size > 0:
                face_crops.append(face_crop)
        
        if not face_crops:
            print("âŒ ì–¼êµ´ ì¶”ì¶œ ì‹¤íŒ¨")
            return
        
        # ì–¼êµ´ ê²©ì í‘œì‹œ
        combined_image = self._create_face_grid(face_crops)
        cv2.imshow(f'Found {len(face_crops)} faces - Enter name in console', combined_image)
        cv2.waitKey(1)
        
        # ì´ë¦„ ì…ë ¥ ë°›ê¸°
        try:
            person_name = input(f"ğŸ‘¤ {len(face_crops)}ê°œ ì–¼êµ´ì˜ ì¸ë¬¼ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (Enter=ê±´ë„ˆë›°ê¸°): ").strip()
            
            cv2.destroyWindow(f'Found {len(face_crops)} faces - Enter name in console')
            
            if person_name:
                self._save_faces_to_staging(person_name, face_crops, timestamp)
            else:
                print("â­ï¸  ê±´ë„ˆë›°ê¸°")
                
        except (KeyboardInterrupt, EOFError):
            cv2.destroyWindow(f'Found {len(face_crops)} faces - Enter name in console')
            print("â­ï¸  ì…ë ¥ ì·¨ì†Œ")
    
    def _create_face_grid(self, face_crops: List[np.ndarray]) -> np.ndarray:
        """ì–¼êµ´ë“¤ì„ ê²©ìë¡œ ë°°ì—´"""
        if not face_crops:
            return np.zeros((100, 100, 3), dtype=np.uint8)
        
        # ê²©ì í¬ê¸° ê³„ì‚°
        num_faces = len(face_crops)
        cols = min(3, num_faces)
        rows = (num_faces + cols - 1) // cols
        
        # ê° ì–¼êµ´ì„ ë™ì¼í•œ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        face_size = 150
        resized_faces = []
        
        for i, face_crop in enumerate(face_crops):
            resized = cv2.resize(face_crop, (face_size, face_size))
            
            # ë²ˆí˜¸ í…ìŠ¤íŠ¸ ì¶”ê°€
            cv2.putText(resized, f"#{i+1}", (5, 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            resized_faces.append(resized)
        
        # ê²©ì ìƒì„±
        grid_height = rows * face_size
        grid_width = cols * face_size
        grid = np.zeros((grid_height, grid_width, 3), dtype=np.uint8)
        
        for i, face in enumerate(resized_faces):
            row = i // cols
            col = i % cols
            
            y1 = row * face_size
            y2 = y1 + face_size
            x1 = col * face_size
            x2 = x1 + face_size
            
            grid[y1:y2, x1:x2] = face
        
        return grid
    
    def _save_faces_to_staging(self, person_name: str, face_crops: List[np.ndarray], timestamp: str):
        """ì–¼êµ´ë“¤ì„ face_stagingìœ¼ë¡œ ì €ì¥"""
        # ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
        safe_name = "".join(c for c in person_name if c.isalnum() or c in (' ', '-', '_')).strip()
        safe_name = safe_name.replace(' ', '_')
        
        source = "auto_saved" if self.is_auto_mode else "manual_saved"
        folder_name = f"{safe_name}_{timestamp}_{source}"
        staging_dir = self.face_staging_dir / folder_name
        staging_dir.mkdir(exist_ok=True)
        
        # ë©”íƒ€ë°ì´í„° ìƒì„±
        metadata = {
            'person_name': person_name,
            'safe_name': safe_name,
            'created_at': timestamp,
            'source': source,
            'face_count': len(face_crops),
            'capture_mode': 'auto' if self.is_auto_mode else 'manual',
            'camera_id': self.camera_id
        }
        
        metadata_file = staging_dir / 'metadata.json'
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        # ì–¼êµ´ë“¤ ì €ì¥
        saved_count = 0
        for i, face_crop in enumerate(face_crops):
            filename = f"face_{safe_name}_{timestamp}_{i:02d}.jpg"
            dest_path = staging_dir / filename
            
            success = cv2.imwrite(str(dest_path), face_crop)
            if success:
                saved_count += 1
        
        print(f"âœ… {person_name}: {saved_count}ê°œ ì–¼êµ´ì„ face_stagingìœ¼ë¡œ ì €ì¥")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {staging_dir}")
        
        # ìº¡ì²˜ í†µê³„ ì—…ë°ì´íŠ¸
        self.captured_faces.extend([{'name': person_name, 'count': saved_count}])
    
    def _capture_face_with_name(self, frame: np.ndarray, detections: List[Dict]):
        """ì–¼êµ´ ìº¡ì²˜ ë° ì´ë¦„ ì§€ì • (ìˆ˜ë™ ëª¨ë“œ ì „ìš©)"""
        if self.is_auto_mode:
            print("âš ï¸  ìë™ ëª¨ë“œì—ì„œëŠ” cí‚¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. aí‚¤ë¡œ ìˆ˜ë™ ëª¨ë“œë¡œ ì „í™˜í•˜ì„¸ìš”.")
            return
        
        if not detections:
            print("âš ï¸  ìº¡ì²˜í•  ì–¼êµ´ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\nğŸ‘¤ {len(detections)}ê°œ ì–¼êµ´ ë°œê²¬ë¨")
        
        # ì–¼êµ´ ì˜ì—­ë“¤ì„ í•˜ì´ë¼ì´íŠ¸í•œ í”„ë ˆì„ ìƒì„±
        highlight_frame = frame.copy()
        for detection in detections:
            x, y, w, h = detection['bbox']
            cv2.rectangle(highlight_frame, (x, y), (x + w, y + h), (0, 255, 0), 3)
        
        cv2.putText(highlight_frame, "Enter person name in console", 
                   (20, highlight_frame.shape[0] - 20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        cv2.imshow('Face Capture - Enter name in console', highlight_frame)
        cv2.waitKey(1)
        
        # ì´ë¦„ ì…ë ¥ ë°›ê¸°
        try:
            person_name = input(f"ğŸ‘¤ ì¸ë¬¼ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (Enter=ì·¨ì†Œ): ").strip()
            
            cv2.destroyWindow('Face Capture - Enter name in console')
            
            if person_name:
                # ì–¼êµ´ ì¶”ì¶œ ë° ì €ì¥
                face_crops = []
                for detection in detections:
                    x, y, w, h = detection['bbox']
                    margin = 20
                    x1 = max(0, x - margin)
                    y1 = max(0, y - margin)
                    x2 = min(frame.shape[1], x + w + margin)
                    y2 = min(frame.shape[0], y + h + margin)
                    
                    face_crop = frame[y1:y2, x1:x2]
                    if face_crop.size > 0:
                        face_crops.append(face_crop)
                
                if face_crops:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    self._save_faces_to_staging(person_name, face_crops, timestamp)
                    print(f"âœ… {person_name}: {len(face_crops)}ê°œ ì–¼êµ´ ìº¡ì²˜ ì™„ë£Œ")
                else:
                    print("âŒ ì–¼êµ´ ì¶”ì¶œ ì‹¤íŒ¨")
            else:
                print("â­ï¸  ìº¡ì²˜ ì·¨ì†Œë¨")
                
        except (KeyboardInterrupt, EOFError):
            cv2.destroyWindow('Face Capture - Enter name in console')
            print("â­ï¸  ì…ë ¥ ì·¨ì†Œ")
    
    def _update_fps(self):
        """FPS ì—…ë°ì´íŠ¸"""
        self.fps_counter += 1
        current_time = time.time()
        
        if current_time - self.fps_timer >= 1.0:
            self.current_fps = self.fps_counter / (current_time - self.fps_timer)
            self.fps_counter = 0
            self.fps_timer = current_time
    
    def _print_help(self):
        """ë„ì›€ë§ ì¶œë ¥"""
        help_text = f"""
ğŸ“‹ ê°„ë‹¨í•œ ì–¼êµ´ ìº¡ì²˜ ì‹œìŠ¤í…œ - í‚¤ë³´ë“œ ëª…ë ¹ì–´:
   i  - ì •ë³´ í‘œì‹œ í† ê¸€ (ì¹´ë©”ë¼, ëª¨ë¸ ì •ë³´)
   a  - ìë™/ìˆ˜ë™ ëª¨ë“œ ì „í™˜ (í˜„ì¬: {'ìë™' if self.is_auto_mode else 'ìˆ˜ë™'})
   s  - í˜„ì¬ í”„ë ˆì„ì„ captured_framesì— ì €ì¥ (ìë™ ì–¼êµ´ ì²˜ë¦¬)
   c  - ì–¼êµ´ ìº¡ì²˜ + ì´ë¦„ ì§€ì • (ìˆ˜ë™ ëª¨ë“œë§Œ)
   h  - ë„ì›€ë§ í‘œì‹œ
   q  - ì¢…ë£Œ

ğŸ’¡ ì‚¬ìš©ë²•:
   ğŸ¤– ìë™ ëª¨ë“œ: sí‚¤ë¡œ í”„ë ˆì„ ì €ì¥ â†’ ìë™ ì–¼êµ´ ê²€ì¶œ ë° ê·¸ë£¹í•‘
   ğŸ‘¤ ìˆ˜ë™ ëª¨ë“œ: cí‚¤ë¡œ ìˆ˜ë™ ìº¡ì²˜ ë˜ëŠ” sí‚¤ë¡œ í”„ë ˆì„ ì €ì¥ í›„ ì²˜ë¦¬
        """
        print(help_text)
    
    def _cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if hasattr(self, 'cap') and self.cap:
            self.cap.release()
        
        cv2.destroyAllWindows()
        
        print(f"\nğŸ“Š ì„¸ì…˜ ìš”ì•½:")
        print(f"   ëª¨ë“œ: {'ìë™' if self.is_auto_mode else 'ìˆ˜ë™'}")
        print(f"   ìº¡ì²˜ëœ ì–¼êµ´: {len(self.captured_faces)}ê°œ")
        print("âœ… ì‹œìŠ¤í…œ ì¢…ë£Œ")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ê°„ë‹¨í•œ ì–¼êµ´ ìº¡ì²˜ ì‹œìŠ¤í…œ")
    parser.add_argument("--camera", type=int, default=0, help="ì¹´ë©”ë¼ ID (ê¸°ë³¸ê°’: 0)")
    parser.add_argument("--auto", action="store_true", help="ìë™ ëª¨ë“œë¡œ ì‹œì‘")
    args = parser.parse_args()
    
    # í•˜ë“œì›¨ì–´ ì—°ê²° ê²€ì¦
    print("ğŸ” í•˜ë“œì›¨ì–´ ì—°ê²° ìƒíƒœ í™•ì¸ ì¤‘...")
    
    # ì¹´ë©”ë¼ ì—°ê²° í…ŒìŠ¤íŠ¸
    test_cap = cv2.VideoCapture(args.camera, cv2.CAP_DSHOW)
    if not test_cap.isOpened():
        print(f"âŒ ì¹´ë©”ë¼ {args.camera}ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ ë‹¤ë¥¸ ì¹´ë©”ë¼ IDë¥¼ ì‹œë„í•´ë³´ì„¸ìš”: --camera 1")
        return
    
    ret, frame = test_cap.read()
    test_cap.release()
    
    if not ret:
        print(f"âŒ ì¹´ë©”ë¼ {args.camera}ì—ì„œ ì˜ìƒì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… ì¹´ë©”ë¼ {args.camera} ì—°ê²° í™•ì¸ë¨")
    
    # ì‹œìŠ¤í…œ ì‹œì‘
    capture_system = SimpleFaceCaptureSystem(camera_id=args.camera)
    
    # ìë™ ëª¨ë“œ ì„¤ì •
    if args.auto:
        capture_system.is_auto_mode = True
    
    capture_system.start_capture()

if __name__ == "__main__":
    main() 