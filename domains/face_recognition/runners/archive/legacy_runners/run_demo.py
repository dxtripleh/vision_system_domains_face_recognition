#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì‹¤ì‹œê°„ ì–¼êµ´ì¸ì‹ ë°ëª¨ ì‹œìŠ¤í…œ.

ì›¹ìº ì„ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì–¼êµ´ì„ ê²€ì¶œí•˜ê³  ì¸ì‹í•˜ëŠ” ë°ëª¨ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
"""

import cv2
import numpy as np
import argparse
import time
import sys
import os
from pathlib import Path
from typing import List, Dict, Optional, Tuple

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent.parent.parent
sys.path.append(str(project_root))

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from common.logging import setup_logging, get_logger
from domains.face_recognition.core.services.face_detection_service import FaceDetectionService

# ê¸°ë³¸ ëª¨ë‹ˆí„°ë§ (ìƒˆë¡œ ì¶”ê°€)
from shared.security.privacy import FaceDataProtection

logger = get_logger(__name__)

class RealtimeDemo:
    """ì‹¤ì‹œê°„ ì–¼êµ´ì¸ì‹ ë°ëª¨"""
    
    def __init__(self, camera_id: int = 0):
        """ì´ˆê¸°í™”"""
        self.camera_id = camera_id
        
        # ì–¼êµ´ ê²€ì¶œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (OpenCV Haar Cascade ì‚¬ìš©)
        self.detection_service = FaceDetectionService(
            config={
                'min_confidence': 0.3,
                'min_face_size': (30, 30),
                'max_faces': 10
            }
        )
        
        # ë³´ì•ˆ ëª¨ë“ˆ ì´ˆê¸°í™” (ìƒˆë¡œ ì¶”ê°€)
        self.data_protection = FaceDataProtection()
        
        # ì„±ëŠ¥ ì¶”ì 
        self.frame_count = 0
        self.start_time = time.time()
        
    def run(self):
        """ë°ëª¨ ì‹¤í–‰"""
        # ì¹´ë©”ë¼ ì´ˆê¸°í™”
        cap = cv2.VideoCapture(self.camera_id)
        
        if not cap.isOpened():
            print(f"âŒ ì¹´ë©”ë¼ {self.camera_id}ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            logger.error(f"Cannot open camera {self.camera_id}")
            return False
        
        # ì¹´ë©”ë¼ í•´ìƒë„ ì„¤ì •
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        print("ğŸ¥ ì‹¤ì‹œê°„ ì–¼êµ´ê²€ì¶œ ë°ëª¨ ì‹œì‘!")
        print("í‚¤ë³´ë“œ ì¡°ì‘:")
        print("  'q' - ì¢…ë£Œ")
        print("  's' - ìŠ¤í¬ë¦°ìƒ· ì €ì¥")
        print("  'i' - ì •ë³´ í‘œì‹œ í† ê¸€")
        print("=" * 50)
        
        show_info = True
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    logger.warning("Failed to read frame from camera")
                    break
                
                # ì–¼êµ´ ê²€ì¶œ
                try:
                    detection_result = self.detection_service.detect_faces(frame)
                    faces = detection_result.faces
                    processing_time = detection_result.processing_time_ms
                    
                    # ê²€ì¶œ ê²°ê³¼ ê·¸ë¦¬ê¸°
                    for i, face in enumerate(faces):
                        bbox = face.bbox
                        confidence = face.confidence.value
                        
                        x, y, w, h = bbox.x, bbox.y, bbox.width, bbox.height
                        
                        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                        color = (0, 255, 0) if confidence > 0.7 else (0, 255, 255)
                        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
                        
                        # ì–¼êµ´ ë²ˆí˜¸ ë° ì‹ ë¢°ë„ í‘œì‹œ
                        label = f"Face {i+1}: {confidence:.2f}"
                        cv2.putText(frame, label, (x, y - 10), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                        
                        # ì–¼êµ´ ì¤‘ì‹¬ì  í‘œì‹œ
                        center_x, center_y = bbox.center
                        cv2.circle(frame, (int(center_x), int(center_y)), 3, color, -1)
                    
                except Exception as e:
                    logger.error(f"Face detection error: {str(e)}")
                    faces = []
                    processing_time = 0
                
                # FPS ê³„ì‚°
                self.frame_count += 1
                elapsed_time = time.time() - self.start_time
                fps = self.frame_count / elapsed_time if elapsed_time > 0 else 0
                
                # ì •ë³´ í‘œì‹œ
                if show_info:
                    # ë°°ê²½ ë°•ìŠ¤
                    cv2.rectangle(frame, (10, 10), (300, 120), (0, 0, 0), -1)
                    cv2.rectangle(frame, (10, 10), (300, 120), (255, 255, 255), 2)
                    
                    # í…ìŠ¤íŠ¸ ì •ë³´
                    cv2.putText(frame, f"FPS: {fps:.1f}", (20, 35), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    cv2.putText(frame, f"Faces: {len(faces)}", (20, 60), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    cv2.putText(frame, f"Process: {processing_time:.1f}ms", (20, 85), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    cv2.putText(frame, "Press 'q' to quit", (20, 110), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                # í”„ë ˆì„ í‘œì‹œ
                cv2.imshow('Face Detection Demo', frame)
                
                # í‚¤ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    print("ğŸ›‘ ì¢…ë£Œ ìš”ì²­")
                    break
                elif key == ord('s'):
                    timestamp = int(time.time())
                    os.makedirs("data/output", exist_ok=True)
                    filename = f"data/output/demo_screenshot_{timestamp}.jpg"
                    cv2.imwrite(filename, frame)
                    print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {filename}")
                    logger.info(f"Screenshot saved: {filename}")
                elif key == ord('i'):
                    show_info = not show_info
                    print(f"â„¹ï¸ ì •ë³´ í‘œì‹œ: {'ON' if show_info else 'OFF'}")
        
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
            logger.info("Demo interrupted by user")
        
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(f"Demo error: {str(e)}")
        
        finally:
            cap.release()
            cv2.destroyAllWindows()
            print("âœ… ë°ëª¨ ì¢…ë£Œ")
            logger.info("Demo finished")
        
        return True


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ì‹¤ì‹œê°„ ì–¼êµ´ê²€ì¶œ ë°ëª¨")
    parser.add_argument("--camera", type=int, default=0, help="ì¹´ë©”ë¼ ID (ê¸°ë³¸ê°’: 0)")
    parser.add_argument("--verbose", "-v", action="store_true", help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")
    args = parser.parse_args()
    
    # ë¡œê¹… ì„¤ì •
    setup_logging(level="DEBUG" if args.verbose else "INFO")
    
    print("ğŸ¯ ì–¼êµ´ê²€ì¶œ ë°ëª¨ ì‹œìŠ¤í…œ")
    print("=" * 50)
    print(f"ì¹´ë©”ë¼ ID: {args.camera}")
    print(f"ë¡œê·¸ ë ˆë²¨: {'DEBUG' if args.verbose else 'INFO'}")
    print("=" * 50)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs("data/output", exist_ok=True)
    os.makedirs("data/logs", exist_ok=True)
    
    # ë°ëª¨ ì‹¤í–‰
    demo = RealtimeDemo(camera_id=args.camera)
    success = demo.run()
    
    return 0 if success else 1


if __name__ == "__main__":
    sys.exit(main()) 