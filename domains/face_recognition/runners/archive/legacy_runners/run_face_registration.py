#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì–¼êµ´ ë“±ë¡ ìŠ¤í¬ë¦½íŠ¸.

ì¹´ë©”ë¼ë¥¼ í†µí•´ ì–¼êµ´ì„ ìº¡ì²˜í•˜ê³  ë“±ë¡í•©ë‹ˆë‹¤.
"""

import cv2
import numpy as np
import sys
import os
import time
from pathlib import Path
from typing import List, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent.parent.parent.parent.parent
sys.path.append(str(project_root))

from common.logging import setup_logging, get_logger
from domains.face_recognition.core.services.face_detection_service import FaceDetectionService
from domains.face_recognition.core.services.face_recognition_service import FaceRecognitionService

logger = get_logger(__name__)

class FaceRegistration:
    """ì–¼êµ´ ë“±ë¡ í´ë˜ìŠ¤"""
    
    def __init__(self, camera_id: int = 0):
        """ì´ˆê¸°í™”"""
        self.camera_id = camera_id
        self.camera = None
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.detection_service = FaceDetectionService(
            config={
                'min_confidence': 0.7,  # ë“±ë¡ì‹œì—ëŠ” ë†’ì€ ì‹ ë¢°ë„ ìš”êµ¬
                'min_face_size': (100, 100),
                'max_faces': 1  # í•œ ë²ˆì— í•œ ëª…ë§Œ
            }
        )
        self.recognition_service = FaceRecognitionService(use_mock=True)
        
        # ìº¡ì²˜ ì„¤ì •
        self.captured_faces = []
        self.target_captures = 5  # 5ì¥ ìº¡ì²˜
        self.capture_interval = 1.0  # 1ì´ˆ ê°„ê²©
        self.last_capture_time = 0
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.create_directories()
    
    def create_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        directories = [
            "data/output", "data/logs", "data/temp",
            "data/storage/faces", "data/storage/persons"
        ]
        for directory in directories:
            Path(directory).mkdir(parents=True, exist_ok=True)
    
    def initialize_camera(self) -> bool:
        """ì¹´ë©”ë¼ ì´ˆê¸°í™”"""
        try:
            self.camera = cv2.VideoCapture(self.camera_id)
            
            if not self.camera.isOpened():
                logger.error(f"ì¹´ë©”ë¼ {self.camera_id} ì—´ê¸° ì‹¤íŒ¨")
                return False
            
            # ì¹´ë©”ë¼ ì„¤ì •
            self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.camera.set(cv2.CAP_PROP_FPS, 30)
            
            logger.info("ì¹´ë©”ë¼ ì´ˆê¸°í™” ì„±ê³µ")
            return True
            
        except Exception as e:
            logger.error(f"ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            return False
    
    def get_person_name(self) -> Optional[str]:
        """ë“±ë¡í•  ì¸ë¬¼ ì´ë¦„ ì…ë ¥ë°›ê¸°"""
        print("\n" + "="*50)
        print("ğŸ§‘â€ğŸ’¼ ìƒˆë¡œìš´ ì¸ë¬¼ ë“±ë¡")
        print("="*50)
        
        while True:
            name = input("ë“±ë¡í•  ì¸ë¬¼ì˜ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (ì·¨ì†Œ: 'cancel'): ").strip()
            
            if name.lower() == 'cancel':
                return None
            
            if not name:
                print("âŒ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue
            
            if len(name) < 2:
                print("âŒ ì´ë¦„ì€ ìµœì†Œ 2ê¸€ì ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
                continue
            
            # ê¸°ì¡´ ì¸ë¬¼ê³¼ ì¤‘ë³µ í™•ì¸
            try:
                existing_persons = self.recognition_service.get_all_persons()
                existing_names = [p.name for p in existing_persons]
                
                if name in existing_names:
                    print(f"âŒ '{name}'ì€ ì´ë¯¸ ë“±ë¡ëœ ì¸ë¬¼ì…ë‹ˆë‹¤.")
                    print(f"ê¸°ì¡´ ë“±ë¡ëœ ì¸ë¬¼ë“¤: {', '.join(existing_names)}")
                    continue
            except Exception as e:
                logger.warning(f"ê¸°ì¡´ ì¸ë¬¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            
            confirm = input(f"'{name}'ìœ¼ë¡œ ë“±ë¡í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
            if confirm in ['y', 'yes']:
                return name
    
    def capture_faces(self, person_name: str) -> bool:
        """ì–¼êµ´ ìº¡ì²˜"""
        print(f"\nğŸ“¸ {person_name}ë‹˜ì˜ ì–¼êµ´ì„ ìº¡ì²˜í•©ë‹ˆë‹¤")
        print(f"ì´ {self.target_captures}ì¥ì˜ ì‚¬ì§„ì„ {self.capture_interval}ì´ˆ ê°„ê²©ìœ¼ë¡œ ì´¬ì˜í•©ë‹ˆë‹¤")
        print("ì¹´ë©”ë¼ë¥¼ ì •ë©´ìœ¼ë¡œ ë°”ë¼ë³´ê³  ë‹¤ì–‘í•œ ê°ë„ë¡œ ì–¼êµ´ì„ ì›€ì§ì—¬ì£¼ì„¸ìš”")
        print("í‚¤ë³´ë“œ ì¡°ì‘:")
        print("  'c' - ìˆ˜ë™ ìº¡ì²˜")
        print("  'q' - ì·¨ì†Œ")
        print("  ìŠ¤í˜ì´ìŠ¤ë°” - ìë™ ìº¡ì²˜ ì‹œì‘")
        print("="*50)
        
        auto_capture = False
        
        try:
            while len(self.captured_faces) < self.target_captures:
                ret, frame = self.camera.read()
                if not ret:
                    logger.warning("í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                    break
                
                # ì–¼êµ´ ê²€ì¶œ
                detection_result = self.detection_service.detect_faces(frame)
                faces = detection_result.faces
                
                # í™”ë©´ì— ê·¸ë¦¬ê¸°
                display_frame = frame.copy()
                
                if faces:
                    face = faces[0]  # ì²« ë²ˆì§¸ ì–¼êµ´ë§Œ ì‚¬ìš©
                    x, y, w, h = face.bbox.x, face.bbox.y, face.bbox.width, face.bbox.height
                    
                    # ë°”ìš´ë”© ë°•ìŠ¤
                    color = (0, 255, 0)
                    cv2.rectangle(display_frame, (x, y), (x + w, y + h), color, 2)
                    
                    # ì‹ ë¢°ë„ í‘œì‹œ
                    confidence = face.confidence.value
                    cv2.putText(display_frame, f"Confidence: {confidence:.2f}", 
                               (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                    
                    # ìë™ ìº¡ì²˜
                    current_time = time.time()
                    if (auto_capture and 
                        current_time - self.last_capture_time >= self.capture_interval and
                        confidence >= 0.7):
                        
                        # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
                        face_region = frame[y:y+h, x:x+w]
                        self.captured_faces.append(face_region.copy())
                        self.last_capture_time = current_time
                        
                        print(f"ğŸ“¸ ìë™ ìº¡ì²˜ {len(self.captured_faces)}/{self.target_captures}")
                        
                        # ìº¡ì²˜ íš¨ê³¼
                        cv2.rectangle(display_frame, (0, 0), (display_frame.shape[1], display_frame.shape[0]), 
                                     (255, 255, 255), 10)
                
                # ì§„í–‰ ìƒí™© í‘œì‹œ
                progress_text = f"Captured: {len(self.captured_faces)}/{self.target_captures}"
                cv2.putText(display_frame, progress_text, (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                
                mode_text = "Auto Capture ON" if auto_capture else "Manual Mode"
                cv2.putText(display_frame, mode_text, (10, 60), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255) if auto_capture else (255, 255, 255), 2)
                
                # ì•ˆë‚´ ë©”ì‹œì§€
                if not faces:
                    cv2.putText(display_frame, "No face detected", (10, 90), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                elif faces[0].confidence.value < 0.7:
                    cv2.putText(display_frame, "Face confidence too low", (10, 90), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                
                cv2.imshow(f'Face Registration - {person_name}', display_frame)
                
                # í‚¤ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    print("âŒ ìº¡ì²˜ ì·¨ì†Œ")
                    return False
                elif key == ord('c') and faces and faces[0].confidence.value >= 0.7:
                    # ìˆ˜ë™ ìº¡ì²˜
                    face = faces[0]
                    x, y, w, h = face.bbox.x, face.bbox.y, face.bbox.width, face.bbox.height
                    face_region = frame[y:y+h, x:x+w]
                    self.captured_faces.append(face_region.copy())
                    print(f"ğŸ“¸ ìˆ˜ë™ ìº¡ì²˜ {len(self.captured_faces)}/{self.target_captures}")
                elif key == ord(' '):
                    # ìë™ ìº¡ì²˜ í† ê¸€
                    auto_capture = not auto_capture
                    print(f"ğŸ”„ ìë™ ìº¡ì²˜: {'ON' if auto_capture else 'OFF'}")
                    self.last_capture_time = time.time()
            
            print(f"âœ… ì´ {len(self.captured_faces)}ì¥ì˜ ì–¼êµ´ ì´ë¯¸ì§€ ìº¡ì²˜ ì™„ë£Œ")
            return True
            
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤")
            return False
        
        except Exception as e:
            print(f"âŒ ìº¡ì²˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(f"ì–¼êµ´ ìº¡ì²˜ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def register_person(self, person_name: str) -> bool:
        """ì¸ë¬¼ ë“±ë¡"""
        if not self.captured_faces:
            print("âŒ ìº¡ì²˜ëœ ì–¼êµ´ì´ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        print(f"\nğŸ”„ {person_name}ë‹˜ì„ ë“±ë¡ ì¤‘...")
        
        try:
            # ì¸ë¬¼ ë“±ë¡
            person_id = self.recognition_service.register_person(
                name=person_name,
                face_images=self.captured_faces,
                metadata={
                    'registration_date': time.strftime('%Y-%m-%d %H:%M:%S'),
                    'capture_count': len(self.captured_faces)
                }
            )
            
            print(f"âœ… {person_name}ë‹˜ì´ ì„±ê³µì ìœ¼ë¡œ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
            print(f"   Person ID: {person_id}")
            print(f"   ë“±ë¡ëœ ì–¼êµ´ ìˆ˜: {len(self.captured_faces)}ê°œ")
            
            return True
            
        except Exception as e:
            print(f"âŒ ë“±ë¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(f"ì¸ë¬¼ ë“±ë¡ ì˜¤ë¥˜: {str(e)}")
            return False
    
    def run(self) -> bool:
        """ë“±ë¡ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("ğŸ¯ ì–¼êµ´ ë“±ë¡ ì‹œìŠ¤í…œ")
        print("=" * 50)
        
        if not self.initialize_camera():
            return False
        
        try:
            # ì¸ë¬¼ ì´ë¦„ ì…ë ¥
            person_name = self.get_person_name()
            if not person_name:
                print("âŒ ë“±ë¡ ì·¨ì†Œ")
                return False
            
            # ì–¼êµ´ ìº¡ì²˜
            if not self.capture_faces(person_name):
                return False
            
            # ì¸ë¬¼ ë“±ë¡
            if not self.register_person(person_name):
                return False
            
            print("\nğŸ‰ ë“±ë¡ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            return True
            
        finally:
            if self.camera:
                self.camera.release()
            cv2.destroyAllWindows()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ì–¼êµ´ ë“±ë¡ ì‹œìŠ¤í…œ")
    parser.add_argument("--camera", type=int, default=0, help="ì¹´ë©”ë¼ ID (ê¸°ë³¸ê°’: 0)")
    parser.add_argument("--verbose", "-v", action="store_true", help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")
    args = parser.parse_args()
    
    # ë¡œê¹… ì„¤ì •
    setup_logging(level="DEBUG" if args.verbose else "INFO")
    
    # ë“±ë¡ ì‹œìŠ¤í…œ ì‹¤í–‰
    registration = FaceRegistration(camera_id=args.camera)
    success = registration.run()
    
    return 0 if success else 1

if __name__ == "__main__":
    sys.exit(main()) 