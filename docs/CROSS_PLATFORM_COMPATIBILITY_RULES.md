# í¬ë¡œìŠ¤ í”Œë«í¼ í˜¸í™˜ì„± ë° í•˜ë“œì›¨ì–´ ìµœì í™” ê·œì¹™

## ğŸ“‹ ê°œìš”

ë¹„ì „ ì‹œìŠ¤í…œì€ ë‹¤ìŒ í™˜ê²½ì—ì„œ ë™ì¼í•˜ê²Œ ì‘ë™í•´ì•¼ í•©ë‹ˆë‹¤:
- **ê°œë°œ í™˜ê²½**: Windows (í˜„ì¬ ë…¸íŠ¸ë¶ - ì‚¬ì–‘ ì œí•œ)
- **í›ˆë ¨ í™˜ê²½**: Ubuntu + RTX5090 (í–¥í›„)
- **ë°°í¬ í™˜ê²½**: NVIDIA Jetson (ì„ë² ë””ë“œ)

## ğŸ–¥ï¸ í•˜ë“œì›¨ì–´ ì‚¬ì–‘ë³„ ìµœì í™”

### í˜„ì¬ ë…¸íŠ¸ë¶ í™˜ê²½ (ì‚¬ì–‘ ì œí•œ)
```python
# ì €ì‚¬ì–‘ ë…¸íŠ¸ë¶ ìµœì í™” ì„¤ì •
LOW_SPEC_CONFIG = {
    "model_size": "small",           # YOLOv8n, MobileNet ë“± ê²½ëŸ‰ ëª¨ë¸
    "input_resolution": (640, 480),  # ë‚®ì€ í•´ìƒë„
    "batch_size": 1,                 # ë°°ì¹˜ í¬ê¸° ìµœì†Œí™”
    "precision": "fp32",             # CPU í˜¸í™˜ ì •ë°€ë„
    "device": "cpu",                 # CPU ì „ìš©
    "workers": 2,                    # ì›Œì»¤ ìˆ˜ ì œí•œ
    "memory_limit": "2GB"            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œ
}

def get_optimal_config():
    """í˜„ì¬ í•˜ë“œì›¨ì–´ì— ìµœì í™”ëœ ì„¤ì • ë°˜í™˜"""
    import psutil
    import platform
    
    # ì‹œìŠ¤í…œ ì‚¬ì–‘ í™•ì¸
    cpu_count = psutil.cpu_count()
    memory_gb = psutil.virtual_memory().total // (1024**3)
    system = platform.system().lower()
    
    # GPU ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
    gpu_available = False
    try:
        import torch
        gpu_available = torch.cuda.is_available()
        if gpu_available:
            gpu_memory = torch.cuda.get_device_properties(0).total_memory // (1024**3)
        else:
            gpu_memory = 0
    except:
        gpu_memory = 0
    
    # ì‚¬ì–‘ë³„ ì„¤ì • ê²°ì •
    if gpu_available and gpu_memory >= 8:
        # ê³ ì‚¬ì–‘ GPU (RTX5090 ë“±)
        return {
            "model_size": "large",
            "input_resolution": (1280, 720),
            "batch_size": 8,
            "precision": "fp16",
            "device": "cuda",
            "workers": min(cpu_count, 8),
            "memory_limit": f"{gpu_memory-1}GB"
        }
    elif gpu_available and gpu_memory >= 4:
        # ì¤‘ì‚¬ì–‘ GPU
        return {
            "model_size": "medium", 
            "input_resolution": (800, 600),
            "batch_size": 4,
            "precision": "fp16",
            "device": "cuda",
            "workers": min(cpu_count, 4),
            "memory_limit": f"{gpu_memory-1}GB"
        }
    else:
        # CPU ì „ìš© (í˜„ì¬ ë…¸íŠ¸ë¶)
        return {
            "model_size": "small",
            "input_resolution": (640, 480),
            "batch_size": 1,
            "precision": "fp32", 
            "device": "cpu",
            "workers": min(cpu_count // 2, 2),
            "memory_limit": f"{memory_gb//2}GB"
        }
```

### RTX5090 í™˜ê²½ (í–¥í›„ í›ˆë ¨ìš©)
```python
# ê³ ì‚¬ì–‘ GPU ìµœì í™” ì„¤ì •
HIGH_SPEC_CONFIG = {
    "model_size": "large",            # YOLOv8x, ResNet152 ë“±
    "input_resolution": (1280, 720),  # ê³ í•´ìƒë„
    "batch_size": 16,                 # ëŒ€ìš©ëŸ‰ ë°°ì¹˜
    "precision": "fp16",              # í˜¼í•© ì •ë°€ë„
    "device": "cuda",                 # GPU ê°€ì†
    "workers": 8,                     # ë©€í‹°í”„ë¡œì„¸ì‹±
    "memory_limit": "20GB",           # ëŒ€ìš©ëŸ‰ ë©”ëª¨ë¦¬
    "tensorrt": True,                 # TensorRT ìµœì í™”
    "amp": True                       # Automatic Mixed Precision
}
```

### Jetson í™˜ê²½ (ë°°í¬ìš©)
```python
# Jetson ìµœì í™” ì„¤ì •
JETSON_CONFIG = {
    "model_size": "medium",           # ê· í˜•ì¡íŒ í¬ê¸°
    "input_resolution": (640, 480),   # ì‹¤ì‹œê°„ ì²˜ë¦¬ ê³ ë ¤
    "batch_size": 1,                  # ì‹¤ì‹œê°„ ë‹¨ì¼ í”„ë ˆì„
    "precision": "fp16",              # Jetson GPU ìµœì í™”
    "device": "cuda",                 # Jetson GPU
    "workers": 4,                     # Jetson ì½”ì–´ ìˆ˜
    "memory_limit": "4GB",            # Jetson ë©”ëª¨ë¦¬ ì œí•œ
    "tensorrt": True,                 # TensorRT ê°€ì† í•„ìˆ˜
    "power_mode": "MAX_N"             # ìµœëŒ€ ì„±ëŠ¥ ëª¨ë“œ
}
```

## ğŸŒ í¬ë¡œìŠ¤ í”Œë«í¼ ê²½ë¡œ ì²˜ë¦¬

### í•„ìˆ˜ ê·œì¹™
```python
import os
from pathlib import Path

# âŒ ì ˆëŒ€ ê¸ˆì§€ - í”Œë«í¼ë³„ ê²½ë¡œ
model_path = "C:\\models\\model.onnx"      # Windows ì „ìš©
model_path = "/home/user/models/model.onnx" # Linux ì „ìš©
model_path = "models\\weights\\model.onnx"  # ë°±ìŠ¬ë˜ì‹œ

# âœ… í•„ìˆ˜ - í¬ë¡œìŠ¤ í”Œë«í¼ ê²½ë¡œ
model_path = os.path.join("models", "weights", "model.onnx")
config_path = Path("config") / "face_recognition.yaml"

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ì ˆëŒ€ ê²½ë¡œ
project_root = Path(__file__).parent.parent
model_path = project_root / "models" / "weights" / "model.onnx"
```

### í™˜ê²½ë³„ ì„¤ì • íŒŒì¼
```yaml
# config/environments/development.yaml (Windows ë…¸íŠ¸ë¶)
hardware:
  device: "cpu"
  batch_size: 1
  workers: 2
  memory_limit: "2GB"

models:
  face_detection: "face_detection_yolov8n_20250703.onnx"
  face_recognition: "face_recognition_mobilefacenet_20250703.onnx"

camera:
  backend: "dshow"  # Windows DirectShow
  resolution: [640, 480]
  fps: 15

# config/environments/training.yaml (Ubuntu RTX5090) 
hardware:
  device: "cuda"
  batch_size: 16
  workers: 8
  memory_limit: "20GB"

models:
  face_detection: "face_detection_yolov8x_20250703.onnx"
  face_recognition: "face_recognition_arcface_r100_20250703.onnx"

camera:
  backend: "v4l2"  # Linux V4L2
  resolution: [1280, 720]
  fps: 30

# config/environments/production.yaml (Jetson)
hardware:
  device: "cuda"
  batch_size: 1
  workers: 4
  memory_limit: "4GB"
  tensorrt: true

models:
  face_detection: "face_detection_yolov8s_jetson_20250703.onnx"
  face_recognition: "face_recognition_mobilefacenet_jetson_20250703.onnx"

camera:
  backend: "v4l2"
  resolution: [640, 480]
  fps: 30
  buffer_size: 1  # ì§€ì—° ìµœì†Œí™”
```

## ğŸ¤– ONNX ëŸ°íƒ€ì„ í”Œë«í¼ë³„ ìµœì í™”

### ìë™ í”„ë¡œë°”ì´ë” ì„ íƒ
```python
import onnxruntime as ort
import platform

def create_optimized_session(model_path: str, config: dict):
    """í”Œë«í¼ë³„ ìµœì í™”ëœ ONNX ì„¸ì…˜ ìƒì„±"""
    
    session_options = ort.SessionOptions()
    session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
    
    system = platform.system().lower()
    device = config.get("device", "cpu")
    
    # í”„ë¡œë°”ì´ë” ìš°ì„ ìˆœìœ„ ì„¤ì •
    providers = []
    
    if system == "linux" and is_jetson():
        # Jetson: TensorRT ìµœìš°ì„ 
        if config.get("tensorrt", False):
            providers.append(('TensorrtExecutionProvider', {
                'device_id': 0,
                'trt_max_workspace_size': 2 * 1024 * 1024 * 1024,
                'trt_fp16_enable': True,
                'trt_engine_cache_enable': True,
                'trt_engine_cache_path': './tensorrt_cache'
            }))
        providers.extend([
            ('CUDAExecutionProvider', {'device_id': 0}),
            'CPUExecutionProvider'
        ])
        
    elif device == "cuda" and torch.cuda.is_available():
        # Windows/Ubuntu GPU
        gpu_memory = torch.cuda.get_device_properties(0).total_memory
        
        if gpu_memory > 8 * 1024**3:  # 8GB ì´ìƒ (RTX5090)
            providers.append(('CUDAExecutionProvider', {
                'device_id': 0,
                'arena_extend_strategy': 'kNextPowerOfTwo',
                'gpu_mem_limit': int(gpu_memory * 0.8),  # 80% ì‚¬ìš©
                'cudnn_conv_algo_search': 'HEURISTIC'
            }))
        else:
            providers.append(('CUDAExecutionProvider', {'device_id': 0}))
            
        providers.append('CPUExecutionProvider')
        
    else:
        # CPU ì „ìš© (í˜„ì¬ ë…¸íŠ¸ë¶)
        providers = ['CPUExecutionProvider']
        session_options.intra_op_num_threads = config.get("workers", 2)
        session_options.inter_op_num_threads = 1
        
        # ë©”ëª¨ë¦¬ ì œí•œ ì„¤ì •
        session_options.enable_mem_pattern = False
        session_options.enable_cpu_mem_arena = False
    
    return ort.InferenceSession(
        str(model_path),
        sess_options=session_options,
        providers=providers
    )

def is_jetson():
    """Jetson í”Œë«í¼ ê°ì§€"""
    try:
        with open("/proc/device-tree/model", "r") as f:
            return "jetson" in f.read().lower()
    except:
        return False
```

## ğŸ“· ì¹´ë©”ë¼ ë°±ì—”ë“œ í˜¸í™˜ì„±

### í”Œë«í¼ë³„ ì¹´ë©”ë¼ ì„¤ì •
```python
def create_platform_camera(camera_id: int = 0, config: dict = None):
    """í”Œë«í¼ë³„ ìµœì í™”ëœ ì¹´ë©”ë¼ ìƒì„±"""
    
    if config is None:
        config = get_optimal_config()
    
    system = platform.system().lower()
    
    # í”Œë«í¼ë³„ ë°±ì—”ë“œ ì„ íƒ
    if system == "windows":
        cap = cv2.VideoCapture(camera_id, cv2.CAP_DSHOW)
        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'))
        
    elif system == "linux":
        cap = cv2.VideoCapture(camera_id, cv2.CAP_V4L2)
        
        if is_jetson():
            # Jetson íŠ¹í™” ìµœì í™”
            cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'))
            cap.set(cv2.CAP_PROP_BUFFERSIZE, config.get("buffer_size", 1))
        
    else:
        cap = cv2.VideoCapture(camera_id)
    
    # ê³µí†µ ì„¤ì •
    resolution = config.get("resolution", [640, 480])
    fps = config.get("fps", 15)
    
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, resolution[0])
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, resolution[1])
    cap.set(cv2.CAP_PROP_FPS, fps)
    
    if not cap.isOpened():
        raise RuntimeError(f"ì¹´ë©”ë¼ {camera_id} ì—´ê¸° ì‹¤íŒ¨")
    
    return cap
```

## ğŸ’¾ ë©”ëª¨ë¦¬ ë° ì„±ëŠ¥ ìµœì í™”

### ì €ì‚¬ì–‘ í™˜ê²½ ìµœì í™”
```python
class LowSpecOptimizer:
    """ì €ì‚¬ì–‘ í™˜ê²½ ìµœì í™” ê´€ë¦¬ì"""
    
    def __init__(self, config: dict):
        self.config = config
        self.memory_usage = []
        
    def optimize_model_loading(self, model_path: str):
        """ëª¨ë¸ ë¡œë”© ìµœì í™”"""
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
        import psutil
        process = psutil.Process()
        
        before_memory = process.memory_info().rss / 1024**2  # MB
        
        # ê²½ëŸ‰ ëª¨ë¸ ì„ íƒ
        if self.config["device"] == "cpu":
            # CPUìš© ìµœì í™”
            session_options = ort.SessionOptions()
            session_options.enable_mem_pattern = False
            session_options.enable_cpu_mem_arena = False
            session_options.intra_op_num_threads = self.config["workers"]
            
        after_memory = process.memory_info().rss / 1024**2
        memory_used = after_memory - before_memory
        
        if memory_used > 1000:  # 1GB ì´ìƒ
            print(f"ê²½ê³ : ëª¨ë¸ì´ {memory_used:.1f}MB ë©”ëª¨ë¦¬ ì‚¬ìš© ì¤‘")
    
    def optimize_frame_processing(self, frame: np.ndarray):
        """í”„ë ˆì„ ì²˜ë¦¬ ìµœì í™”"""
        
        # í•´ìƒë„ ë‹¤ìš´ìŠ¤ì¼€ì¼ (ì €ì‚¬ì–‘ í™˜ê²½)
        if self.config["device"] == "cpu":
            target_resolution = self.config["input_resolution"]
            if frame.shape[:2] != target_resolution[::-1]:
                frame = cv2.resize(frame, target_resolution)
        
        return frame
    
    def cleanup_memory(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        import gc
        gc.collect()
        
        if self.config["device"] == "cuda":
            import torch
            torch.cuda.empty_cache()
```

## ğŸ”§ ë„ë©”ì¸ ëª¨ë“ˆ í…œí”Œë¦¿ (í¬ë¡œìŠ¤ í”Œë«í¼)

### domains/factory/defect_detection/ ì˜ˆì‹œ
```python
# domains/factory/defect_detection/model.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ê³µì¥ ë¶ˆëŸ‰ ê²€ì¶œ ëª¨ë¸ (í¬ë¡œìŠ¤ í”Œë«í¼ í˜¸í™˜)

ONNX ê¸°ë°˜ YOLOv8 ë¶ˆëŸ‰ ê²€ì¶œ ëª¨ë¸ì„ ë¡œë”©í•˜ê³  ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import os
import sys
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import logging

import cv2
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent
sys.path.append(str(project_root))

from common.config import load_config
from common.logging import get_logger

class DefectDetectionModel:
    """YOLOv8 ê¸°ë°˜ ë¶ˆëŸ‰ ê²€ì¶œ ëª¨ë¸ (í¬ë¡œìŠ¤ í”Œë«í¼)"""
    
    def __init__(self, model_path: Optional[str] = None, config: Optional[Dict] = None):
        self.logger = get_logger(__name__)
        
        # ì„¤ì • ë¡œë“œ
        if config is None:
            config = load_config("factory_defect_detection")
        self.config = config
        
        # í”Œë«í¼ë³„ ìµœì í™” ì„¤ì •
        self.hardware_config = get_optimal_config()
        
        # ëª¨ë¸ ê²½ë¡œ ì„¤ì • (í¬ë¡œìŠ¤ í”Œë«í¼)
        if model_path is None:
            model_path = self._get_default_model_path()
        
        self.model_path = Path(model_path)
        if not self.model_path.exists():
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
        
        # ONNX ì„¸ì…˜ ìƒì„±
        self.session = create_optimized_session(str(self.model_path), self.hardware_config)
        
        # í´ë˜ìŠ¤ ì •ë³´
        self.classes = config.get("classes", ["good", "defect"])
        self.confidence_threshold = config.get("confidence_threshold", 0.5)
        
        self.logger.info(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.model_path}")
        self.logger.info(f"í•˜ë“œì›¨ì–´ ì„¤ì •: {self.hardware_config['device']}")
    
    def _get_default_model_path(self) -> Path:
        """ê¸°ë³¸ ëª¨ë¸ ê²½ë¡œ (í¬ë¡œìŠ¤ í”Œë«í¼)"""
        model_size = self.hardware_config["model_size"]
        
        model_name = f"defect_detection_yolov8{model_size[0]}_factory_20250703.onnx"
        return project_root / "models" / "weights" / model_name
    
    def predict(self, image: np.ndarray) -> List[Dict]:
        """ì´ë¯¸ì§€ì—ì„œ ë¶ˆëŸ‰ ê²€ì¶œ"""
        
        # ì „ì²˜ë¦¬
        processed_image = self._preprocess(image)
        
        # ì¶”ë¡  ì‹¤í–‰
        outputs = self.session.run(None, {"images": processed_image})
        
        # í›„ì²˜ë¦¬
        detections = self._postprocess(outputs[0], image.shape[:2])
        
        return detections
    
    def _preprocess(self, image: np.ndarray) -> np.ndarray:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (í¬ë¡œìŠ¤ í”Œë«í¼ í˜¸í™˜)"""
        
        # ì…ë ¥ í¬ê¸° ì¡°ì • (í•˜ë“œì›¨ì–´ ì‚¬ì–‘ì— ë”°ë¼)
        input_size = self.hardware_config["input_resolution"]
        
        # ë¹„ìœ¨ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì¦ˆ
        h, w = image.shape[:2]
        scale = min(input_size[0] / w, input_size[1] / h)
        new_w, new_h = int(w * scale), int(h * scale)
        
        resized = cv2.resize(image, (new_w, new_h))
        
        # íŒ¨ë”© ì¶”ê°€
        top = (input_size[1] - new_h) // 2
        bottom = input_size[1] - new_h - top
        left = (input_size[0] - new_w) // 2
        right = input_size[0] - new_w - left
        
        padded = cv2.copyMakeBorder(
            resized, top, bottom, left, right, 
            cv2.BORDER_CONSTANT, value=(114, 114, 114)
        )
        
        # ì •ê·œí™” ë° ì°¨ì› ë³€ê²½
        normalized = padded.astype(np.float32) / 255.0
        transposed = normalized.transpose(2, 0, 1)  # HWC -> CHW
        batched = np.expand_dims(transposed, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
        
        return batched
    
    def _postprocess(self, outputs: np.ndarray, original_shape: Tuple[int, int]) -> List[Dict]:
        """ì¶œë ¥ í›„ì²˜ë¦¬"""
        
        detections = []
        
        # NMS ì ìš© ë° ì¢Œí‘œ ë³€í™˜
        # ... (YOLO í›„ì²˜ë¦¬ ë¡œì§)
        
        return detections

# domains/factory/defect_detection/run.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ê³µì¥ ë¶ˆëŸ‰ ê²€ì¶œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (í¬ë¡œìŠ¤ í”Œë«í¼)

USB ì¹´ë©”ë¼ ë˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ì‹¤ì‹œê°„ ë¶ˆëŸ‰ ê²€ì¶œì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import argparse
import logging
import sys
import time
from pathlib import Path
from typing import Optional

import cv2
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent
sys.path.append(str(project_root))

from common.config import load_config
from common.logging import setup_logging
from .model import DefectDetectionModel

def parse_args():
    """ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(description="ê³µì¥ ë¶ˆëŸ‰ ê²€ì¶œ ì‹œìŠ¤í…œ")
    parser.add_argument("--source", type=str, default="0", 
                       help="ì…ë ¥ ì†ŒìŠ¤ (ì¹´ë©”ë¼ ID, íŒŒì¼ ê²½ë¡œ, RTSP URL)")
    parser.add_argument("--model", type=str, help="ëª¨ë¸ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--conf", type=float, default=0.5, help="ì‹ ë¢°ë„ ì„ê³„ê°’")
    parser.add_argument("--show", action="store_true", help="ê²°ê³¼ í™”ë©´ í‘œì‹œ")
    parser.add_argument("--save", action="store_true", help="ê²°ê³¼ ì €ì¥")
    parser.add_argument("--headless", action="store_true", help="GUI ì—†ì´ ì‹¤í–‰")
    return parser.parse_args()

def verify_hardware_connection():
    """í•˜ë“œì›¨ì–´ ì—°ê²° ìƒíƒœ í™•ì¸ (ì‹œë®¬ë ˆì´ì…˜ ë°©ì§€)"""
    import os
    
    # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ ê¸ˆì§€
    if os.environ.get("USE_SIMULATION", "False").lower() == "true":
        raise RuntimeError("ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œëŠ” ê¸ˆì§€ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    
    # ì¹´ë©”ë¼ ì—°ê²° í™•ì¸
    cap = create_platform_camera(0)
    ret, frame = cap.read()
    cap.release()
    
    if not ret or frame is None:
        raise RuntimeError("ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return True

def handle_keyboard_input():
    """í‘œì¤€ í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤ ì²˜ë¦¬"""
    key = cv2.waitKey(1) & 0xFF
    
    if key == ord('q'):      # q: ì¢…ë£Œ
        return 'quit'
    elif key == ord('s'):    # s: í˜„ì¬ í”„ë ˆì„ ì €ì¥
        return 'save_frame'
    elif key == ord('p'):    # p: ì¼ì‹œ ì •ì§€/ì¬ìƒ
        return 'toggle_pause'
    elif key == ord('r'):    # r: ë…¹í™” ì‹œì‘/ì¤‘ì§€
        return 'toggle_record'
    
    return None

def visualize_results(frame: np.ndarray, detections: list, config: dict) -> np.ndarray:
    """ê²€ì¶œ ê²°ê³¼ ì‹œê°í™” (í¬ë¡œìŠ¤ í”Œë«í¼)"""
    
    result_frame = frame.copy()
    
    for detection in detections:
        bbox = detection["bbox"]
        confidence = detection["confidence"]
        class_name = detection["class"]
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        x1, y1, x2, y2 = map(int, bbox)
        color = (0, 255, 0) if class_name == "good" else (0, 0, 255)
        cv2.rectangle(result_frame, (x1, y1), (x2, y2), color, 2)
        
        # ë¼ë²¨ ê·¸ë¦¬ê¸°
        label = f"{class_name}: {confidence:.2f}"
        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
        cv2.rectangle(result_frame, (x1, y1 - label_size[1] - 10), 
                     (x1 + label_size[0], y1), color, -1)
        cv2.putText(result_frame, label, (x1, y1 - 5), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
    
    return result_frame

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    args = parse_args()
    
    # ë¡œê¹… ì„¤ì •
    setup_logging()
    logger = logging.getLogger(__name__)
    
    try:
        logger.info("ê³µì¥ ë¶ˆëŸ‰ ê²€ì¶œ ì‹œìŠ¤í…œ ì‹œì‘")
        
        # í•˜ë“œì›¨ì–´ ì—°ê²° ê²€ì¦ (í•„ìˆ˜)
        verify_hardware_connection()
        
        # ì„¤ì • ë¡œë“œ
        config = load_config("factory_defect_detection")
        hardware_config = get_optimal_config()
        
        logger.info(f"í•˜ë“œì›¨ì–´ ì„¤ì •: {hardware_config}")
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        model = DefectDetectionModel(model_path=args.model, config=config)
        
        # ì…ë ¥ ì†ŒìŠ¤ ì„¤ì •
        if args.source.isdigit():
            cap = create_platform_camera(int(args.source), hardware_config)
        else:
            cap = cv2.VideoCapture(args.source)
        
        if not cap.isOpened():
            raise RuntimeError(f"ì…ë ¥ ì†ŒìŠ¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.source}")
        
        # ì„±ëŠ¥ ì¸¡ì •
        fps_counter = 0
        start_time = time.time()
        
        # ë©”ì¸ ì²˜ë¦¬ ë£¨í”„
        paused = False
        
        while True:
            if not paused:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # ë¶ˆëŸ‰ ê²€ì¶œ
                detections = model.predict(frame)
                
                # ê²°ê³¼ ë¡œê¹…
                defect_count = len([d for d in detections if d["class"] == "defect"])
                if defect_count > 0:
                    logger.warning(f"ë¶ˆëŸ‰ ê²€ì¶œ: {defect_count}ê°œ")
                
                # ê²°ê³¼ ì‹œê°í™”
                if args.show or not args.headless:
                    display_frame = visualize_results(frame, detections, config)
                    
                    # FPS í‘œì‹œ
                    fps_counter += 1
                    elapsed = time.time() - start_time
                    if elapsed > 0:
                        fps = fps_counter / elapsed
                        cv2.putText(display_frame, f"FPS: {fps:.1f}", (10, 30),
                                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                    
                    cv2.imshow("Factory Defect Detection", display_frame)
                
                # ê²°ê³¼ ì €ì¥
                if args.save:
                    timestamp = int(time.time())
                    output_dir = project_root / "data" / "runtime" / "output"
                    output_dir.mkdir(parents=True, exist_ok=True)
                    output_path = output_dir / f"defect_result_{timestamp}.jpg"
                    cv2.imwrite(str(output_path), display_frame)
            
            # í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬
            if not args.headless:
                action = handle_keyboard_input()
                if action == 'quit':
                    break
                elif action == 'toggle_pause':
                    paused = not paused
                    logger.info(f"{'ì¼ì‹œì •ì§€' if paused else 'ì¬ìƒ'}")
                elif action == 'save_frame':
                    timestamp = int(time.time())
                    output_dir = project_root / "data" / "runtime" / "output"
                    output_dir.mkdir(parents=True, exist_ok=True)
                    output_path = output_dir / f"captured_frame_{timestamp}.jpg"
                    cv2.imwrite(str(output_path), frame)
                    logger.info(f"í”„ë ˆì„ ì €ì¥: {output_path}")
        
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        logger.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise
    finally:
        if 'cap' in locals():
            cap.release()
        cv2.destroyAllWindows()
        logger.info("ì‹œìŠ¤í…œ ì¢…ë£Œ ì™„ë£Œ")

if __name__ == "__main__":
    main()

# domains/factory/defect_detection/test_model.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ë¶ˆëŸ‰ ê²€ì¶œ ëª¨ë¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

ì˜ˆì œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ê¸°ë³¸ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import sys
import unittest
from pathlib import Path

import cv2
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent
sys.path.append(str(project_root))

from .model import DefectDetectionModel

class TestDefectDetectionModel(unittest.TestCase):
    """ë¶ˆëŸ‰ ê²€ì¶œ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    
    def setUp(self):
        """í…ŒìŠ¤íŠ¸ ì„¤ì •"""
        self.model = DefectDetectionModel()
        
        # í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ìƒì„± (ì‹¤ì œë¡œëŠ” ì˜ˆì œ ì´ë¯¸ì§€ ì‚¬ìš©)
        self.test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
    
    def test_model_loading(self):
        """ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸"""
        self.assertIsNotNone(self.model.session)
        self.assertGreater(len(self.model.classes), 0)
    
    def test_prediction(self):
        """ì˜ˆì¸¡ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        detections = self.model.predict(self.test_image)
        self.assertIsInstance(detections, list)
    
    def test_cross_platform_path(self):
        """í¬ë¡œìŠ¤ í”Œë«í¼ ê²½ë¡œ í…ŒìŠ¤íŠ¸"""
        model_path = self.model.model_path
        self.assertTrue(model_path.exists())

if __name__ == "__main__":
    unittest.main()
```

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê°€ì´ë“œ

### í™˜ê²½ë³„ ì˜ˆìƒ ì„±ëŠ¥
```yaml
# í˜„ì¬ ë…¸íŠ¸ë¶ (CPU)
performance_expectation:
  fps: 5-10
  latency: 200-500ms
  accuracy: ë™ì¼
  memory: 1-2GB

# RTX5090 (GPU)
performance_expectation:
  fps: 60-120
  latency: 8-15ms  
  accuracy: ë™ì¼
  memory: 4-8GB

# Jetson (ì„ë² ë””ë“œ)
performance_expectation:
  fps: 15-30
  latency: 30-60ms
  accuracy: ë™ì¼
  memory: 2-4GB
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **í˜„ì¬ ë…¸íŠ¸ë¶ ê°œë°œ ì‹œ**:
   - CPU ì „ìš©ìœ¼ë¡œ ê°œë°œí•˜ë˜, GPU ì½”ë“œ ê²½ë¡œë„ ìœ ì§€
   - ê²½ëŸ‰ ëª¨ë¸ ìš°ì„  ì‚¬ìš© (YOLOv8n, MobileNet)
   - ë°°ì¹˜ í¬ê¸°ëŠ” 1ë¡œ ê³ ì •
   
2. **RTX5090 ì „í™˜ ì‹œ**:
   - ì„¤ì • íŒŒì¼ë§Œ ë³€ê²½í•˜ë©´ ìë™ GPU í™œìš©
   - ëŒ€ìš©ëŸ‰ ëª¨ë¸ ë° ë°°ì¹˜ ì²˜ë¦¬ ê°€ëŠ¥
   
3. **Jetson ë°°í¬ ì‹œ**:
   - TensorRT ìµœì í™” í•„ìˆ˜
   - ì „ë ¥ ê´€ë¦¬ ê³ ë ¤ í•„ìš” 