# Vision Core ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ë¹„ì „ ì‹œìŠ¤í…œì˜ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì„ ì œê³µí•˜ëŠ” ê³µí†µ ëª¨ë“ˆì…ë‹ˆë‹¤.

## ğŸ“ í´ë” êµ¬ì¡°

```
vision_core/
â”œâ”€â”€ __init__.py              # ëª¨ë“ˆ ì´ˆê¸°í™”
â”œâ”€â”€ README.md                # ì´ íŒŒì¼
â”œâ”€â”€ detection/               # ê°ì²´ ê²€ì¶œ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ base_detector.py
â”‚   â”œâ”€â”€ face_detector.py
â”‚   â”œâ”€â”€ object_detector.py
â”‚   â””â”€â”€ quality_assessor.py
â”œâ”€â”€ recognition/             # ì¸ì‹ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ base_recognizer.py
â”‚   â”œâ”€â”€ face_embedder.py
â”‚   â”œâ”€â”€ face_matcher.py
â”‚   â””â”€â”€ similarity_matcher.py
â”œâ”€â”€ preprocessing/           # ì „ì²˜ë¦¬ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ image_processor.py
â”‚   â”œâ”€â”€ face_aligner.py
â”‚   â”œâ”€â”€ augmentation.py
â”‚   â””â”€â”€ normalization.py
â”œâ”€â”€ postprocessing/          # í›„ì²˜ë¦¬ ëª¨ë“ˆ (í–¥í›„)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ nms_utils.py
â”‚   â”œâ”€â”€ filtering.py
â”‚   â””â”€â”€ visualization.py
â”œâ”€â”€ tracking/                # ì¶”ì  ëª¨ë“ˆ (í–¥í›„)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ tracker.py
â”‚   â”œâ”€â”€ motion_model.py
â”‚   â””â”€â”€ association.py
â””â”€â”€ pose_estimation/         # ìì„¸ ì¶”ì • ëª¨ë“ˆ (í–¥í›„)
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ README.md
    â”œâ”€â”€ pose_estimator.py
    â””â”€â”€ keypoint_utils.py
```

## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥

### 1. Detection (ê°ì²´ ê²€ì¶œ)
- **ì–¼êµ´ ê²€ì¶œ**: RetinaFace, MTCNN ë“± ë‹¤ì–‘í•œ ì–¼êµ´ ê²€ì¶œ ëª¨ë¸ ì§€ì›
- **ì¼ë°˜ ê°ì²´ ê²€ì¶œ**: YOLO, SSD ë“± ë²”ìš© ê°ì²´ ê²€ì¶œ ëª¨ë¸ ì§€ì›
- **í’ˆì§ˆ í‰ê°€**: ì´ë¯¸ì§€ í’ˆì§ˆ ìë™ í‰ê°€ ë° í•„í„°ë§

### 2. Recognition (ì¸ì‹)
- **ì–¼êµ´ ì¸ì‹**: ArcFace, FaceNet ë“± ê³ ì„±ëŠ¥ ì–¼êµ´ ì¸ì‹ ëª¨ë¸ ì§€ì›
- **íŠ¹ì§• ë§¤ì¹­**: ì½”ì‚¬ì¸ ìœ ì‚¬ë„, ìœ í´ë¦¬ë“œ ê±°ë¦¬ ë“± ë‹¤ì–‘í•œ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜
- **ìœ ì‚¬ë„ ê²€ìƒ‰**: ëŒ€ìš©ëŸ‰ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ íš¨ìœ¨ì ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰

### 3. Preprocessing (ì „ì²˜ë¦¬)
- **ì´ë¯¸ì§€ ì²˜ë¦¬**: ë¦¬ì‚¬ì´ì¦ˆ, ì •ê·œí™”, ìƒ‰ìƒ ë³€í™˜ ë“± ê¸°ë³¸ ì²˜ë¦¬
- **ì–¼êµ´ ì •ë ¬**: ëœë“œë§ˆí¬ ê¸°ë°˜ ì–¼êµ´ ì •ë ¬ ë° ì •ê·œí™”
- **ë°ì´í„° ì¦ê°•**: íšŒì „, ë°ê¸° ì¡°ì •, ë…¸ì´ì¦ˆ ì¶”ê°€ ë“± ë‹¤ì–‘í•œ ì¦ê°• ê¸°ë²•

### 4. Postprocessing (í›„ì²˜ë¦¬) - í–¥í›„
- **NMS**: Non-Maximum Suppressionìœ¼ë¡œ ì¤‘ë³µ ê²€ì¶œ ì œê±°
- **í•„í„°ë§**: ì‹ ë¢°ë„, í¬ê¸°, ìœ„ì¹˜ ê¸°ë°˜ ê²°ê³¼ í•„í„°ë§
- **ì‹œê°í™”**: ê²€ì¶œ ê²°ê³¼ ì‹œê°í™” ë° ì–´ë…¸í…Œì´ì…˜

### 5. Tracking (ì¶”ì ) - í–¥í›„
- **ê°ì²´ ì¶”ì **: Kalman Filter, SORT ë“± ì¶”ì  ì•Œê³ ë¦¬ì¦˜
- **ëª¨ì…˜ ëª¨ë¸**: ê°ì²´ ì›€ì§ì„ ì˜ˆì¸¡ ë° ëª¨ë¸ë§
- **ì—°ê´€ ë¶„ì„**: í”„ë ˆì„ ê°„ ê°ì²´ ì—°ê´€ì„± ë¶„ì„

### 6. Pose Estimation (ìì„¸ ì¶”ì •) - í–¥í›„
- **í‚¤í¬ì¸íŠ¸ ê²€ì¶œ**: ì¸ì²´, ì–¼êµ´ í‚¤í¬ì¸íŠ¸ ê²€ì¶œ
- **ìì„¸ ì¶”ì •**: 2D/3D ìì„¸ ì¶”ì • ë° ë¶„ì„
- **ì œìŠ¤ì²˜ ì¸ì‹**: ì†, ì–¼êµ´ ì œìŠ¤ì²˜ ì¸ì‹

## ğŸ”§ ì‚¬ìš© ì˜ˆì‹œ

### ê¸°ë³¸ ë¹„ì „ íŒŒì´í”„ë¼ì¸
```python
import cv2
import numpy as np
from shared.vision_core.detection import FaceDetector
from shared.vision_core.recognition import FaceEmbedder, FaceMatcher
from shared.vision_core.preprocessing import ImageProcessor

def vision_pipeline(image_path: str):
    """ì™„ì „í•œ ë¹„ì „ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    
    # ì´ë¯¸ì§€ ë¡œë“œ
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
    
    # 1. ì „ì²˜ë¦¬
    processor = ImageProcessor(config={"resize": (640, 640)})
    processed_image = processor.process(image)
    
    # 2. ì–¼êµ´ ê²€ì¶œ
    detector = FaceDetector(
        model_path="models/weights/face_detection.onnx",
        config={"confidence_threshold": 0.5}
    )
    faces = detector.detect(processed_image)
    
    # 3. ì–¼êµ´ ì¸ì‹ (ê²€ì¶œëœ ì–¼êµ´ì´ ìˆëŠ” ê²½ìš°)
    if faces:
        embedder = FaceEmbedder(
            model_path="models/weights/face_recognition.onnx",
            config={"embedding_size": 512}
        )
        
        matcher = FaceMatcher(config={"similarity_threshold": 0.6})
        
        # ì²« ë²ˆì§¸ ì–¼êµ´ ì¸ì‹
        face = faces[0]
        face_roi = processed_image[face.bbox[1]:face.bbox[1]+face.bbox[3], 
                                  face.bbox[0]:face.bbox[0]+face.bbox[2]]
        
        embedding = embedder.extract_embedding(face_roi)
        
        # ë°ì´í„°ë² ì´ìŠ¤ì™€ ë§¤ì¹­ (ì˜ˆì‹œ)
        database = {"person1": np.random.rand(512)}  # ì‹¤ì œë¡œëŠ” ì €ì¥ëœ ì„ë² ë”©
        best_match = "Unknown"
        best_score = 0.0
        
        for person_id, stored_embedding in database.items():
            similarity = matcher.match(embedding, stored_embedding)
            if similarity > best_score:
                best_score = similarity
                best_match = person_id
        
        return {
            "faces_detected": len(faces),
            "recognized_person": best_match,
            "confidence": best_score
        }
    
    return {"faces_detected": 0, "recognized_person": "None", "confidence": 0.0}

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    result = vision_pipeline("test_image.jpg")
    print(f"ê²€ì¶œëœ ì–¼êµ´: {result['faces_detected']}ê°œ")
    print(f"ì¸ì‹ ê²°ê³¼: {result['recognized_person']}")
    print(f"ì‹ ë¢°ë„: {result['confidence']:.3f}")
```

### ì‹¤ì‹œê°„ ë¹„ì „ ì‹œìŠ¤í…œ
```python
import cv2
import time
from shared.vision_core.detection import FaceDetector, ObjectDetector
from shared.vision_core.recognition import FaceEmbedder, FaceMatcher
from shared.vision_core.preprocessing import ImageProcessor

def real_time_vision_system(camera_id: int = 0):
    """ì‹¤ì‹œê°„ ë¹„ì „ ì‹œìŠ¤í…œ"""
    
    # ì¹´ë©”ë¼ ì´ˆê¸°í™”
    cap = cv2.VideoCapture(camera_id)
    if not cap.isOpened():
        raise RuntimeError(f"ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {camera_id}")
    
    # ëª¨ë“ˆ ì´ˆê¸°í™”
    image_processor = ImageProcessor(config={"resize": (640, 640)})
    face_detector = FaceDetector(
        model_path="models/weights/face_detection.onnx",
        config={"confidence_threshold": 0.5}
    )
    object_detector = ObjectDetector(
        model_path="models/weights/object_detection.onnx",
        config={"confidence_threshold": 0.5}
    )
    
    try:
        while True:
            # í”„ë ˆì„ ì½ê¸°
            ret, frame = cap.read()
            if not ret:
                break
            
            # ì „ì²˜ë¦¬
            processed_frame = image_processor.process(frame)
            
            # ì–¼êµ´ ê²€ì¶œ
            faces = face_detector.detect(processed_frame)
            
            # ê°ì²´ ê²€ì¶œ
            objects = object_detector.detect(processed_frame)
            
            # ê²°ê³¼ ì‹œê°í™”
            result_frame = processed_frame.copy()
            
            # ì–¼êµ´ ë°”ìš´ë”© ë°•ìŠ¤
            for face in faces:
                x, y, w, h = face.bbox
                cv2.rectangle(result_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                cv2.putText(result_frame, f"Face: {face.confidence:.2f}", 
                           (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            
            # ê°ì²´ ë°”ìš´ë”© ë°•ìŠ¤
            for obj in objects:
                x, y, w, h = obj.bbox
                cv2.rectangle(result_frame, (x, y), (x+w, y+h), (255, 0, 0), 2)
                cv2.putText(result_frame, f"{obj.class_name}: {obj.confidence:.2f}", 
                           (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
            
            # í†µê³„ ì •ë³´ í‘œì‹œ
            cv2.putText(result_frame, f"Faces: {len(faces)}", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(result_frame, f"Objects: {len(objects)}", 
                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
            
            # í™”ë©´ í‘œì‹œ
            cv2.imshow("Real-time Vision System", result_frame)
            
            # í‚¤ ì…ë ¥ ì²˜ë¦¬
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
                
    finally:
        cap.release()
        cv2.destroyAllWindows()

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    real_time_vision_system()
```

### ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ
```python
import cv2
import numpy as np
from pathlib import Path
from shared.vision_core.detection import FaceDetector
from shared.vision_core.preprocessing import ImageProcessor, Augmentation

def batch_processing_pipeline(input_dir: str, output_dir: str):
    """ë°°ì¹˜ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # ëª¨ë“ˆ ì´ˆê¸°í™”
    processor = ImageProcessor(config={"resize": (640, 640)})
    detector = FaceDetector(
        model_path="models/weights/face_detection.onnx",
        config={"confidence_threshold": 0.5}
    )
    augmenter = Augmentation(
        config={
            "rotation_range": (-15, 15),
            "brightness_range": (0.8, 1.2),
            "flip_probability": 0.5
        }
    )
    
    # ì…ë ¥ ì´ë¯¸ì§€ ëª©ë¡
    input_path = Path(input_dir)
    image_files = list(input_path.glob("*.jpg")) + list(input_path.glob("*.png"))
    
    total_processed = 0
    faces_detected = 0
    
    for image_file in image_files:
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(str(image_file))
        if image is None:
            continue
        
        # ì „ì²˜ë¦¬
        processed_image = processor.process(image)
        
        # ì–¼êµ´ ê²€ì¶œ
        faces = detector.detect(processed_image)
        
        if len(faces) > 0:
            faces_detected += len(faces)
            
            # ë°ì´í„° ì¦ê°• (ì–¼êµ´ì´ ê²€ì¶œëœ ê²½ìš°)
            augmented_images = augmenter.augment_single(processed_image, num_augmentations=3)
            
            # ê²°ê³¼ ì €ì¥
            base_name = image_file.stem
            for i, aug_image in enumerate(augmented_images):
                output_file = output_path / f"{base_name}_aug_{i:03d}.jpg"
                cv2.imwrite(str(output_file), aug_image)
        
        total_processed += 1
        print(f"ì²˜ë¦¬ ì™„ë£Œ: {image_file.name} (ì–¼êµ´ {len(faces)}ê°œ)")
    
    print(f"ì´ ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {total_processed}ê°œ")
    print(f"ì´ ê²€ì¶œëœ ì–¼êµ´: {faces_detected}ê°œ")

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    batch_processing_pipeline(
        input_dir="datasets/humanoid/raw",
        output_dir="datasets/humanoid/processed"
    )
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### 1. ëª¨ë“ˆë³„ ìµœì í™”
```python
# Detection ìµœì í™”
detector_config = {
    "device": "cuda",           # GPU ì‚¬ìš©
    "precision": "fp16",        # ë°˜ì •ë°€ë„
    "batch_size": 4,            # ë°°ì¹˜ ì²˜ë¦¬
    "num_threads": 4            # ë©€í‹°ìŠ¤ë ˆë”©
}

# Recognition ìµœì í™”
recognizer_config = {
    "device": "cuda",
    "precision": "fp16",
    "enable_cache": True,       # ìºì‹œ í™œì„±í™”
    "cache_size": 1000
}

# Preprocessing ìµœì í™”
processor_config = {
    "device": "cuda",
    "enable_cache": True,
    "batch_size": 8
}
```

### 2. íŒŒì´í”„ë¼ì¸ ìµœì í™”
```python
def optimized_pipeline(images: List[np.ndarray]):
    """ìµœì í™”ëœ íŒŒì´í”„ë¼ì¸"""
    
    # ë°°ì¹˜ ì „ì²˜ë¦¬
    processor = ImageProcessor(config={"batch_size": 8})
    processed_batch = processor.process_batch(images)
    
    # ë°°ì¹˜ ê²€ì¶œ
    detector = FaceDetector(config={"batch_size": 4})
    detection_batch = detector.detect_batch(processed_batch)
    
    # ë°°ì¹˜ ì¸ì‹
    embedder = FaceEmbedder(config={"batch_size": 4})
    embedding_batch = embedder.extract_embeddings_batch(processed_batch)
    
    return detection_batch, embedding_batch
```

### 3. ë©”ëª¨ë¦¬ ìµœì í™”
```python
def memory_efficient_processing(image_paths: List[str]):
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì²˜ë¦¬"""
    
    chunk_size = 10  # í•œ ë²ˆì— ì²˜ë¦¬í•  ì´ë¯¸ì§€ ìˆ˜
    
    for i in range(0, len(image_paths), chunk_size):
        chunk_paths = image_paths[i:i+chunk_size]
        
        # ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        chunk_images = [cv2.imread(path) for path in chunk_paths]
        chunk_results = process_chunk(chunk_images)
        
        # ê²°ê³¼ ì €ì¥ í›„ ë©”ëª¨ë¦¬ í•´ì œ
        save_results(chunk_results)
        del chunk_images, chunk_results
```

## ğŸ”§ ì„¤ì • ì˜µì…˜

### ê³µí†µ ì„¤ì •
```python
COMMON_CONFIG = {
    "device": "cpu",               # ì‹¤í–‰ ë””ë°”ì´ìŠ¤ (cpu/cuda)
    "precision": "fp32",           # ì •ë°€ë„ (fp32/fp16)
    "batch_size": 1,               # ë°°ì¹˜ í¬ê¸°
    "num_threads": 4,              # ìŠ¤ë ˆë“œ ìˆ˜
    "enable_cache": False,         # ìºì‹œ í™œì„±í™”
    "cache_size": 100,             # ìºì‹œ í¬ê¸°
    "enable_logging": True,        # ë¡œê¹… í™œì„±í™”
    "log_level": "INFO"            # ë¡œê·¸ ë ˆë²¨
}
```

### ëª¨ë“ˆë³„ ì„¤ì •
```python
# Detection ëª¨ë“ˆ ì„¤ì •
DETECTION_CONFIG = {
    **COMMON_CONFIG,
    "confidence_threshold": 0.5,    # ì‹ ë¢°ë„ ì„ê³„ê°’
    "nms_threshold": 0.4,          # NMS ì„ê³„ê°’
    "min_detection_size": 20,      # ìµœì†Œ ê²€ì¶œ í¬ê¸°
    "max_detections": 100          # ìµœëŒ€ ê²€ì¶œ ìˆ˜
}

# Recognition ëª¨ë“ˆ ì„¤ì •
RECOGNITION_CONFIG = {
    **COMMON_CONFIG,
    "embedding_size": 512,          # ì„ë² ë”© ì°¨ì›
    "similarity_threshold": 0.6,    # ìœ ì‚¬ë„ ì„ê³„ê°’
    "distance_metric": "cosine",    # ê±°ë¦¬ ì¸¡ì • ë°©ì‹
    "enable_face_quality": True     # ì–¼êµ´ í’ˆì§ˆ ê²€ì‚¬
}

# Preprocessing ëª¨ë“ˆ ì„¤ì •
PREPROCESSING_CONFIG = {
    **COMMON_CONFIG,
    "resize": (640, 640),           # ë¦¬ì‚¬ì´ì¦ˆ í¬ê¸°
    "normalize": True,              # ì •ê·œí™” ì—¬ë¶€
    "mean": [0.485, 0.456, 0.406],  # í‰ê· ê°’
    "std": [0.229, 0.224, 0.225]    # í‘œì¤€í¸ì°¨
}
```

## ğŸš¨ ì£¼ì˜ì‚¬í•­

### 1. ëª¨ë¸ í˜¸í™˜ì„±
- ONNX ëª¨ë¸ë§Œ ì§€ì› (PyTorch ëª¨ë¸ì€ ë³€í™˜ í•„ìš”)
- ëª¨ë¸ ì…ë ¥/ì¶œë ¥ í˜•ì‹ í™•ì¸ í•„ìˆ˜
- ë²„ì „ í˜¸í™˜ì„± ê²€ì¦ í•„ìš”

### 2. ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­
- GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ë°°ì¹˜ í¬ê¸° ì¡°ì •
- CPU ì‚¬ìš© ì‹œ ìŠ¤ë ˆë“œ ìˆ˜ ìµœì í™”
- ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹œ íŒŒì´í”„ë¼ì¸ ìµœì í™”

### 3. ë©”ëª¨ë¦¬ ê´€ë¦¬
- ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- ë°°ì¹˜ í¬ê¸° ì¡°ì •ìœ¼ë¡œ ë©”ëª¨ë¦¬ ë¶€ì¡± ë°©ì§€
- ì„ì‹œ ê°ì²´ ìë™ ì •ë¦¬ ì„¤ì •

### 4. ì •í™•ë„ vs ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„
- ì‹ ë¢°ë„ ì„ê³„ê°’ ì¡°ì •ìœ¼ë¡œ ì •í™•ë„/ì†ë„ ê· í˜•
- ëª¨ë¸ ë³µì¡ë„ì— ë”°ë¥¸ í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­ í™•ì¸
- ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹œ í”„ë ˆì„ ìŠ¤í‚µ ê³ ë ¤

## ğŸ“ ì§€ì›

### ë¬¸ì œ í•´ê²°
1. **ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨**: ëª¨ë¸ ê²½ë¡œ ë° í˜•ì‹ í™•ì¸
2. **ë©”ëª¨ë¦¬ ë¶€ì¡±**: ë°°ì¹˜ í¬ê¸° ë° ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
3. **GPU ì˜¤ë¥˜**: CUDA ë²„ì „ ë° ë“œë¼ì´ë²„ í™•ì¸
4. **ì„±ëŠ¥ ì €í•˜**: ì„¤ì • ìµœì í™” ë° í•˜ë“œì›¨ì–´ í™•ì¸

### ì¶”ê°€ ë„ì›€ë§
- ê° ëª¨ë“ˆì˜ README.md ì°¸ì¡°
- ëª¨ë¸ íŒŒì¼ì˜ ë©”íƒ€ë°ì´í„° í™•ì¸
- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì°¸ì¡°
- GitHub Issuesì—ì„œ ìœ ì‚¬í•œ ë¬¸ì œ ê²€ìƒ‰

### ê¸°ì—¬ ë°©ë²•
1. ìƒˆë¡œìš´ ì•Œê³ ë¦¬ì¦˜ ì¶”ê°€ ì‹œ í•´ë‹¹ ëª¨ë“ˆì— êµ¬í˜„
2. ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜ ê°œì„  ì‹œ ë¬¸ì„œí™” ì¶”ê°€
3. ì„±ëŠ¥ ìµœì í™” ì œì•ˆ ì‹œ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ í¬í•¨
4. ë²„ê·¸ ë¦¬í¬íŠ¸ ì‹œ ìƒì„¸í•œ í™˜ê²½ ì •ë³´ í¬í•¨ 