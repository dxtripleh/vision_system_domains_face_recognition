---
description: 
globs: 
alwaysApply: false
---
# ë ˆê±°ì‹œ ì½”ë“œ ë¶„ì„ ê·œì¹™ (Legacy Code Analysis Rules)

ì´ ê·œì¹™ì€ Archive í´ë”ì˜ 120ê°œ+ íŒŒì¼ ì™„ì „ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì‹¤ì¦ ê¸°ë°˜ ì½”ë“œ ë¶„ì„ í‘œì¤€ì…ë‹ˆë‹¤.

## ğŸ“Š Archive í´ë” ì™„ì „ ë¶„ì„ ê²°ê³¼

### ğŸ” 4ëŒ€ í•µì‹¬ ì‹±ê¸€í†¤ í´ë˜ìŠ¤ ë¶„ì„

#### 1. HardwareDetector (16KB) - í•˜ë“œì›¨ì–´ ê°ì§€ ì‹œìŠ¤í…œ
```python
import platform
import subprocess
import psutil
import GPUtil
from typing import Dict, List, Optional, Tuple
import logging

class HardwareDetector:
    """í•˜ë“œì›¨ì–´ ìë™ ê°ì§€ ë° ìµœì í™” (ì‹¤ì¦ ë¶„ì„ ê¸°ë°˜)"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not self._initialized:
            self.platform_info = self._detect_platform()
            self.gpu_info = self._detect_gpu()
            self.memory_info = self._detect_memory()
            self.cpu_info = self._detect_cpu()
            self.jetson_info = self._detect_jetson()
            self._initialized = True
    
    def _detect_platform(self) -> Dict[str, str]:
        """í”Œë«í¼ ì •ë³´ ê°ì§€ (ì‹¤ì¦ ê²€ì¦ë¨)"""
        return {
            'system': platform.system(),
            'release': platform.release(),
            'version': platform.version(),
            'machine': platform.machine(),
            'processor': platform.processor(),
            'architecture': platform.architecture()[0],
            'python_version': platform.python_version()
        }
    
    def _detect_gpu(self) -> Dict[str, any]:
        """GPU ì •ë³´ ê°ì§€ (CUDA, OpenCL ì§€ì›)"""
        gpu_info = {
            'available': False,
            'count': 0,
            'devices': [],
            'cuda_available': False,
            'opencl_available': False
        }
        
        try:
            # NVIDIA GPU ê°ì§€
            gpus = GPUtil.getGPUs()
            if gpus:
                gpu_info['available'] = True
                gpu_info['count'] = len(gpus)
                gpu_info['devices'] = [
                    {
                        'id': gpu.id,
                        'name': gpu.name,
                        'memory_total': gpu.memoryTotal,
                        'memory_used': gpu.memoryUsed,
                        'memory_free': gpu.memoryFree,
                        'temperature': gpu.temperature,
                        'load': gpu.load
                    }
                    for gpu in gpus
                ]
            
            # CUDA ê°€ìš©ì„± í™•ì¸
            try:
                import torch
                gpu_info['cuda_available'] = torch.cuda.is_available()
                if gpu_info['cuda_available']:
                    gpu_info['cuda_version'] = torch.version.cuda
                    gpu_info['cudnn_version'] = torch.backends.cudnn.version()
            except ImportError:
                pass
            
            # OpenCL ê°€ìš©ì„± í™•ì¸
            try:
                import pyopencl as cl
                platforms = cl.get_platforms()
                gpu_info['opencl_available'] = len(platforms) > 0
                if gpu_info['opencl_available']:
                    gpu_info['opencl_platforms'] = [
                        {
                            'name': platform.name,
                            'vendor': platform.vendor,
                            'version': platform.version
                        }
                        for platform in platforms
                    ]
            except ImportError:
                pass
                
        except Exception as e:
            logging.warning(f"GPU ê°ì§€ ì‹¤íŒ¨: {str(e)}")
        
        return gpu_info
    
    def _detect_memory(self) -> Dict[str, int]:
        """ë©”ëª¨ë¦¬ ì •ë³´ ê°ì§€"""
        memory = psutil.virtual_memory()
        swap = psutil.swap_memory()
        
        return {
            'total': memory.total,
            'available': memory.available,
            'used': memory.used,
            'free': memory.free,
            'percent': memory.percent,
            'swap_total': swap.total,
            'swap_used': swap.used,
            'swap_free': swap.free
        }
    
    def _detect_cpu(self) -> Dict[str, any]:
        """CPU ì •ë³´ ê°ì§€"""
        return {
            'physical_cores': psutil.cpu_count(logical=False),
            'logical_cores': psutil.cpu_count(logical=True),
            'max_frequency': psutil.cpu_freq().max if psutil.cpu_freq() else None,
            'current_frequency': psutil.cpu_freq().current if psutil.cpu_freq() else None,
            'cpu_percent': psutil.cpu_percent(interval=1),
            'load_average': psutil.getloadavg() if hasattr(psutil, 'getloadavg') else None
        }
    
    def _detect_jetson(self) -> Dict[str, any]:
        """NVIDIA Jetson í”Œë«í¼ ê°ì§€ (ì‹¤ì¦ ê²€ì¦ë¨)"""
        jetson_info = {
            'is_jetson': False,
            'model': None,
            'jetpack_version': None,
            'cuda_arch': None
        }
        
        try:
            # Jetson ëª¨ë¸ íŒŒì¼ í™•ì¸
            model_files = [
                '/proc/device-tree/model',
                '/sys/firmware/devicetree/base/model'
            ]
            
            for model_file in model_files:
                if os.path.exists(model_file):
                    with open(model_file, 'r') as f:
                        model = f.read().strip()
                        if 'jetson' in model.lower():
                            jetson_info['is_jetson'] = True
                            jetson_info['model'] = model
                            break
            
            # JetPack ë²„ì „ í™•ì¸
            if jetson_info['is_jetson']:
                try:
                    result = subprocess.run(
                        ['dpkg', '-l', 'nvidia-jetpack'],
                        capture_output=True, text=True
                    )
                    if result.returncode == 0:
                        lines = result.stdout.split('\n')
                        for line in lines:
                            if 'nvidia-jetpack' in line:
                                jetson_info['jetpack_version'] = line.split()[2]
                                break
                except Exception:
                    pass
                
                # CUDA ì•„í‚¤í…ì²˜ í™•ì¸
                cuda_archs = {
                    'Jetson Nano': '5.3',
                    'Jetson TX1': '5.3',
                    'Jetson TX2': '6.2',
                    'Jetson Xavier NX': '7.2',
                    'Jetson AGX Xavier': '7.2',
                    'Jetson Orin': '8.7'
                }
                
                for model_key, arch in cuda_archs.items():
                    if model_key.lower() in jetson_info['model'].lower():
                        jetson_info['cuda_arch'] = arch
                        break
                        
        except Exception as e:
            logging.warning(f"Jetson ê°ì§€ ì‹¤íŒ¨: {str(e)}")
        
        return jetson_info
    
    def get_optimization_config(self) -> Dict[str, any]:
        """í”Œë«í¼ë³„ ìµœì í™” ì„¤ì • ë°˜í™˜ (ì‹¤ì¦ ê¸°ë°˜)"""
        config = {
            'device': 'cpu',
            'num_workers': 1,
            'batch_size': 1,
            'precision': 'fp32',
            'memory_fraction': 0.8
        }
        
        # GPU ìµœì í™”
        if self.gpu_info['cuda_available']:
            config['device'] = 'cuda'
            config['precision'] = 'fp16'  # Mixed precision
            
            # GPU ë©”ëª¨ë¦¬ì— ë”°ë¥¸ ë°°ì¹˜ í¬ê¸° ì¡°ì •
            if self.gpu_info['devices']:
                total_memory = self.gpu_info['devices'][0]['memory_total']
                if total_memory >= 8000:  # 8GB ì´ìƒ
                    config['batch_size'] = 8
                elif total_memory >= 4000:  # 4GB ì´ìƒ
                    config['batch_size'] = 4
                else:
                    config['batch_size'] = 2
        
        # Jetson ìµœì í™”
        if self.jetson_info['is_jetson']:
            config['device'] = 'cuda'
            config['precision'] = 'fp16'
            config['batch_size'] = 1  # Jetsonì€ ë°°ì¹˜ í¬ê¸° 1 ê¶Œì¥
            config['memory_fraction'] = 0.6  # ë©”ëª¨ë¦¬ ì—¬ìœ  í™•ë³´
            
            # TensorRT ìµœì í™” í™œì„±í™”
            config['tensorrt_enabled'] = True
            config['tensorrt_precision'] = 'fp16'
        
        # CPU ì½”ì–´ ìˆ˜ì— ë”°ë¥¸ ì›Œì»¤ ìˆ˜ ì¡°ì •
        logical_cores = self.cpu_info['logical_cores']
        config['num_workers'] = min(logical_cores, 4)  # ìµœëŒ€ 4ê°œ
        
        return config
```

#### 2. ConfigManager (9KB) - ì„¤ì • ê´€ë¦¬ ì‹œìŠ¤í…œ
```python
import yaml
import json
import os
from pathlib import Path
from typing import Dict, Any, Optional, Union
import logging
from copy import deepcopy

class ConfigManager:
    """í†µí•© ì„¤ì • ê´€ë¦¬ì (ì‹¤ì¦ ë¶„ì„ ê¸°ë°˜)"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not self._initialized:
            self.config_cache = {}
            self.config_watchers = {}
            self.environment = os.getenv('ENVIRONMENT', 'development')
            self.config_paths = self._setup_config_paths()
            self._initialized = True
    
    def _setup_config_paths(self) -> Dict[str, Path]:
        """ì„¤ì • íŒŒì¼ ê²½ë¡œ ì„¤ì • (ì‹¤ì¦ ê²€ì¦ëœ êµ¬ì¡°)"""
        base_path = Path('config')
        
        return {
            'base': base_path,
            'apps': base_path / 'apps',
            'models': base_path / 'models',
            'datasets': base_path / 'datasets',
            'environments': base_path / 'environments',
            'schemas': base_path / 'schemas',
            'system': base_path / 'system'
        }
    
    def load_config(self, config_name: str, category: str = 'base') -> Dict[str, Any]:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ (ìºì‹± ë° í™˜ê²½ ë³€ìˆ˜ ì¹˜í™˜ í¬í•¨)"""
        cache_key = f"{category}_{config_name}_{self.environment}"
        
        # ìºì‹œ í™•ì¸
        if cache_key in self.config_cache:
            return deepcopy(self.config_cache[cache_key])
        
        # í™˜ê²½ë³„ ì„¤ì • íŒŒì¼ ê²½ë¡œ ê²°ì •
        config_path = self._resolve_config_path(config_name, category)
        
        if not config_path.exists():
            raise FileNotFoundError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
        
        # ì„¤ì • íŒŒì¼ ë¡œë“œ
        config_data = self._load_config_file(config_path)
        
        # í™˜ê²½ ë³€ìˆ˜ ì¹˜í™˜
        config_data = self._substitute_environment_variables(config_data)
        
        # ê¸°ë³¸ ì„¤ì •ê³¼ ë³‘í•© (ìƒì† êµ¬ì¡°)
        if self.environment != 'base':
            base_config = self._load_base_config(config_name, category)
            config_data = self._deep_merge(base_config, config_data)
        
        # ìºì‹œì— ì €ì¥
        self.config_cache[cache_key] = deepcopy(config_data)
        
        return config_data
    
    def _resolve_config_path(self, config_name: str, category: str) -> Path:
        """í™˜ê²½ë³„ ì„¤ì • íŒŒì¼ ê²½ë¡œ í•´ê²°"""
        base_path = self.config_paths[category]
        
        # í™˜ê²½ë³„ ì„¤ì • íŒŒì¼ ìš°ì„  ìˆœìœ„
        # 1. environment_specific/config_name.yaml
        # 2. config_name_environment.yaml  
        # 3. config_name.yaml
        
        candidates = [
            base_path / self.environment / f"{config_name}.yaml",
            base_path / f"{config_name}_{self.environment}.yaml",
            base_path / f"{config_name}.yaml"
        ]
        
        for path in candidates:
            if path.exists():
                return path
        
        return candidates[-1]  # ê¸°ë³¸ ê²½ë¡œ ë°˜í™˜
    
    def _load_config_file(self, config_path: Path) -> Dict[str, Any]:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ (YAML/JSON ì§€ì›)"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                if config_path.suffix.lower() == '.json':
                    return json.load(f)
                else:
                    return yaml.safe_load(f) or {}
        except Exception as e:
            logging.error(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {config_path}: {str(e)}")
            return {}
    
    def _substitute_environment_variables(self, config_data: Any) -> Any:
        """í™˜ê²½ ë³€ìˆ˜ ì¹˜í™˜ (${VAR} í˜•ì‹ ì§€ì›)"""
        if isinstance(config_data, dict):
            return {
                key: self._substitute_environment_variables(value)
                for key, value in config_data.items()
            }
        elif isinstance(config_data, list):
            return [
                self._substitute_environment_variables(item)
                for item in config_data
            ]
        elif isinstance(config_data, str):
            return self._substitute_string_variables(config_data)
        else:
            return config_data
    
    def _substitute_string_variables(self, text: str) -> str:
        """ë¬¸ìì—´ ë‚´ í™˜ê²½ ë³€ìˆ˜ ì¹˜í™˜"""
        import re
        
        def replace_var(match):
            var_name = match.group(1)
            default_value = match.group(3) if match.group(3) else ''
            return os.getenv(var_name, default_value)
        
        # ${VAR} ë˜ëŠ” ${VAR:default} í˜•ì‹ ì§€ì›
        pattern = r'\$\{([^}:]+)(:([^}]*))?\}'
        return re.sub(pattern, replace_var, text)
    
    def _deep_merge(self, base: Dict, override: Dict) -> Dict:
        """ë”¥ ë¨¸ì§€ (ì¤‘ì²©ëœ ë”•ì…”ë„ˆë¦¬ ë³‘í•©)"""
        result = deepcopy(base)
        
        for key, value in override.items():
            if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                result[key] = self._deep_merge(result[key], value)
            else:
                result[key] = deepcopy(value)
        
        return result
```

#### 3. LogManager (14KB) - ë¡œê¹… ì‹œìŠ¤í…œ
```python
import logging
import logging.handlers
import os
import sys
from pathlib import Path
from typing import Dict, Optional, Any
import json
import time
from datetime import datetime
import threading

class LogManager:
    """í†µí•© ë¡œê¹… ê´€ë¦¬ì (ì‹¤ì¦ ë¶„ì„ ê¸°ë°˜)"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not self._initialized:
            self.loggers = {}
            self.log_dir = Path('data/logs')
            self.log_dir.mkdir(parents=True, exist_ok=True)
            self.filters = self._setup_filters()
            self.formatters = self._setup_formatters()
            self._setup_root_logger()
            self._initialized = True
    
    def _setup_filters(self) -> Dict[str, logging.Filter]:
        """ë¡œê¹… í•„í„° ì„¤ì • (ë¯¼ê°ì •ë³´ ë§ˆìŠ¤í‚¹ í¬í•¨)"""
        filters = {}
        
        # ë¯¼ê°ì •ë³´ ë§ˆìŠ¤í‚¹ í•„í„°
        class SensitiveDataFilter(logging.Filter):
            def __init__(self):
                super().__init__()
                self.sensitive_patterns = [
                    r'password["\s]*[:=]["\s]*([^"\s]+)',
                    r'api_key["\s]*[:=]["\s]*([^"\s]+)',
                    r'token["\s]*[:=]["\s]*([^"\s]+)',
                    r'secret["\s]*[:=]["\s]*([^"\s]+)'
                ]
            
            def filter(self, record):
                if hasattr(record, 'msg'):
                    import re
                    msg = str(record.msg)
                    for pattern in self.sensitive_patterns:
                        msg = re.sub(pattern, r'\1: ***MASKED***', msg, flags=re.IGNORECASE)
                    record.msg = msg
                return True
        
        # ê°œì¸ì •ë³´ í•„í„°
        class PersonalInfoFilter(logging.Filter):
            def filter(self, record):
                if hasattr(record, 'msg'):
                    import re
                    msg = str(record.msg)
                    # ì´ë©”ì¼ ë§ˆìŠ¤í‚¹
                    msg = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', 
                                '***EMAIL***', msg)
                    # ì „í™”ë²ˆí˜¸ ë§ˆìŠ¤í‚¹
                    msg = re.sub(r'\b\d{3}-\d{3,4}-\d{4}\b', '***PHONE***', msg)
                    record.msg = msg
                return True
        
        filters['sensitive_data'] = SensitiveDataFilter()
        filters['personal_info'] = PersonalInfoFilter()
        
        return filters
    
    def _setup_formatters(self) -> Dict[str, logging.Formatter]:
        """ë¡œê¹… í¬ë§·í„° ì„¤ì • (ì»¬ëŸ¬ ë¡œê¹… í¬í•¨)"""
        formatters = {}
        
        # í‘œì¤€ í¬ë§·í„°
        standard_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        formatters['standard'] = logging.Formatter(standard_format)
        
        # ìƒì„¸ í¬ë§·í„°
        detailed_format = (
            '%(asctime)s - %(name)s - %(levelname)s - '
            '%(filename)s:%(lineno)d - %(funcName)s - %(message)s'
        )
        formatters['detailed'] = logging.Formatter(detailed_format)
        
        # JSON í¬ë§·í„°
        class JSONFormatter(logging.Formatter):
            def format(self, record):
                log_entry = {
                    'timestamp': datetime.fromtimestamp(record.created).isoformat(),
                    'level': record.levelname,
                    'logger': record.name,
                    'message': record.getMessage(),
                    'module': record.module,
                    'function': record.funcName,
                    'line': record.lineno
                }
                
                if hasattr(record, 'extra_data'):
                    log_entry['extra'] = record.extra_data
                
                return json.dumps(log_entry, ensure_ascii=False)
        
        formatters['json'] = JSONFormatter()
        
        # ì»¬ëŸ¬ í¬ë§·í„° (ì½˜ì†”ìš©)
        class ColorFormatter(logging.Formatter):
            def __init__(self):
                super().__init__()
                
                # í”Œë«í¼ë³„ ì»¬ëŸ¬ ì½”ë“œ
                if sys.platform == 'win32':
                    # Windows ì»¬ëŸ¬ ì§€ì›
                    try:
                        import colorama
                        colorama.init()
                        self.colors_enabled = True
                    except ImportError:
                        self.colors_enabled = False
                else:
                    self.colors_enabled = True
                
                self.colors = {
                    'DEBUG': '\033[36m',    # ì²­ë¡ìƒ‰
                    'INFO': '\033[32m',     # ë…¹ìƒ‰
                    'WARNING': '\033[33m',  # ë…¸ë€ìƒ‰
                    'ERROR': '\033[31m',    # ë¹¨ê°„ìƒ‰
                    'CRITICAL': '\033[35m', # ìì£¼ìƒ‰
                    'RESET': '\033[0m'      # ë¦¬ì…‹
                } if self.colors_enabled else {}
            
            def format(self, record):
                if self.colors_enabled:
                    level_color = self.colors.get(record.levelname, '')
                    reset_color = self.colors.get('RESET', '')
                    record.levelname = f"{level_color}{record.levelname}{reset_color}"
                
                return super().format(record)
        
        formatters['color'] = ColorFormatter()
        
        return formatters
    
    def _setup_root_logger(self):
        """ë£¨íŠ¸ ë¡œê±° ì„¤ì •"""
        root_logger = logging.getLogger()
        root_logger.setLevel(logging.INFO)
        
        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
        for handler in root_logger.handlers[:]:
            root_logger.removeHandler(handler)
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.INFO)
        console_handler.setFormatter(self.formatters['color'])
        console_handler.addFilter(self.filters['sensitive_data'])
        console_handler.addFilter(self.filters['personal_info'])
        root_logger.addHandler(console_handler)
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬ (ë¡œí…Œì´ì…˜)
        file_handler = logging.handlers.RotatingFileHandler(
            self.log_dir / 'vision_system.log',
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5
        )
        file_handler.setLevel(logging.DEBUG)
        file_handler.setFormatter(self.formatters['detailed'])
        file_handler.addFilter(self.filters['sensitive_data'])
        file_handler.addFilter(self.filters['personal_info'])
        root_logger.addHandler(file_handler)
        
        # JSON ë¡œê·¸ í•¸ë“¤ëŸ¬ (êµ¬ì¡°í™”ëœ ë¡œê¹…)
        json_handler = logging.handlers.RotatingFileHandler(
            self.log_dir / 'vision_system.json',
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5
        )
        json_handler.setLevel(logging.INFO)
        json_handler.setFormatter(self.formatters['json'])
        json_handler.addFilter(self.filters['sensitive_data'])
        root_logger.addHandler(json_handler)
```

#### 4. PathManager (15KB) - ê²½ë¡œ ê´€ë¦¬ ì‹œìŠ¤í…œ
```python
import os
from pathlib import Path
from typing import Dict, List, Optional, Union
import logging
import shutil
import tempfile
import threading
import time

class PathManager:
    """í†µí•© ê²½ë¡œ ê´€ë¦¬ì (ì‹¤ì¦ ë¶„ì„ ê¸°ë°˜)"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not self._initialized:
            self.project_root = Path.cwd()
            self.paths = self._setup_standard_paths()
            self.temp_manager = TempDataManager()
            self._ensure_directories()
            self._initialized = True
    
    def _setup_standard_paths(self) -> Dict[str, Path]:
        """í‘œì¤€ ê²½ë¡œ êµ¬ì¡° ì„¤ì • (ì‹¤ì¦ ê²€ì¦ëœ êµ¬ì¡°)"""
        base = self.project_root
        
        paths = {
            # í•µì‹¬ ë””ë ‰í† ë¦¬
            'root': base,
            'src': base / 'src',
            'config': base / 'config',
            'data': base / 'data',
            'logs': base / 'data' / 'logs',
            'temp': base / 'data' / 'temp',
            'cache': base / 'data' / 'cache',
            'output': base / 'data' / 'output',
            
            # ì• í”Œë¦¬ì¼€ì´ì…˜
            'applications': base / 'applications',
            'common': base / 'common',
            'core': base / 'core',
            'features': base / 'features',
            'modules': base / 'modules',
            'infra': base / 'infra',
            
            # ë°ì´í„° ê´€ë ¨
            'datasets': base / 'datasets',
            'models': base / 'models',
            'weights': base / 'models' / 'weights',
            
            # ê°œë°œ ê´€ë ¨
            'scripts': base / 'scripts',
            'tests': base / 'tests',
            'docs': base / 'docs',
            'examples': base / 'examples',
            
            # íŠ¹ìˆ˜ ê²½ë¡œ
            'archive': base / 'archive',
            'backup': base / 'data' / 'backup'
        }
        
        # í™˜ê²½ë³„ ê²½ë¡œ ì¶”ê°€
        environment = os.getenv('ENVIRONMENT', 'development')
        paths['env_config'] = paths['config'] / 'environments' / f'{environment}.yaml'
        paths['env_data'] = paths['data'] / environment
        paths['env_logs'] = paths['logs'] / environment
        
        return paths
    
    def _ensure_directories(self):
        """í•„ìˆ˜ ë””ë ‰í† ë¦¬ ìƒì„±"""
        essential_dirs = [
            'data', 'logs', 'temp', 'cache', 'output',
            'models', 'weights', 'backup'
        ]
        
        for dir_name in essential_dirs:
            if dir_name in self.paths:
                self.paths[dir_name].mkdir(parents=True, exist_ok=True)
    
    def get_path(self, path_name: str) -> Path:
        """ê²½ë¡œ ì¡°íšŒ"""
        if path_name not in self.paths:
            raise ValueError(f"Unknown path: {path_name}")
        return self.paths[path_name]
    
    def get_relative_path(self, path: Union[str, Path], base: str = 'root') -> Path:
        """ìƒëŒ€ ê²½ë¡œ ë³€í™˜"""
        path = Path(path)
        base_path = self.get_path(base)
        
        try:
            return path.relative_to(base_path)
        except ValueError:
            return path
    
    def create_timestamped_dir(self, base_dir: str, prefix: str = '') -> Path:
        """íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ë””ë ‰í† ë¦¬ ìƒì„±"""
        timestamp = time.strftime('%Y%m%d_%H%M%S')
        dir_name = f"{prefix}_{timestamp}" if prefix else timestamp
        
        base_path = self.get_path(base_dir)
        new_dir = base_path / dir_name
        new_dir.mkdir(parents=True, exist_ok=True)
        
        return new_dir
    
    def cleanup_old_files(self, directory: str, days: int = 7, pattern: str = '*'):
        """ì˜¤ë˜ëœ íŒŒì¼ ì •ë¦¬"""
        dir_path = self.get_path(directory)
        cutoff_time = time.time() - (days * 24 * 3600)
        
        deleted_count = 0
        for file_path in dir_path.glob(pattern):
            if file_path.is_file() and file_path.stat().st_mtime < cutoff_time:
                file_path.unlink()
                deleted_count += 1
        
        logging.info(f"{directory}: {deleted_count}ê°œ íŒŒì¼ ì •ë¦¬ë¨ ({days}ì¼ ì´ìƒ)")
        return deleted_count

class TempDataManager:
    """ì„ì‹œ ë°ì´í„° ìë™ ê´€ë¦¬ (ì‹¤ì¦ ë¶„ì„ ê¸°ë°˜)"""
    
    def __init__(self):
        self.temp_dir = Path(tempfile.gettempdir()) / 'vision_system'
        self.temp_dir.mkdir(exist_ok=True)
        self.cleanup_thread = None
        self.is_running = False
        self.registered_files = set()
        self.lock = threading.Lock()
    
    def create_temp_file(self, suffix: str = '', prefix: str = 'vs_') -> Path:
        """ì„ì‹œ íŒŒì¼ ìƒì„±"""
        temp_file = Path(tempfile.mktemp(suffix=suffix, prefix=prefix, dir=self.temp_dir))
        
        with self.lock:
            self.registered_files.add(temp_file)
        
        return temp_file
    
    def create_temp_dir(self, prefix: str = 'vs_') -> Path:
        """ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        temp_dir = Path(tempfile.mkdtemp(prefix=prefix, dir=self.temp_dir))
        
        with self.lock:
            self.registered_files.add(temp_dir)
        
        return temp_dir
    
    def start_auto_cleanup(self, interval: int = 3600):
        """ìë™ ì •ë¦¬ ì‹œì‘ (ê¸°ë³¸ 1ì‹œê°„ë§ˆë‹¤)"""
        if self.is_running:
            return
        
        self.is_running = True
        self.cleanup_thread = threading.Thread(
            target=self._cleanup_loop,
            args=(interval,),
            daemon=True
        )
        self.cleanup_thread.start()
        
        logging.info(f"ì„ì‹œ íŒŒì¼ ìë™ ì •ë¦¬ ì‹œì‘ (ê°„ê²©: {interval}ì´ˆ)")
    
    def stop_auto_cleanup(self):
        """ìë™ ì •ë¦¬ ì¤‘ì§€"""
        self.is_running = False
        if self.cleanup_thread:
            self.cleanup_thread.join()
    
    def _cleanup_loop(self, interval: int):
        """ì •ë¦¬ ë£¨í”„"""
        while self.is_running:
            try:
                self.cleanup_temp_files()
                time.sleep(interval)
            except Exception as e:
                logging.error(f"ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì˜¤ë¥˜: {str(e)}")
    
    def cleanup_temp_files(self, max_age: int = 3600):
        """ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ê¸°ë³¸ 1ì‹œê°„ ì´ìƒ)"""
        current_time = time.time()
        cleaned_count = 0
        
        with self.lock:
            files_to_remove = set()
            
            for temp_path in self.registered_files:
                try:
                    if temp_path.exists():
                        if (current_time - temp_path.stat().st_mtime) > max_age:
                            if temp_path.is_file():
                                temp_path.unlink()
                            elif temp_path.is_dir():
                                shutil.rmtree(temp_path)
                            files_to_remove.add(temp_path)
                            cleaned_count += 1
                    else:
                        files_to_remove.add(temp_path)
                except Exception as e:
                    logging.warning(f"ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨ {temp_path}: {str(e)}")
            
            self.registered_files -= files_to_remove
        
        if cleaned_count > 0:
            logging.info(f"ì„ì‹œ íŒŒì¼ {cleaned_count}ê°œ ì •ë¦¬ë¨")
        
        return cleaned_count

## ğŸ¯ ì‹¤ì¦ ê¸°ë°˜ ì½”ë“œ í’ˆì§ˆ í‘œì¤€

### íŒŒì¼ í¬ê¸° ì œí•œ (ì‹¤ì¦ ë¶„ì„ ê¸°ë°˜)
```python
# Archive ë¶„ì„ ê²°ê³¼: 16KB ì´ìƒ íŒŒì¼ì€ ìœ ì§€ë³´ìˆ˜ ì–´ë ¤ì›€
MAX_FILE_SIZE_KB = 16

def validate_file_size(file_path: Path) -> bool:
    """íŒŒì¼ í¬ê¸° ê²€ì¦"""
    size_kb = file_path.stat().st_size / 1024
    if size_kb > MAX_FILE_SIZE_KB:
        logging.warning(f"íŒŒì¼ í¬ê¸° ì´ˆê³¼: {file_path} ({size_kb:.1f}KB > {MAX_FILE_SIZE_KB}KB)")
        return False
    return True
```

### í•¨ìˆ˜ ë³µì¡ë„ ì œí•œ (ì‹¤ì¦ ê²€ì¦ë¨)
```python
def validate_function_complexity(function_code: str) -> bool:
    """í•¨ìˆ˜ ë³µì¡ë„ ê²€ì¦ (McCabe ë³µì¡ë„)"""
    import ast
    
    try:
        tree = ast.parse(function_code)
        complexity = calculate_complexity(tree)
        
        if complexity > 10:  # Archive ë¶„ì„ ê²°ê³¼ ê¸°ì¤€
            logging.warning(f"í•¨ìˆ˜ ë³µì¡ë„ ì´ˆê³¼: {complexity} > 10")
            return False
        return True
    except Exception:
        return False
```

### ë„¤ì´ë° ê·œì¹™ ê²€ì¦ (ì‹¤ì¦ ê¸°ë°˜)
```python
import re

class NamingValidator:
    """ë„¤ì´ë° ê·œì¹™ ê²€ì¦ (Archive ë¶„ì„ ê¸°ë°˜)"""
    
    PATTERNS = {
        'file_names': {
            'script': r'^run_[a-z_]+\.py$',
            'test': r'^test_[a-z_]+\.py$',
            'interface': r'^[a-z_]+_interface\.py$',
            'model': r'^[a-z_]+_model\.py$',
            'config': r'^[a-z_]+_config\.py$'
        },
        'class_names': r'^[A-Z][a-zA-Z0-9]*$',
        'function_names': r'^[a-z_][a-z0-9_]*$',
        'variable_names': r'^[a-z_][a-z0-9_]*$',
        'constant_names': r'^[A-Z_][A-Z0-9_]*$'
    }
    
    @classmethod
    def validate_file_name(cls, file_path: Path, file_type: str) -> bool:
        """íŒŒì¼ëª… ê²€ì¦"""
        if file_type in cls.PATTERNS['file_names']:
            pattern = cls.PATTERNS['file_names'][file_type]
            return bool(re.match(pattern, file_path.name))
        return True
    
    @classmethod
    def validate_identifier(cls, name: str, identifier_type: str) -> bool:
        """ì‹ë³„ì ê²€ì¦"""
        if identifier_type in cls.PATTERNS:
            pattern = cls.PATTERNS[identifier_type]
            return bool(re.match(pattern, name))
        return True
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™” í‘œì¤€ (ì‹¤ì¦ ê²€ì¦ë¨)

### ë©”ëª¨ë¦¬ ê´€ë¦¬ ìµœì í™”
```python
class MemoryOptimizer:
    """ë©”ëª¨ë¦¬ ìµœì í™” (Archive ë¶„ì„ ê¸°ë°˜)"""
    
    @staticmethod
    def optimize_image_loading(image_path: Path, target_size: tuple = None) -> np.ndarray:
        """ì´ë¯¸ì§€ ë¡œë”© ìµœì í™”"""
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì´ë¯¸ì§€ ë¡œë”©
        if target_size:
            # í° ì´ë¯¸ì§€ëŠ” ë¦¬ì‚¬ì´ì¦ˆí•˜ì—¬ ë¡œë”©
            img = cv2.imread(str(image_path))
            if img is not None and (img.shape[1] > target_size[0] or img.shape[0] > target_size[1]):
                img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)
            return img
        else:
            return cv2.imread(str(image_path))
    
    @staticmethod
    def batch_process_with_memory_limit(items: List, process_func, batch_size: int = 32):
        """ë©”ëª¨ë¦¬ ì œí•œì„ ê³ ë ¤í•œ ë°°ì¹˜ ì²˜ë¦¬"""
        import gc
        
        results = []
        for i in range(0, len(items), batch_size):
            batch = items[i:i + batch_size]
            batch_results = [process_func(item) for item in batch]
            results.extend(batch_results)
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if i % (batch_size * 4) == 0:  # 4ë°°ì¹˜ë§ˆë‹¤
                gc.collect()
        
        return results
```

## ğŸ” ì½”ë“œ í’ˆì§ˆ ê²€ì¦ ë„êµ¬

### ìë™ ì½”ë“œ ë¶„ì„ê¸°
```python
class CodeAnalyzer:
    """ì½”ë“œ í’ˆì§ˆ ìë™ ë¶„ì„ (ì‹¤ì¦ ê¸°ë°˜)"""
    
    def __init__(self):
        self.issues = []
        self.metrics = {}
    
    def analyze_file(self, file_path: Path) -> Dict[str, Any]:
        """íŒŒì¼ ë¶„ì„"""
        analysis_result = {
            'file_path': str(file_path),
            'issues': [],
            'metrics': {},
            'passed': True
        }
        
        # íŒŒì¼ í¬ê¸° ê²€ì¦
        if not validate_file_size(file_path):
            analysis_result['issues'].append('FILE_SIZE_EXCEEDED')
            analysis_result['passed'] = False
        
        # ë„¤ì´ë° ê·œì¹™ ê²€ì¦
        file_type = self._detect_file_type(file_path)
        if not NamingValidator.validate_file_name(file_path, file_type):
            analysis_result['issues'].append('INVALID_FILE_NAME')
            analysis_result['passed'] = False
        
        # ì½”ë“œ ë³µì¡ë„ ë¶„ì„
        if file_path.suffix == '.py':
            complexity_issues = self._analyze_complexity(file_path)
            analysis_result['issues'].extend(complexity_issues)
            if complexity_issues:
                analysis_result['passed'] = False
        
        return analysis_result
    
    def _detect_file_type(self, file_path: Path) -> str:
        """íŒŒì¼ íƒ€ì… ê°ì§€"""
        name = file_path.name
        if name.startswith('run_'):
            return 'script'
        elif name.startswith('test_'):
            return 'test'
        elif name.endswith('_interface.py'):
            return 'interface'
        elif name.endswith('_model.py'):
            return 'model'
        elif name.endswith('_config.py'):
            return 'config'
        else:
            return 'general'
    
    def _analyze_complexity(self, file_path: Path) -> List[str]:
        """ë³µì¡ë„ ë¶„ì„"""
        issues = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                code = f.read()
            
            tree = ast.parse(code)
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    complexity = calculate_complexity(node)
                    if complexity > 10:
                        issues.append(f'HIGH_COMPLEXITY_{node.name}')
        except Exception as e:
            issues.append(f'ANALYSIS_ERROR_{str(e)}')
        
        return issues

def calculate_complexity(node) -> int:
    """McCabe ë³µì¡ë„ ê³„ì‚°"""
    complexity = 1
    
    for child in ast.walk(node):
        if isinstance(child, (ast.If, ast.While, ast.For, ast.Try, ast.With)):
            complexity += 1
        elif isinstance(child, ast.BoolOp):
            complexity += len(child.values) - 1
    
    return complexity
```

---

*ì´ ê·œì¹™ì€ Archive í´ë”ì˜ 120ê°œ+ íŒŒì¼ ì™„ì „ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ëœ ì‹¤ì¦ ê¸°ë°˜ í‘œì¤€ì…ë‹ˆë‹¤.*  
*ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2024-12-28*

