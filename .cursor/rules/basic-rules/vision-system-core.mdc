---
description: 
globs: 
alwaysApply: false
---
# ë¹„ì „ ì‹œìŠ¤í…œ í•µì‹¬ ê·œì¹™ (Basic)

## ğŸ¯ ë¹„ì „ ì‹œìŠ¤í…œ íŠ¹í™” ë„¤ì´ë°

### ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ ë„¤ì´ë°
**íŒ¨í„´**: `{task}_{architecture}_{dataset}_{date}.{ext}`

```python
# ì§€ì› íƒœìŠ¤í¬ (í˜„ì¬ ë‹¨ê³„)
SUPPORTED_TASKS = [
    'face_detection',     # ì–¼êµ´ ê°ì§€
    'face_recognition',   # ì–¼êµ´ ì¸ì‹
    'emotion',           # ê°ì • ì¸ì‹ (í–¥í›„)
    'landmark'           # ëœë“œë§ˆí¬ ì¶”ì¶œ (í–¥í›„)
]

# ì˜ˆì‹œ
EXAMPLES = [
    'face_detection_retinaface_widerface_20250628.pt',
    'face_recognition_arcface_glint360k_20250628.onnx',
    'emotion_resnet50_fer_20250628.onnx'
]
```

### ë„ë©”ì¸ íŒŒì¼ ë„¤ì´ë°
```python
# Core ê³„ì¸µ
face.py                      # ì—”í‹°í‹°
person.py                    # ì—”í‹°í‹°
face_detection_service.py    # ì„œë¹„ìŠ¤

# Infrastructure ê³„ì¸µ
retinaface_model.py         # AI ëª¨ë¸
arcface_model.py            # AI ëª¨ë¸
file_storage.py             # ì €ì¥ì†Œ

# Interfaces ê³„ì¸µ
face_recognition_api.py     # REST API
run_face_recognition.py     # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
```

## ğŸ–¥ï¸ ì¹´ë©”ë¼ ì‹œìŠ¤í…œ ê¸°ë³¸ ê·œì¹™

### í‘œì¤€ ì¹´ë©”ë¼ ì—°ê²°
```python
def connect_camera(camera_id: int = 0) -> cv2.VideoCapture:
    """í‘œì¤€ ì¹´ë©”ë¼ ì—°ê²° í•¨ìˆ˜"""
    cap = cv2.VideoCapture(camera_id)
    
    if not cap.isOpened():
        raise RuntimeError(f"Camera {camera_id} connection failed")
    
    # ê¸°ë³¸ í•´ìƒë„ ì„¤ì •
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    cap.set(cv2.CAP_PROP_FPS, 30)
    
    return cap
```

### ë¦¬ì†ŒìŠ¤ í•´ì œ ê·œì¹™
```python
def safe_camera_usage():
    """ì•ˆì „í•œ ì¹´ë©”ë¼ ì‚¬ìš© íŒ¨í„´"""
    cap = None
    try:
        cap = cv2.VideoCapture(0)
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
                
            # í”„ë ˆì„ ì²˜ë¦¬
            process_frame(frame)
            
            # ì¢…ë£Œ ì¡°ê±´ í™•ì¸
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
                
    finally:
        # ë°˜ë“œì‹œ ë¦¬ì†ŒìŠ¤ í•´ì œ
        if cap is not None:
            cap.release()
        cv2.destroyAllWindows()
```

## ğŸ® í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬ (í‘œì¤€)

### ê¸°ë³¸ í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤
```python
def handle_keyboard_input() -> str:
    """í‘œì¤€ í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤ ì²˜ë¦¬"""
    key = cv2.waitKey(1) & 0xFF
    
    if key == ord('q'):      # q: ì¢…ë£Œ
        return 'quit'
    elif key == ord('s'):    # s: í˜„ì¬ í”„ë ˆì„ ì €ì¥
        return 'save_frame'
    elif key == ord('r'):    # r: ë…¹í™” ì‹œì‘/ì¤‘ì§€
        return 'toggle_record'
    elif key == ord('p'):    # p: ì¼ì‹œ ì •ì§€/ì¬ìƒ
        return 'toggle_pause'
    elif key == ord('h'):    # h: ë„ì›€ë§ í‘œì‹œ
        return 'show_help'
    elif key == ord('c'):    # c: ì–¼êµ´ ìº¡ì²˜ (face_recognition ì „ìš©)
        return 'capture_face'
    
    return None
```

## ğŸ¤– ëª¨ë¸ ê´€ë¦¬ ê¸°ë³¸ ê·œì¹™

### í•˜ë“œì›¨ì–´ ê°ì§€ ë° ëª¨ë¸ ì„ íƒ
```python
def select_optimal_model() -> Dict:
    """í•˜ë“œì›¨ì–´ í™˜ê²½ì— ë”°ë¥¸ ìµœì  ëª¨ë¸ ì„ íƒ"""
    import torch
    
    if torch.cuda.is_available():
        # GPU í™˜ê²½
        return {
            'device': 'cuda',
            'model_type': 'retinaface_resnet50',
            'batch_size': 4,
            'precision': 'fp16'
        }
    else:
        # CPU í™˜ê²½  
        return {
            'device': 'cpu',
            'model_type': 'retinaface_mobilenet',
            'batch_size': 1,
            'precision': 'fp32'
        }
```

### ëª¨ë¸ ë¡œë”© í‘œì¤€
```python
def load_detection_model(model_path: str, device: str = 'cpu'):
    """í‘œì¤€ ëª¨ë¸ ë¡œë”© í•¨ìˆ˜"""
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Model file not found: {model_path}")
    
    try:
        # ëª¨ë¸ ë¡œë”© (PyTorch ì˜ˆì‹œ)
        model = torch.load(model_path, map_location=device)
        model.eval()
        
        logger.info(f"Model loaded successfully: {model_path}")
        return model
        
    except Exception as e:
        logger.error(f"Failed to load model {model_path}: {str(e)}")
        raise
```

## ğŸ“Š ê¸°ë³¸ ì„±ëŠ¥ ì¸¡ì •

### FPS ì¸¡ì •
```python
class FPSCounter:
    """ê°„ë‹¨í•œ FPS ì¸¡ì •ê¸°"""
    
    def __init__(self):
        self.frame_count = 0
        self.start_time = time.time()
        self.fps = 0.0
    
    def tick(self) -> float:
        """FPS ê³„ì‚° ë° ë°˜í™˜"""
        self.frame_count += 1
        elapsed = time.time() - self.start_time
        
        if elapsed > 1.0:  # 1ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸
            self.fps = self.frame_count / elapsed
            self.frame_count = 0
            self.start_time = time.time()
        
        return self.fps
```

### ê¸°ë³¸ ë¡œê¹…
```python
def setup_basic_logging():
    """ê¸°ë³¸ ë¡œê¹… ì„¤ì •"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('data/runtime/logs/vision_system.log'),
            logging.StreamHandler()
        ]
    )
```

## ğŸ”§ í•˜ë“œì›¨ì–´ ì—°ê²° ê²€ì¦

### ì‹œë®¬ë ˆì´ì…˜ ë°©ì§€ ê·œì¹™
```python
def verify_hardware_connection():
    """í•˜ë“œì›¨ì–´ ì—°ê²° ìƒíƒœ í™•ì¸ (ì‹œë®¬ë ˆì´ì…˜ ë°©ì§€)"""
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    if os.environ.get("USE_SIMULATION", "False").lower() == "true":
        raise RuntimeError("ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œëŠ” ê¸ˆì§€ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    
    # ì¹´ë©”ë¼ ì—°ê²° í™•ì¸
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        raise RuntimeError("ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨. í•˜ë“œì›¨ì–´ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    # í…ŒìŠ¤íŠ¸ í”„ë ˆì„ ì½ê¸°
    ret, frame = cap.read()
    cap.release()
    
    if not ret or frame is None:
        raise RuntimeError("ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ê°€ì§œ ë°ì´í„° ê°ì§€
    if frame.shape == (480, 640, 3) and np.all(frame == 0):
        raise RuntimeError("ê°€ì§œ ë°ì´í„°ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return True
```

## ğŸš« ë¹„ì „ ì‹œìŠ¤í…œ ê¸ˆì§€ ì‚¬í•­

### 1. í•˜ë“œì›¨ì–´ ê´€ë ¨
```python
# âŒ ì ˆëŒ€ ê¸ˆì§€
USE_SIMULATION = True
frame = np.zeros((480, 640, 3))  # ê°€ì§œ í”„ë ˆì„
cap = MockCamera()               # ê°€ì§œ ì¹´ë©”ë¼

# âœ… ì˜¬ë°”ë¥¸ ë°©ë²•
cap = cv2.VideoCapture(0)        # ì‹¤ì œ ì¹´ë©”ë¼
verify_hardware_connection()     # í•˜ë“œì›¨ì–´ ê²€ì¦
```

### 2. ë¦¬ì†ŒìŠ¤ ê´€ë¦¬
```python
# âŒ ì ˆëŒ€ ê¸ˆì§€
cap = cv2.VideoCapture(0)
# ... ì½”ë“œ ...
# cap.release() ëˆ„ë½

# âœ… ì˜¬ë°”ë¥¸ ë°©ë²•
try:
    cap = cv2.VideoCapture(0)
    # ... ì½”ë“œ ...
finally:
    cap.release()
    cv2.destroyAllWindows()
```

### 3. íŒŒì¼ ì €ì¥ ìœ„ì¹˜
```python
# âŒ ì ˆëŒ€ ê¸ˆì§€
cv2.imwrite("captured_frame.jpg", frame)  # ë£¨íŠ¸ì— ì €ì¥

# âœ… ì˜¬ë°”ë¥¸ ë°©ë²•
cv2.imwrite("data/runtime/output/captured_frame.jpg", frame)
```

## ğŸ“‹ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ í…œí”Œë¦¿

### ê¸°ë³¸ run ìŠ¤í¬ë¦½íŠ¸ êµ¬ì¡°
```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

Example:
    $ python run_face_recognition.py --source 0 --conf 0.5
"""

import argparse
import logging
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent.parent))

from common.logging import setup_logging
from common.config import load_config


def parse_args():
    """ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(description="ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œ")
    parser.add_argument("--source", type=str, default="0", 
                       help="ì…ë ¥ ì†ŒìŠ¤ (ì¹´ë©”ë¼ ID ë˜ëŠ” íŒŒì¼ ê²½ë¡œ)")
    parser.add_argument("--conf", type=float, default=0.5, 
                       help="ì‹ ë¢°ë„ ì„ê³„ê°’")
    parser.add_argument("--show", action="store_true", 
                       help="ê²°ê³¼ í™”ë©´ í‘œì‹œ")
    return parser.parse_args()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    args = parse_args()
    
    # ë¡œê¹… ì„¤ì •
    setup_logging()
    logger = logging.getLogger(__name__)
    
    try:
        # í•˜ë“œì›¨ì–´ ì—°ê²° ê²€ì¦
        verify_hardware_connection()
        
        # ë©”ì¸ ë¡œì§ ì‹¤í–‰
        logger.info("Starting face recognition system")
        
        # ... ì‹¤ì œ ì²˜ë¦¬ ë¡œì§ ...
        
    except KeyboardInterrupt:
        logger.info("Interrupted by user")
    except Exception as e:
        logger.error(f"Error: {e}")
        raise
    finally:
        logger.info("System shutdown completed")


if __name__ == "__main__":
    main()
```


---

**ì ìš© ìš°ì„ ìˆœìœ„**:
1. í•˜ë“œì›¨ì–´ ì—°ê²° ê²€ì¦ (í•„ìˆ˜)
2. ë¦¬ì†ŒìŠ¤ í•´ì œ ê·œì¹™ (í•„ìˆ˜)
3. í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬ (ê¶Œì¥)
4. ê¸°ë³¸ ì„±ëŠ¥ ì¸¡ì • (ê¶Œì¥)


