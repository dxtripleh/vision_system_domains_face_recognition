---
description: 
globs: 
alwaysApply: false
---
# ë‹¤ì¤‘ ë„ë©”ì¸ ê´€ë¦¬ (ADVANCED) - CROSS_PLATFORM_COMPATIBILITY í˜¸í™˜

## ğŸ—ï¸ ë„ë©”ì¸ í™•ì¥ ì „ëµ

### ìƒˆë¡œìš´ ë„ë©”ì¸ ì¶”ê°€ ì ˆì°¨ (CROSS_PLATFORM_COMPATIBILITY í˜¸í™˜)
```python
# ë„ë©”ì¸ ì¶”ê°€ ì‹œ ì²´í¬ë¦¬ìŠ¤íŠ¸
DOMAIN_ADDITION_CHECKLIST = {
    'preparation': [
        'domain_requirements_analysis',      # ë„ë©”ì¸ ìš”êµ¬ì‚¬í•­ ë¶„ì„
        'architecture_design',              # ì•„í‚¤í…ì²˜ ì„¤ê³„
        'data_strategy_planning',           # ë°ì´í„° ì „ëµ ê³„íš
        'integration_points_identification' # í†µí•© ì§€ì  ì‹ë³„
    ],
    'implementation': [
        'domain_structure_creation',        # ë„ë©”ì¸ êµ¬ì¡° ìƒì„± (CROSS_PLATFORM_COMPATIBILITY ê·œì¹™)
        'core_entities_definition',         # í•µì‹¬ ì—”í‹°í‹° ì •ì˜
        'services_implementation',          # ì„œë¹„ìŠ¤ êµ¬í˜„
        'infrastructure_setup',             # ì¸í”„ë¼ ì„¤ì •
        'interfaces_development'            # ì¸í„°í˜ì´ìŠ¤ ê°œë°œ
    ],
    'integration': [
        'shared_modules_extension',         # ê³µìœ  ëª¨ë“ˆ í™•ì¥
        'communication_channels_setup',     # í†µì‹  ì±„ë„ ì„¤ì •
        'event_system_integration',         # ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ í†µí•©
        'data_pipeline_connection'          # ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì—°ê²°
    ],
    'validation': [
        'unit_tests_creation',              # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ìƒì„±
        'integration_tests_development',    # í†µí•© í…ŒìŠ¤íŠ¸ ê°œë°œ
        'performance_testing',              # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        'end_to_end_testing'               # ì¢…ë‹¨ê°„ í…ŒìŠ¤íŠ¸
    ]
}

def create_new_domain(domain_name: str, feature_name: str):
    """ìƒˆë¡œìš´ ë„ë©”ì¸ ê¸°ëŠ¥ ìƒì„± (CROSS_PLATFORM_COMPATIBILITY ê·œì¹™)"""
    
    from pathlib import Path  # CROSS_PLATFORM_COMPATIBILITY í•„ìˆ˜
    
    # 1. ë„ë©”ì¸ ê¸°ëŠ¥ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
    domain_path = Path("domains") / domain_name / feature_name
    
    # í•„ìˆ˜ íŒŒì¼ ëª©ë¡ (CROSS_PLATFORM_COMPATIBILITY ê·œì¹™)
    required_files = [
        '__init__.py',
        'model.py',        # ONNX ëª¨ë¸ í´ë˜ìŠ¤
        'run.py',          # ì‹¤ì‹œê°„ ì¶”ë¡  ì‹¤í–‰
        'test_model.py',   # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
        'README.md'        # ê¸°ëŠ¥ ì„¤ëª…
    ]
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    domain_path.mkdir(parents=True, exist_ok=True)
    
    # í•„ìˆ˜ íŒŒì¼ ìƒì„±
    for file_name in required_files:
        file_path = domain_path / file_name
        if not file_path.exists():
            if file_name == '__init__.py':
                content = f'"""Domain: {domain_name} - Feature: {feature_name}"""\n'
            elif file_name == 'model.py':
                content = f'''#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
{domain_name} {feature_name} ONNX ëª¨ë¸ í´ë˜ìŠ¤.

ì´ ëª¨ë“ˆì€ {feature_name} ê¸°ëŠ¥ì˜ ONNX ëª¨ë¸ ë¡œë”© ë° ì¶”ë¡  ì²˜ë¦¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import sys
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union
import numpy as np
import onnxruntime as ort

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from common.logging import get_logger

logger = get_logger(__name__)

class {feature_name.title().replace('_', '')}Model:
    """{feature_name} ONNX ëª¨ë¸ í´ë˜ìŠ¤"""
    
    def __init__(self, model_path: Optional[str] = None, config: Optional[Dict] = None):
        """ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            model_path: ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            config: ëª¨ë¸ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        self.config = config or {{}}
        
        # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
        if model_path is None:
            model_path = project_root / "models" / "weights" / f"{feature_name}.onnx"
        
        self.model_path = Path(model_path)
        
        if not self.model_path.exists():
            raise FileNotFoundError(f"Model file not found: {{self.model_path}}")
        
        # ONNX ëŸ°íƒ€ì„ ì„¸ì…˜ ìƒì„±
        self._create_session()
        
        logger.info(f"{feature_name.title().replace('_', '')}Model initialized")
    
    def _create_session(self):
        """ONNX ëŸ°íƒ€ì„ ì„¸ì…˜ ìƒì„±"""
        try:
            # í•˜ë“œì›¨ì–´ í™˜ê²½ì— ë”°ë¥¸ ìµœì í™” í”„ë¡œë°”ì´ë” ì„ íƒ
            providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
            self.session = ort.InferenceSession(str(self.model_path), providers=providers)
            logger.info(f"ONNX session created with providers: {{self.session.get_providers()}}")
        except Exception as e:
            logger.error(f"Failed to create ONNX session: {{e}}")
            raise
    
    def predict(self, image: np.ndarray) -> List[Dict]:
        """ì´ë¯¸ì§€ ì¶”ë¡ 
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (numpy ë°°ì—´)
            
        Returns:
            ì¶”ë¡  ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # ì „ì²˜ë¦¬
            input_data = self._preprocess(image)
            
            # ì¶”ë¡ 
            outputs = self.session.run(None, {{'input': input_data}})
            
            # í›„ì²˜ë¦¬
            results = self._postprocess(outputs)
            
            return results
            
        except Exception as e:
            logger.error(f"Prediction failed: {{e}}")
            raise
    
    def _preprocess(self, image: np.ndarray) -> np.ndarray:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        # TODO: êµ¬í˜„ í•„ìš”
        return image
    
    def _postprocess(self, outputs: List[np.ndarray]) -> List[Dict]:
        """ì¶”ë¡  ê²°ê³¼ í›„ì²˜ë¦¬"""
        # TODO: êµ¬í˜„ í•„ìš”
        return []
'''
            elif file_name == 'run.py':
                content = f'''#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
{domain_name} {feature_name} ì‹¤ì‹œê°„ ì¶”ë¡  ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸.

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” USB ì¹´ë©”ë¼ ë˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ì‹¤ì‹œê°„ ì¶”ë¡ ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
"""

import os
import sys
import argparse
import logging
import cv2
import time
from pathlib import Path
from typing import Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from common.logging import setup_logging
from common.config import load_config
from .model import {feature_name.title().replace('_', '')}Model

def get_optimal_config():
    """í•˜ë“œì›¨ì–´ í™˜ê²½ì— ë”°ë¥¸ ìµœì  ì„¤ì • ìë™ ì„ íƒ"""
    import platform, psutil
    system = platform.system().lower()
    cpu_count = psutil.cpu_count()
    memory_gb = psutil.virtual_memory().total // (1024**3)
    
    try:
        import torch
        gpu_available = torch.cuda.is_available()
        gpu_memory = torch.cuda.get_device_properties(0).total_memory // (1024**3) if gpu_available else 0
    except:
        gpu_available = False
        gpu_memory = 0
    
    if gpu_available and gpu_memory >= 16:
        return {{"device": "cuda", "batch_size": 16, "model_size": "large", "precision": "fp16"}}
    elif gpu_available and gpu_memory >= 4:
        return {{"device": "cuda", "batch_size": 4, "model_size": "medium", "precision": "fp16"}}
    else:
        return {{"device": "cpu", "batch_size": 1, "model_size": "small", "precision": "fp32"}}

def is_jetson():
    """Jetson í™˜ê²½ ê°ì§€"""
    try:
        with open("/proc/device-tree/model", "r") as f:
            return "jetson" in f.read().lower()
    except:
        return False

def create_platform_camera(camera_id=0, config=None):
    """í”Œë«í¼ë³„ ì¹´ë©”ë¼ ìƒì„±"""
    import platform
    system = platform.system().lower()
    
    if system == "windows":
        cap = cv2.VideoCapture(camera_id, cv2.CAP_DSHOW)
        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M','J','P','G'))
    elif system == "linux":
        cap = cv2.VideoCapture(camera_id, cv2.CAP_V4L2)
        if is_jetson():
            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
    else:
        cap = cv2.VideoCapture(camera_id)
    
    return cap

def parse_args():
    """ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(description="{feature_name} ì‹¤ì‹œê°„ ì¶”ë¡ ")
    parser.add_argument("--source", type=str, default="0", help="ì…ë ¥ ì†ŒìŠ¤ (ì¹´ë©”ë¼ ID, íŒŒì¼ ê²½ë¡œ)")
    parser.add_argument("--model", type=str, help="ëª¨ë¸ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--config", type=str, help="ì„¤ì • íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--conf", type=float, default=0.5, help="ì‹ ë¢°ë„ ì„ê³„ê°’")
    parser.add_argument("--show", action="store_true", help="ê²°ê³¼ í™”ë©´ í‘œì‹œ")
    parser.add_argument("--save", action="store_true", help="ê²°ê³¼ ì €ì¥")
    return parser.parse_args()

def handle_keyboard_input():
    """í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬"""
    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'):
        return 'quit'
    elif key == ord('s'):
        return 'save_frame'
    elif key == ord('r'):
        return 'toggle_record'
    elif key == ord('p'):
        return 'toggle_pause'
    return None

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    args = parse_args()
    
    # ë¡œê¹… ì„¤ì •
    setup_logging()
    logger = logging.getLogger(__name__)
    
    # ì„¤ì • ë¡œë“œ
    config = load_config(args.config)
    
    try:
        # í•˜ë“œì›¨ì–´ ìµœì í™” ì„¤ì •
        optimal_config = get_optimal_config()
        logger.info(f"Optimal config: {{optimal_config}}")
        
        # ëª¨ë¸ ë¡œë”©
        model = {feature_name.title().replace('_', '')}Model(args.model, config)
        
        # ì…ë ¥ ì†ŒìŠ¤ ì„¤ì •
        if args.source.isdigit():
            cap = create_platform_camera(int(args.source))
        else:
            cap = cv2.VideoCapture(args.source)
        
        if not cap.isOpened():
            logger.error(f"Cannot open source: {{args.source}}")
            return
        
        # ë©”ì¸ ì²˜ë¦¬ ë£¨í”„
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # ì¶”ë¡  ì‹¤í–‰
            start_time = time.time()
            results = model.predict(frame)
            processing_time = time.time() - start_time
            
            # ê²°ê³¼ ì‹œê°í™”
            if args.show:
                # TODO: ê²°ê³¼ ì‹œê°í™” êµ¬í˜„
                cv2.imshow('Result', frame)
                
                # í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬
                action = handle_keyboard_input()
                if action == 'quit':
                    break
                elif action == 'save_frame':
                    output_path = project_root / "data" / "runtime" / "output" / f"frame_{{int(time.time())}}.jpg"
                    cv2.imwrite(str(output_path), frame)
                    logger.info(f"Frame saved: {{output_path}}")
        
        cap.release()
        cv2.destroyAllWindows()
        
    except KeyboardInterrupt:
        logger.info("Interrupted by user")
    except Exception as e:
        logger.error(f"Error: {{e}}")
        raise
    finally:
        logger.info("Finished {feature_name}")

if __name__ == "__main__":
    main()
'''
            elif file_name == 'test_model.py':
                content = f'''#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
{domain_name} {feature_name} ëª¨ë¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸.

ì´ ëª¨ë“ˆì€ {feature_name} ëª¨ë¸ì˜ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import sys
import unittest
import numpy as np
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from .model import {feature_name.title().replace('_', '')}Model

class Test{feature_name.title().replace('_', '')}Model(unittest.TestCase):
    """{feature_name.title().replace('_', '')}Model í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def setUp(self):
        """í…ŒìŠ¤íŠ¸ ì„¤ì •"""
        # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
        self.test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        
        # ëª¨ë¸ ì´ˆê¸°í™” (ëª¨ë¸ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬)
        try:
            self.model = {feature_name.title().replace('_', '')}Model()
        except FileNotFoundError:
            self.skipTest("Model file not found")
    
    def test_model_initialization(self):
        """ëª¨ë¸ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        self.assertIsNotNone(self.model)
        self.assertIsNotNone(self.model.session)
    
    def test_prediction(self):
        """ì¶”ë¡  í…ŒìŠ¤íŠ¸"""
        results = self.model.predict(self.test_image)
        self.assertIsInstance(results, list)
    
    def test_preprocessing(self):
        """ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        input_data = self.model._preprocess(self.test_image)
        self.assertIsInstance(input_data, np.ndarray)
    
    def test_postprocessing(self):
        """í›„ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        # ë”ë¯¸ ì¶œë ¥ ìƒì„±
        dummy_outputs = [np.random.rand(1, 100, 100)]
        results = self.model._postprocess(dummy_outputs)
        self.assertIsInstance(results, list)

if __name__ == '__main__':
    unittest.main()
'''
            elif file_name == 'README.md':
                content = f'''# {domain_name.title()} - {feature_name.title()}

## ê°œìš”

ì´ ëª¨ë“ˆì€ {domain_name} ë„ë©”ì¸ì˜ {feature_name} ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

## ê¸°ëŠ¥

- ì‹¤ì‹œê°„ {feature_name} ì¶”ë¡ 
- ONNX ëª¨ë¸ ê¸°ë°˜ ì²˜ë¦¬
- í¬ë¡œìŠ¤ í”Œë«í¼ í˜¸í™˜ì„±

## ì‚¬ìš©ë²•

### ê¸°ë³¸ ì‹¤í–‰
```bash
python run.py
```

### ì¹´ë©”ë¼ ì§€ì •
```bash
python run.py --source 1
```

### ì´ë¯¸ì§€ íŒŒì¼
```bash
python run.py --source path/to/image.jpg
```

### ì„¤ì • íŒŒì¼ ì§€ì •
```bash
python run.py --config config.yaml
```

## íŒŒì¼ êµ¬ì¡°

- `model.py`: ONNX ëª¨ë¸ í´ë˜ìŠ¤
- `run.py`: ì‹¤ì‹œê°„ ì¶”ë¡  ì‹¤í–‰
- `test_model.py`: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

## ìš”êµ¬ì‚¬í•­

- Python 3.10+
- ONNX Runtime
- OpenCV
- NumPy
'''
            else:
                content = ""
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
    
    print(f"âœ“ Domain feature '{domain_name}/{feature_name}' created successfully")
    print(f"âœ“ Created files: {{', '.join(required_files)}}")
    print(f"âœ“ Location: {{domain_path}}")
```

### ë‹¤ì¤‘ ë„ë©”ì¸ í™•ì¥ ê³„íš (CROSS_PLATFORM_COMPATIBILITY í˜¸í™˜)
```python
# í–¥í›„ ë„ë©”ì¸ í™•ì¥ ë¡œë“œë§µ
DOMAIN_EXPANSION_ROADMAP = {
    'factory_defect': {
        'priority': 'high',
        'estimated_timeline': '3-4 months',
        'dependencies': ['vision_core', 'monitoring_system'],
        'features': [
            'defect_detection',      # ë¶ˆëŸ‰ ê²€ì¶œ
            'quality_assessment',    # í’ˆì§ˆ í‰ê°€
            'classification'         # ë¶„ë¥˜
        ],
        'requirements': {
            'hardware': ['industrial_cameras', 'lighting_system'],
            'models': ['defect_detection.onnx', 'classification.onnx'],
            'data': ['factory_samples', 'defect_annotations']
        },
        'integration_points': [
            'shared.vision_core.detection',
            'shared.vision_core.preprocessing',
            'quality_metrics_tracking'
        ]
    },
    'powerline_inspection': {
        'priority': 'medium',
        'estimated_timeline': '4-6 months',
        'dependencies': ['vision_core', 'drone_integration'],
        'features': [
            'inspection',           # ê²€ì‚¬
            'defect_detection',     # ê²°í•¨ ê²€ì¶œ
            'thermal_analysis'      # ì—´í™”ìƒ ë¶„ì„
        ],
        'requirements': {
            'hardware': ['drone_cameras', 'gps_module', 'thermal_camera'],
            'models': ['powerline_detection.onnx', 'defect_classification.onnx'],
            'data': ['aerial_images', 'thermal_data', 'gps_coordinates']
        },
        'integration_points': [
            'shared.vision_core.detection',
            'shared.vision_core.tracking',
            'geolocation_services'
        ]
    },
    'medical_imaging': {
        'priority': 'low',
        'estimated_timeline': '6-8 months',
        'dependencies': ['vision_core', 'security_enhanced', 'privacy_compliance'],
        'features': [
            'anomaly_detection',    # ì´ìƒ ê²€ì¶œ
            'segmentation',         # ì„¸ê·¸ë©˜í…Œì´ì…˜
            'diagnosis_support'     # ì§„ë‹¨ ì§€ì›
        ],
        'requirements': {
            'hardware': ['medical_scanners', 'dicom_compatible'],
            'models': ['anomaly_detection.onnx', 'segmentation.onnx'],
            'data': ['medical_images', 'anonymized_datasets', 'expert_annotations']
        },
        'integration_points': [
            'shared.vision_core.preprocessing',
            'shared.security.gdpr_compliance',
            'medical_data_protection'
        ]
    }
}
```

## ğŸ”— ë„ë©”ì¸ ê°„ í†µì‹  ì‹œìŠ¤í…œ (CROSS_PLATFORM_COMPATIBILITY í˜¸í™˜)

### ì´ë²¤íŠ¸ ê¸°ë°˜ í†µì‹ 
```python
# shared/communication/event_bus.py
from abc import ABC, abstractmethod
from typing import Dict, List, Callable, Any
import asyncio
import json
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path  # CROSS_PLATFORM_COMPATIBILITY í•„ìˆ˜

@dataclass
class DomainEvent:
    """ë„ë©”ì¸ ì´ë²¤íŠ¸ ê¸°ë³¸ í´ë˜ìŠ¤"""
    event_id: str
    domain: str
    feature: str  # CROSS_PLATFORM_COMPATIBILITY ê·œì¹™ì— ë§ì¶° feature ì¶”ê°€
    event_type: str
    data: Dict[str, Any]
    timestamp: datetime
    version: str = "1.0"

class EventHandler(ABC):
    """ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì¶”ìƒ í´ë˜ìŠ¤"""
    
    @abstractmethod
    async def handle(self, event: DomainEvent) -> None:
        pass

class EventBus:
    """ë„ë©”ì¸ ê°„ ì´ë²¤íŠ¸ ë²„ìŠ¤"""
    
    def __init__(self):
        self.handlers: Dict[str, List[EventHandler]] = {}
        self.event_store: List[DomainEvent] = []
        
        # ì´ë²¤íŠ¸ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ (CROSS_PLATFORM_COMPATIBILITY)
        project_root = Path(__file__).parent.parent.parent
        self.log_path = project_root / "data" / "runtime" / "logs" / "events.log"
        self.log_path.parent.mkdir(parents=True, exist_ok=True)
        
    def subscribe(self, event_type: str, handler: EventHandler):
        """ì´ë²¤íŠ¸ êµ¬ë…"""
        if event_type not in self.handlers:
            self.handlers[event_type] = []
        self.handlers[event_type].append(handler)
    
    async def publish(self, event: DomainEvent):
        """ì´ë²¤íŠ¸ ë°œí–‰"""
        # ì´ë²¤íŠ¸ ì €ì¥
        self.event_store.append(event)
        
        # ì´ë²¤íŠ¸ ë¡œê·¸ ê¸°ë¡
        self._log_event(event)
        
        # í•¸ë“¤ëŸ¬ë“¤ì—ê²Œ ì´ë²¤íŠ¸ ì „ë‹¬
        if event.event_type in self.handlers:
            tasks = [
                handler.handle(event) 
                for handler in self.handlers[event.event_type]
            ]
            await asyncio.gather(*tasks, return_exceptions=True)
    
    def _log_event(self, event: DomainEvent):
        """ì´ë²¤íŠ¸ ë¡œê·¸ ê¸°ë¡"""
        try:
            with open(self.log_path, 'a', encoding='utf-8') as f:
                log_entry = {
                    'timestamp': event.timestamp.isoformat(),
                    'domain': event.domain,
                    'feature': event.feature,
                    'event_type': event.event_type,
                    'data': event.data
                }
                f.write(json.dumps(log_entry) + '\n')
        except Exception as e:
            print(f"Failed to log event: {e}")
    
    def get_events_by_domain(self, domain: str) -> List[DomainEvent]:
        """ë„ë©”ì¸ë³„ ì´ë²¤íŠ¸ ì¡°íšŒ"""
        return [event for event in self.event_store if event.domain == domain]
    
    def get_events_by_feature(self, domain: str, feature: str) -> List[DomainEvent]:
        """ë„ë©”ì¸/ê¸°ëŠ¥ë³„ ì´ë²¤íŠ¸ ì¡°íšŒ"""
        return [event for event in self.event_store 
                if event.domain == domain and event.feature == feature]

# ì´ë²¤íŠ¸ ë²„ìŠ¤ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
event_bus = EventBus()
```

### ë„ë©”ì¸ë³„ ì´ë²¤íŠ¸ ì •ì˜ (CROSS_PLATFORM_COMPATIBILITY í˜¸í™˜)
```python
# ì–¼êµ´ì¸ì‹ ë„ë©”ì¸ ì´ë²¤íŠ¸
class FaceDetectedEvent(DomainEvent):
    """ì–¼êµ´ ê°ì§€ ì´ë²¤íŠ¸"""
    
    def __init__(self, face_data: Dict):
        super().__init__(
            event_id=f"face_detected_{int(time.time())}",
            domain="face_recognition",
            feature="detection",  # CROSS_PLATFORM_COMPATIBILITY ê·œì¹™
            event_type="face_detected",
            data=face_data,
            timestamp=datetime.now()
        )

class FaceRecognizedEvent(DomainEvent):
    """ì–¼êµ´ ì¸ì‹ ì´ë²¤íŠ¸"""
    
    def __init__(self, recognition_data: Dict):
        super().__init__(
            event_id=f"face_recognized_{int(time.time())}",
            domain="face_recognition",
            feature="recognition",  # CROSS_PLATFORM_COMPATIBILITY ê·œì¹™
            event_type="face_recognized",
            data=recognition_data,
            timestamp=datetime.now()
        )

# ê³µì¥ ë¶ˆëŸ‰ ê²€ì¶œ ë„ë©”ì¸ ì´ë²¤íŠ¸ (í–¥í›„)
class DefectDetectedEvent(DomainEvent):
    """ë¶ˆëŸ‰ ê²€ì¶œ ì´ë²¤íŠ¸"""
    
    def __init__(self, defect_data: Dict):
        super().__init__(
            event_id=f"defect_detected_{int(time.time())}",
            domain="factory_defect",
            feature="defect_detection",  # CROSS_PLATFORM_COMPATIBILITY ê·œì¹™
            event_type="defect_detected",
            data=defect_data,
            timestamp=datetime.now()
        )
```

## ğŸ”„ ê³µìœ  ëª¨ë“ˆ í™•ì¥ ê´€ë¦¬

### Shared ëª¨ë“ˆ í™•ì¥ ì „ëµ
```python
# shared ëª¨ë“ˆ í™•ì¥ ê³„íš
SHARED_MODULE_EXPANSION = {
    'vision_core': {
        'current_modules': [
            'detection',           # ê°ì²´/ì–¼êµ´ ê²€ì¶œ
            'recognition',         # ì¸ì‹
            'preprocessing',       # ì „ì²˜ë¦¬
            'postprocessing'       # í›„ì²˜ë¦¬
        ],
        'planned_modules': [
            'tracking',           # ê°ì²´ ì¶”ì  (factory_defectìš©)
            'pose_estimation',    # ìì„¸ ì¶”ì • (powerline_inspectionìš©)
            'thermal_analysis',   # ì—´í™”ìƒ ë¶„ì„ (powerline_inspectionìš©)
            'medical_processing'  # ì˜ë£Œ ì˜ìƒ ì²˜ë¦¬ (medical_imagingìš©)
        ]
    },
    'communication': {
        'current_modules': [
            'event_bus',          # ì´ë²¤íŠ¸ ë²„ìŠ¤
            'data_manager'        # ë°ì´í„° ê´€ë¦¬
        ],
        'planned_modules': [
            'message_queue',      # ë©”ì‹œì§€ í (ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ìš©)
            'real_time_sync',     # ì‹¤ì‹œê°„ ë™ê¸°í™” (ë‹¤ì¤‘ ì¹´ë©”ë¼ìš©)
            'distributed_cache'   # ë¶„ì‚° ìºì‹œ (í™•ì¥ì„±ìš©)
        ]
    },
    'quality': {
        'current_modules': [],
        'planned_modules': [
            'metrics_aggregator', # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°
            'quality_dashboard',  # í’ˆì§ˆ ëŒ€ì‹œë³´ë“œ
            'alert_system',       # ì•Œë¦¼ ì‹œìŠ¤í…œ
            'reporting'           # ë¦¬í¬íŒ… ì‹œìŠ¤í…œ
        ]
    }
}

def extend_shared_module(module_name: str, new_component: str):
    """ê³µìœ  ëª¨ë“ˆ í™•ì¥"""
    
    # 1. ìƒˆë¡œìš´ ì»´í¬ë„ŒíŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
    component_path = f"shared/{module_name}/{new_component}"
    os.makedirs(component_path, exist_ok=True)
    
    # 2. __init__.py íŒŒì¼ ìƒì„±
    init_file = os.path.join(component_path, '__init__.py')
    with open(init_file, 'w') as f:
        f.write(f'"""Shared module: {module_name}.{new_component}"""\n')
    
    # 3. ê¸°ë³¸ êµ¬í˜„ íŒŒì¼ ìƒì„±
    impl_file = os.path.join(component_path, f'{new_component}.py')
    with open(impl_file, 'w') as f:
        f.write(generate_component_template(module_name, new_component))
    
    # 4. í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    test_dir = f"tests/shared/{module_name}"
    os.makedirs(test_dir, exist_ok=True)
    
    test_file = os.path.join(test_dir, f'test_{new_component}.py')
    with open(test_file, 'w') as f:
        f.write(generate_test_template(module_name, new_component))
    
    print(f"âœ“ Shared module component '{module_name}.{new_component}' created")

def generate_component_template(module_name: str, component_name: str) -> str:
    """ì»´í¬ë„ŒíŠ¸ í…œí”Œë¦¿ ìƒì„±"""
    template = f'''#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
{module_name}.{component_name} ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ {component_name} ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import logging
from typing import Dict, List, Optional, Any

logger = logging.getLogger(__name__)

class {component_name.title().replace('_', '')}:
    """{ component_name.replace('_', ' ').title()} í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.initialized = False
        self._setup()
    
    def _setup(self):
        """ì´ˆê¸° ì„¤ì •"""
        logger.info(f"Initializing {{self.__class__.__name__}}")
        self.initialized = True
    
    def process(self, data: Any) -> Any:
        """ë©”ì¸ ì²˜ë¦¬ ë©”ì„œë“œ"""
        if not self.initialized:
            raise RuntimeError("Component not initialized")
        
        # êµ¬í˜„ í•„ìš”
        raise NotImplementedError("Subclass must implement process method")

# íŒ©í† ë¦¬ í•¨ìˆ˜
def create_{component_name}() -> {component_name.title().replace('_', '')}:
    """{ component_name.replace('_', ' ').title()} ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return {component_name.title().replace('_', '')}()
'''
    return template
```

## ğŸ“Š ë‹¤ì¤‘ ë„ë©”ì¸ ë©”íŠ¸ë¦­ ê´€ë¦¬

### í†µí•© ë©”íŠ¸ë¦­ ì‹œìŠ¤í…œ
```python
# shared/quality/metrics_aggregator.py
class DomainMetricsAggregator:
    """ë„ë©”ì¸ë³„ ë©”íŠ¸ë¦­ í†µí•© ê´€ë¦¬"""
    
    def __init__(self):
        self.domain_metrics = {}
        self.metric_definitions = {}
    
    def register_domain_metrics(self, domain: str, metrics_config: Dict):
        """ë„ë©”ì¸ë³„ ë©”íŠ¸ë¦­ ë“±ë¡"""
        self.domain_metrics[domain] = {
            'config': metrics_config,
            'current_values': {},
            'history': []
        }
    
    def update_metric(self, domain: str, metric_name: str, value: float):
        """ë©”íŠ¸ë¦­ ê°’ ì—…ë°ì´íŠ¸"""
        if domain not in self.domain_metrics:
            raise ValueError(f"Domain {domain} not registered")
        
        self.domain_metrics[domain]['current_values'][metric_name] = value
        self.domain_metrics[domain]['history'].append({
            'metric': metric_name,
            'value': value,
            'timestamp': datetime.now()
        })
    
    def get_cross_domain_summary(self) -> Dict:
        """ë„ë©”ì¸ ê°„ ë©”íŠ¸ë¦­ ìš”ì•½"""
        summary = {
            'total_domains': len(self.domain_metrics),
            'active_domains': 0,
            'overall_health': 'healthy',
            'domain_status': {}
        }
        
        for domain, metrics in self.domain_metrics.items():
            domain_health = self._calculate_domain_health(domain, metrics)
            summary['domain_status'][domain] = domain_health
            
            if domain_health['status'] == 'active':
                summary['active_domains'] += 1
        
        # ì „ì²´ ì‹œìŠ¤í…œ ê±´ê°•ë„ ê³„ì‚°
        if summary['active_domains'] == 0:
            summary['overall_health'] = 'inactive'
        elif any(status['health'] == 'critical' for status in summary['domain_status'].values()):
            summary['overall_health'] = 'critical'
        elif any(status['health'] == 'warning' for status in summary['domain_status'].values()):
            summary['overall_health'] = 'warning'
        
        return summary
    
    def _calculate_domain_health(self, domain: str, metrics: Dict) -> Dict:
        """ë„ë©”ì¸ ê±´ê°•ë„ ê³„ì‚°"""
        current_values = metrics['current_values']
        config = metrics['config']
        
        health_score = 1.0
        status = 'active'
        issues = []
        
        for metric_name, thresholds in config.get('thresholds', {}).items():
            if metric_name in current_values:
                value = current_values[metric_name]
                
                if 'min' in thresholds and value < thresholds['min']:
                    health_score *= 0.7
                    issues.append(f"{metric_name} below minimum: {value} < {thresholds['min']}")
                
                if 'max' in thresholds and value > thresholds['max']:
                    health_score *= 0.7
                    issues.append(f"{metric_name} above maximum: {value} > {thresholds['max']}")
        
        # ê±´ê°•ë„ ë¶„ë¥˜
        if health_score >= 0.8:
            health = 'healthy'
        elif health_score >= 0.6:
            health = 'warning'
        else:
            health = 'critical'
        
        return {
            'status': status,
            'health': health,
            'score': health_score,
            'issues': issues,
            'metrics_count': len(current_values)
        }

# ë„ë©”ì¸ë³„ ë©”íŠ¸ë¦­ ì„¤ì • ì˜ˆì‹œ
DOMAIN_METRICS_CONFIG = {
    'face_recognition': {
        'thresholds': {
            'fps': {'min': 15.0, 'max': 60.0},
            'accuracy': {'min': 0.85, 'max': 1.0},
            'processing_time_ms': {'min': 0.0, 'max': 100.0}
        },
        'alerts': {
            'low_fps': {'condition': 'fps < 15', 'severity': 'warning'},
            'high_latency': {'condition': 'processing_time_ms > 100', 'severity': 'critical'}
        }
    },
    'factory_defect': {  # í–¥í›„
        'thresholds': {
            'defect_rate': {'min': 0.0, 'max': 0.05},
            'false_positive_rate': {'min': 0.0, 'max': 0.02},
            'throughput_per_hour': {'min': 100.0, 'max': 1000.0}
        },
        'alerts': {
            'high_defect_rate': {'condition': 'defect_rate > 0.05', 'severity': 'critical'},
            'low_throughput': {'condition': 'throughput_per_hour < 100', 'severity': 'warning'}
        }
    }
}
```

## ğŸ”§ ë„ë©”ì¸ ë…ë¦½ì„± ë³´ì¥

### ì˜ì¡´ì„± ê²€ì¦ ì‹œìŠ¤í…œ
```python
# scripts/validation/check_domain_independence.py
def validate_domain_independence():
    """ë„ë©”ì¸ ë…ë¦½ì„± ê²€ì¦"""
    
    violations = []
    
    # 1. ì§ì ‘ import ê²€ì¦
    direct_import_violations = check_direct_domain_imports()
    violations.extend(direct_import_violations)
    
    # 2. ìˆœí™˜ ì˜ì¡´ì„± ê²€ì¦
    circular_dependencies = check_circular_dependencies()
    violations.extend(circular_dependencies)
    
    # 3. ê³µìœ  ëª¨ë“ˆ ì‚¬ìš© ê²€ì¦
    shared_module_violations = check_shared_module_usage()
    violations.extend(shared_module_violations)
    
    # 4. ë¦¬í¬íŠ¸ ìƒì„±
    generate_independence_report(violations)
    
    return len(violations) == 0

def check_direct_domain_imports():
    """ë„ë©”ì¸ ê°„ ì§ì ‘ import ê²€ì‚¬"""
    violations = []
    
    for domain_dir in os.listdir('domains/'):
        if not os.path.isdir(f'domains/{domain_dir}'):
            continue
        
        for py_file in Path(f'domains/{domain_dir}').rglob('*.py'):
            with open(py_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # domains.other_domain import íŒ¨í„´ ê²€ì‚¬
            import_pattern = r'from\s+domains\.([^.]+)'
            matches = re.findall(import_pattern, content)
            
            for imported_domain in matches:
                if imported_domain != domain_dir:
                    violations.append({
                        'type': 'direct_domain_import',
                        'file': str(py_file),
                        'source_domain': domain_dir,
                        'target_domain': imported_domain,
                        'severity': 'critical'
                    })
    
    return violations

def check_circular_dependencies():
    """ìˆœí™˜ ì˜ì¡´ì„± ê²€ì‚¬"""
    # ê°„ë‹¨í•œ ìˆœí™˜ ì˜ì¡´ì„± ê²€ì‚¬ êµ¬í˜„
    # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ê·¸ë˜í”„ ë¶„ì„ì´ í•„ìš”
    return []

def generate_independence_report(violations):
    """ë…ë¦½ì„± ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±"""
    report = {
        'timestamp': datetime.now().isoformat(),
        'total_violations': len(violations),
        'violations_by_type': {},
        'violations': violations
    }
    
    # ìœ í˜•ë³„ ìœ„ë°˜ ìˆ˜ ì§‘ê³„
    for violation in violations:
        vtype = violation['type']
        if vtype not in report['violations_by_type']:
            report['violations_by_type'][vtype] = 0
        report['violations_by_type'][vtype] += 1
    
    # ë¦¬í¬íŠ¸ ì €ì¥
    with open('data/runtime/logs/domain_independence_report.json', 'w') as f:
        json.dump(report, f, indent=2)
    
    # ì½˜ì†” ì¶œë ¥
    if violations:
        print(f"âŒ Found {len(violations)} domain independence violations")
        for violation in violations:
            print(f"  - {violation['type']}: {violation['file']}")
    else:
        print("âœ“ Domain independence validation passed")
```


---

**ì ìš© ì‹œì **: factory_defect ë˜ëŠ” powerline_inspection ë„ë©”ì¸ ì¶”ê°€ ì‹œ
**ì˜ì¡´ì„±**: `pip install asyncio dataclasses`
**ì„¤ì •**: ì´ë²¤íŠ¸ ë²„ìŠ¤, ë°ì´í„° ê³„ì•½, ë©”íŠ¸ë¦­ ì •ì˜ í•„ìš”


