#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸.

ì–¼êµ´ì¸ì‹ì— í•„ìš”í•œ AI ëª¨ë¸ë“¤ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì„¤ì •í•©ë‹ˆë‹¤.
"""

import os
import sys
import time
import hashlib
import requests
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from urllib.parse import urlparse

def create_directories():
    """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
    directories = [
        "models/weights",
        "models/metadata", 
        "models/configs",
        "data/temp"
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
        print(f"ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±: {directory}")

def calculate_file_hash(file_path: str, algorithm: str = 'sha256') -> str:
    """íŒŒì¼ í•´ì‹œ ê³„ì‚°"""
    hash_func = hashlib.new(algorithm)
    
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_func.update(chunk)
    
    return hash_func.hexdigest()

def download_file(url: str, output_path: str, expected_hash: Optional[str] = None) -> bool:
    """íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    try:
        print(f"â¬‡ï¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {os.path.basename(output_path)}")
        print(f"   URL: {url}")
        
        response = requests.get(url, stream=True)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        downloaded_size = 0
        
        with open(output_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    downloaded_size += len(chunk)
                    
                    if total_size > 0:
                        progress = (downloaded_size / total_size) * 100
                        print(f"\r   ì§„í–‰ë¥ : {progress:.1f}% ({downloaded_size}/{total_size} bytes)", end='')
        
        print()  # ìƒˆ ì¤„
        
        # í•´ì‹œ ê²€ì¦
        if expected_hash:
            actual_hash = calculate_file_hash(output_path)
            if actual_hash != expected_hash:
                print(f"âŒ í•´ì‹œ ê²€ì¦ ì‹¤íŒ¨:")
                print(f"   ì˜ˆìƒ: {expected_hash}")
                print(f"   ì‹¤ì œ: {actual_hash}")
                os.remove(output_path)
                return False
            else:
                print(f"âœ… í•´ì‹œ ê²€ì¦ ì„±ê³µ")
        
        print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {output_path}")
        return True
        
    except Exception as e:
        print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        if os.path.exists(output_path):
            os.remove(output_path)
        return False

def download_opencv_models():
    """OpenCV ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
    print("\nğŸ” OpenCV ëª¨ë¸ ë‹¤ìš´ë¡œë“œ")
    print("=" * 50)
    
    models = {
        "haarcascade_frontalface_default.xml": {
            "url": "https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml",
            "description": "OpenCV Haar Cascade ì–¼êµ´ ê²€ì¶œ ëª¨ë¸"
        },
        "haarcascade_eye.xml": {
            "url": "https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_eye.xml", 
            "description": "OpenCV Haar Cascade ëˆˆ ê²€ì¶œ ëª¨ë¸"
        }
    }
    
    success_count = 0
    
    for filename, info in models.items():
        output_path = f"models/weights/{filename}"
        
        if os.path.exists(output_path):
            print(f"â­ï¸ ì´ë¯¸ ì¡´ì¬í•¨: {filename}")
            success_count += 1
            continue
        
        print(f"\nğŸ“¥ {info['description']}")
        if download_file(info['url'], output_path):
            success_count += 1
    
    print(f"\nğŸ“Š OpenCV ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {success_count}/{len(models)}")
    return success_count == len(models)

def download_onnx_models():
    """ONNX ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì‹¤ì œ URLì€ ì‚¬ìš©ìê°€ ì œê³µí•´ì•¼ í•¨)"""
    print("\nğŸ¤– ONNX AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ")
    print("=" * 50)
    
    # ì‹¤ì œ ëª¨ë¸ URLë“¤ (ì˜ˆì‹œ - ì‹¤ì œë¡œëŠ” ìœ íš¨í•œ URLë¡œ êµì²´ í•„ìš”)
    models = {
        "retinaface_r50.onnx": {
            "url": "https://example.com/models/retinaface_r50.onnx",  # ì‹¤ì œ URLë¡œ êµì²´ í•„ìš”
            "description": "RetinaFace ì–¼êµ´ ê²€ì¶œ ëª¨ë¸ (ResNet-50)",
            "size_mb": 100,
            "hash": None  # ì‹¤ì œ í•´ì‹œê°’ìœ¼ë¡œ êµì²´ í•„ìš”
        },
        "arcface_r100.onnx": {
            "url": "https://example.com/models/arcface_r100.onnx",  # ì‹¤ì œ URLë¡œ êµì²´ í•„ìš”
            "description": "ArcFace ì–¼êµ´ ì¸ì‹ ëª¨ë¸ (ResNet-100)",
            "size_mb": 200,
            "hash": None  # ì‹¤ì œ í•´ì‹œê°’ìœ¼ë¡œ êµì²´ í•„ìš”
        }
    }
    
    print("âš ï¸ ì£¼ì˜: ONNX ëª¨ë¸ì€ ì‹¤ì œ URLì´ í•„ìš”í•©ë‹ˆë‹¤.")
    print("í˜„ì¬ëŠ” ì˜ˆì‹œ URLì´ë¯€ë¡œ ë‹¤ìš´ë¡œë“œê°€ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("ì‹¤ì œ ëª¨ë¸ íŒŒì¼ì„ ì§ì ‘ ë‹¤ìš´ë¡œë“œí•˜ì—¬ models/weights/ í´ë”ì— ì €ì¥í•˜ì„¸ìš”.")
    
    success_count = 0
    
    for filename, info in models.items():
        output_path = f"models/weights/{filename}"
        
        if os.path.exists(output_path):
            print(f"â­ï¸ ì´ë¯¸ ì¡´ì¬í•¨: {filename}")
            success_count += 1
            continue
        
        print(f"\nğŸ“¥ {info['description']} (~{info['size_mb']}MB)")
        
        # ì‹¤ì œ URLì´ ì•„ë‹ˆë¯€ë¡œ ê±´ë„ˆë›°ê¸°
        print(f"â­ï¸ ê±´ë„ˆë›°ê¸°: ì‹¤ì œ URL í•„ìš” ({filename})")
        
        # ì‹¤ì œ ë‹¤ìš´ë¡œë“œë¥¼ ì›í•œë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
        # if download_file(info['url'], output_path, info['hash']):
        #     success_count += 1
    
    print(f"\nğŸ“Š ONNX ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {success_count}/{len(models)}")
    return True  # ì‹¤ì œë¡œëŠ” success_count == len(models)

def create_model_configs():
    """ëª¨ë¸ ì„¤ì • íŒŒì¼ ìƒì„±"""
    print("\nâš™ï¸ ëª¨ë¸ ì„¤ì • íŒŒì¼ ìƒì„±")
    print("=" * 50)
    
    # OpenCV ëª¨ë¸ ì„¤ì •
    opencv_config = {
        "haarcascade_frontalface": {
            "model_path": "models/weights/haarcascade_frontalface_default.xml",
            "model_type": "opencv_cascade",
            "input_format": "grayscale",
            "parameters": {
                "scaleFactor": 1.1,
                "minNeighbors": 5,
                "minSize": [30, 30],
                "maxSize": [300, 300]
            }
        }
    }
    
    # ONNX ëª¨ë¸ ì„¤ì •
    onnx_config = {
        "retinaface": {
            "model_path": "models/weights/retinaface_r50.onnx",
            "model_type": "onnx",
            "input_size": [640, 640],
            "input_format": "rgb",
            "confidence_threshold": 0.5,
            "nms_threshold": 0.4
        },
        "arcface": {
            "model_path": "models/weights/arcface_r100.onnx", 
            "model_type": "onnx",
            "input_size": [112, 112],
            "input_format": "rgb",
            "embedding_size": 512,
            "normalize": True
        }
    }
    
    # í†µí•© ì„¤ì •
    model_config = {
        "default_detection_model": "haarcascade_frontalface",
        "default_recognition_model": "arcface",
        "models": {
            **opencv_config,
            **onnx_config
        }
    }
    
    # ì„¤ì • íŒŒì¼ ì €ì¥
    import json
    config_path = "models/configs/model_config.json"
    
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(model_config, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… ëª¨ë¸ ì„¤ì • íŒŒì¼ ìƒì„±: {config_path}")
    
    # ë©”íƒ€ë°ì´í„° íŒŒì¼ ìƒì„±
    metadata = {
        "created_at": time.strftime('%Y-%m-%d %H:%M:%S'),
        "version": "1.0",
        "models": {
            "opencv": {
                "haarcascade_frontalface_default.xml": {
                    "type": "face_detection",
                    "framework": "opencv",
                    "accuracy": "medium",
                    "speed": "fast"
                }
            },
            "onnx": {
                "retinaface_r50.onnx": {
                    "type": "face_detection", 
                    "framework": "onnx",
                    "accuracy": "high",
                    "speed": "medium"
                },
                "arcface_r100.onnx": {
                    "type": "face_recognition",
                    "framework": "onnx", 
                    "accuracy": "high",
                    "speed": "medium"
                }
            }
        }
    }
    
    metadata_path = "models/metadata/models_metadata.json"
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… ë©”íƒ€ë°ì´í„° íŒŒì¼ ìƒì„±: {metadata_path}")

def check_dependencies():
    """ì˜ì¡´ì„± í™•ì¸"""
    print("\nğŸ” ì˜ì¡´ì„± í™•ì¸")
    print("=" * 50)
    
    dependencies = {
        "opencv-python": "cv2",
        "numpy": "numpy",
        "requests": "requests"
    }
    
    optional_dependencies = {
        "onnxruntime": "onnxruntime",
        "onnxruntime-gpu": "onnxruntime"  # GPU ë²„ì „
    }
    
    missing_deps = []
    
    # í•„ìˆ˜ ì˜ì¡´ì„± í™•ì¸
    for package, module in dependencies.items():
        try:
            __import__(module)
            print(f"âœ… {package}: ì„¤ì¹˜ë¨")
        except ImportError:
            print(f"âŒ {package}: ëˆ„ë½")
            missing_deps.append(package)
    
    # ì„ íƒì  ì˜ì¡´ì„± í™•ì¸
    print("\nì„ íƒì  ì˜ì¡´ì„±:")
    for package, module in optional_dependencies.items():
        try:
            __import__(module)
            print(f"âœ… {package}: ì„¤ì¹˜ë¨")
        except ImportError:
            print(f"âš ï¸ {package}: ëˆ„ë½ (AI ëª¨ë¸ ì‚¬ìš©ì„ ìœ„í•´ ê¶Œì¥)")
    
    if missing_deps:
        print(f"\nâŒ ëˆ„ë½ëœ í•„ìˆ˜ ì˜ì¡´ì„±: {', '.join(missing_deps)}")
        print("ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print(f"pip install {' '.join(missing_deps)}")
        return False
    
    print("\nâœ… ëª¨ë“  í•„ìˆ˜ ì˜ì¡´ì„±ì´ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")
    return True

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ¤– AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œìŠ¤í…œ")
    print("=" * 60)
    print("ì–¼êµ´ì¸ì‹ì— í•„ìš”í•œ AI ëª¨ë¸ë“¤ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì„¤ì •í•©ë‹ˆë‹¤.")
    print("=" * 60)
    
    # ì˜ì¡´ì„± í™•ì¸
    if not check_dependencies():
        print("\nâŒ ì˜ì¡´ì„± ë¬¸ì œë¡œ ì¸í•´ ì¤‘ë‹¨ë©ë‹ˆë‹¤.")
        return 1
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    create_directories()
    
    # OpenCV ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    opencv_success = download_opencv_models()
    
    # ONNX ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    onnx_success = download_onnx_models()
    
    # ì„¤ì • íŒŒì¼ ìƒì„±
    create_model_configs()
    
    # ê²°ê³¼ ìš”ì•½
    print("\nğŸ“Š ë‹¤ìš´ë¡œë“œ ê²°ê³¼ ìš”ì•½")
    print("=" * 50)
    print(f"OpenCV ëª¨ë¸: {'âœ… ì„±ê³µ' if opencv_success else 'âŒ ì‹¤íŒ¨'}")
    print(f"ONNX ëª¨ë¸: {'âš ï¸ ìˆ˜ë™ ì„¤ì¹˜ í•„ìš”' if onnx_success else 'âŒ ì‹¤íŒ¨'}")
    print(f"ì„¤ì • íŒŒì¼: âœ… ìƒì„± ì™„ë£Œ")
    
    print("\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
    print("1. ONNX ëª¨ë¸ì„ ì§ì ‘ ë‹¤ìš´ë¡œë“œí•˜ì—¬ models/weights/ í´ë”ì— ì €ì¥")
    print("2. python run_simple_demo.py ë¡œ OpenCV ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    print("3. ONNX ëª¨ë¸ ì„¤ì¹˜ í›„ python run_face_recognition_demo.py í…ŒìŠ¤íŠ¸")
    
    print("\nâœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ì™„ë£Œ!")
    return 0

if __name__ == "__main__":
    sys.exit(main()) 