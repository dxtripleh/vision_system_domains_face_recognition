#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì–¼êµ´ ì¸ì‹ ë°ëª¨.

ì–¼êµ´ ê²€ì¶œê³¼ ì¸ì‹ ê¸°ëŠ¥ì„ í¬í•¨í•œ ì™„ì „í•œ ë°ëª¨ì…ë‹ˆë‹¤.
"""

import cv2
import numpy as np
import sys
import os
import time
import json
from pathlib import Path
from typing import Dict, List, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from common.logging import setup_logging, get_logger
from domains.face_recognition.core.services.face_detection_service import FaceDetectionService
from domains.face_recognition.core.services.face_recognition_service import FaceRecognitionService

logger = get_logger(__name__)

class FaceRecognitionDemo:
    """ì–¼êµ´ ì¸ì‹ ë°ëª¨ í´ë˜ìŠ¤"""
    
    def __init__(self, camera_id: int = 0):
        """ì´ˆê¸°í™”"""
        self.camera_id = camera_id
        self.camera = None
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.detection_service = FaceDetectionService(
            config={
                'min_confidence': 0.5,
                'min_face_size': (80, 80),
                'max_faces': 5
            }
        )
        self.recognition_service = FaceRecognitionService(use_mock=True)
        
        # UI ìƒíƒœ
        self.show_info = True
        self.frame_count = 0
        self.start_time = time.time()
        self.registered_persons = {}
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.create_directories()
        
        # ë“±ë¡ëœ ì¸ë¬¼ ë¡œë“œ
        self.load_registered_persons()
    
    def create_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        directories = [
            "data/output", "data/logs", "data/temp",
            "data/storage/faces", "data/storage/persons"
        ]
        for directory in directories:
            Path(directory).mkdir(parents=True, exist_ok=True)
    
    def load_registered_persons(self):
        """ë“±ë¡ëœ ì¸ë¬¼ ì •ë³´ ë¡œë“œ"""
        try:
            persons = self.recognition_service.get_all_persons()
            self.registered_persons = {p.person_id: p.name for p in persons}
            logger.info(f"ë“±ë¡ëœ ì¸ë¬¼ {len(self.registered_persons)}ëª… ë¡œë“œ")
        except Exception as e:
            logger.warning(f"ë“±ë¡ëœ ì¸ë¬¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            self.registered_persons = {}
    
    def initialize_camera(self) -> bool:
        """ì¹´ë©”ë¼ ì´ˆê¸°í™”"""
        try:
            self.camera = cv2.VideoCapture(self.camera_id)
            
            if not self.camera.isOpened():
                logger.error(f"ì¹´ë©”ë¼ {self.camera_id} ì—´ê¸° ì‹¤íŒ¨")
                return False
            
            # ì¹´ë©”ë¼ ì„¤ì •
            self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.camera.set(cv2.CAP_PROP_FPS, 30)
            
            logger.info("ì¹´ë©”ë¼ ì´ˆê¸°í™” ì„±ê³µ")
            return True
            
        except Exception as e:
            logger.error(f"ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            return False
    
    def process_frame(self, frame: np.ndarray) -> np.ndarray:
        """í”„ë ˆì„ ì²˜ë¦¬"""
        try:
            # ì–¼êµ´ ê²€ì¶œ
            detection_result = self.detection_service.detect_faces(frame)
            faces = detection_result.faces
            
            # ê° ì–¼êµ´ì— ëŒ€í•´ ì¸ì‹ ìˆ˜í–‰
            for i, face in enumerate(faces):
                x, y, w, h = face.bbox.x, face.bbox.y, face.bbox.width, face.bbox.height
                
                # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
                face_region = frame[y:y+h, x:x+w]
                
                # ì–¼êµ´ ì¸ì‹ ì‹œë„
                person_name = "Unknown"
                confidence = face.confidence.value
                
                try:
                    if face_region.size > 0:
                        # ì„ë² ë”© ì¶”ì¶œ (Mock ëª¨ë“œì—ì„œëŠ” ë”ë¯¸ ì„ë² ë”©)
                        embedding = self.recognition_service.extract_embedding(face_region)
                        face.embedding = embedding
                        
                        # ì¸ë¬¼ ì‹ë³„
                        identified_person = self.recognition_service.identify_face(face)
                        if identified_person:
                            person_name = identified_person.name
                except Exception as e:
                    logger.debug(f"ì–¼êµ´ ì¸ì‹ ì˜¤ë¥˜: {str(e)}")
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ìƒ‰ìƒ ê²°ì •
                if person_name != "Unknown":
                    color = (0, 255, 0)  # ë…¹ìƒ‰ - ì•Œë ¤ì§„ ì¸ë¬¼
                else:
                    color = (0, 255, 255)  # ë…¸ë€ìƒ‰ - ë¯¸ì§€ì˜ ì¸ë¬¼
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
                
                # ë¼ë²¨ í…ìŠ¤íŠ¸
                label = f"{person_name} ({confidence:.2f})"
                
                # ë¼ë²¨ ë°°ê²½
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
                cv2.rectangle(frame, (x, y - label_size[1] - 10), 
                             (x + label_size[0], y), color, -1)
                
                # ë¼ë²¨ í…ìŠ¤íŠ¸
                cv2.putText(frame, label, (x, y - 5), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
                
                # ì–¼êµ´ ì¤‘ì‹¬ì 
                center_x, center_y = x + w//2, y + h//2
                cv2.circle(frame, (center_x, center_y), 3, color, -1)
            
            return frame
            
        except Exception as e:
            logger.error(f"í”„ë ˆì„ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return frame
    
    def draw_info_overlay(self, frame: np.ndarray):
        """ì •ë³´ ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸°"""
        if not self.show_info:
            return
        
        # FPS ê³„ì‚°
        self.frame_count += 1
        elapsed_time = time.time() - self.start_time
        fps = self.frame_count / elapsed_time if elapsed_time > 0 else 0
        
        # ë°°ê²½ ë°•ìŠ¤
        cv2.rectangle(frame, (10, 10), (400, 150), (0, 0, 0), -1)
        cv2.rectangle(frame, (10, 10), (400, 150), (255, 255, 255), 2)
        
        # ì •ë³´ í…ìŠ¤íŠ¸
        y_offset = 35
        cv2.putText(frame, f"FPS: {fps:.1f}", (20, y_offset), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        y_offset += 25
        cv2.putText(frame, f"Registered: {len(self.registered_persons)}", (20, y_offset), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        y_offset += 25
        cv2.putText(frame, "Controls:", (20, y_offset), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        y_offset += 20
        cv2.putText(frame, "q: Quit, s: Screenshot", (20, y_offset), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        y_offset += 15
        cv2.putText(frame, "i: Toggle info, r: Reload", (20, y_offset), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    
    def handle_key_input(self, key: int) -> str:
        """í‚¤ ì…ë ¥ ì²˜ë¦¬"""
        if key == ord('q'):
            return 'quit'
        elif key == ord('s'):
            timestamp = int(time.time())
            filename = f"data/output/face_recognition_demo_{timestamp}.jpg"
            return f'screenshot:{filename}'
        elif key == ord('i'):
            self.show_info = not self.show_info
            return f'toggle_info:{self.show_info}'
        elif key == ord('r'):
            self.load_registered_persons()
            return 'reload'
        return 'continue'
    
    def run(self) -> bool:
        """ë°ëª¨ ì‹¤í–‰"""
        print("ğŸ¯ ì–¼êµ´ ì¸ì‹ ë°ëª¨ ì‹œì‘")
        print("=" * 50)
        print("ê¸°ëŠ¥:")
        print("  - ì‹¤ì‹œê°„ ì–¼êµ´ ê²€ì¶œ")
        print("  - ë“±ë¡ëœ ì¸ë¬¼ ì¸ì‹")
        print("  - FPS ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")
        print("=" * 50)
        print("í‚¤ë³´ë“œ ì¡°ì‘:")
        print("  'q' - ì¢…ë£Œ")
        print("  's' - ìŠ¤í¬ë¦°ìƒ· ì €ì¥")
        print("  'i' - ì •ë³´ í‘œì‹œ í† ê¸€")
        print("  'r' - ë“±ë¡ëœ ì¸ë¬¼ ë‹¤ì‹œ ë¡œë“œ")
        print("=" * 50)
        
        if not self.initialize_camera():
            return False
        
        try:
            while True:
                ret, frame = self.camera.read()
                if not ret:
                    logger.warning("í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                    break
                
                # í”„ë ˆì„ ì²˜ë¦¬
                processed_frame = self.process_frame(frame)
                
                # ì •ë³´ ì˜¤ë²„ë ˆì´
                self.draw_info_overlay(processed_frame)
                
                # í”„ë ˆì„ í‘œì‹œ
                cv2.imshow('Face Recognition Demo', processed_frame)
                
                # í‚¤ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                action = self.handle_key_input(key)
                
                if action == 'quit':
                    print("ğŸ›‘ ì¢…ë£Œ ìš”ì²­")
                    break
                elif action.startswith('screenshot:'):
                    filename = action.split(':', 1)[1]
                    cv2.imwrite(filename, processed_frame)
                    print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {filename}")
                elif action.startswith('toggle_info:'):
                    status = action.split(':', 1)[1]
                    print(f"â„¹ï¸ ì •ë³´ í‘œì‹œ: {'ON' if status == 'True' else 'OFF'}")
                elif action == 'reload':
                    print("ğŸ”„ ë“±ë¡ëœ ì¸ë¬¼ ë‹¤ì‹œ ë¡œë“œ")
        
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤")
        
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(f"ë°ëª¨ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
            return False
        
        finally:
            if self.camera:
                self.camera.release()
            cv2.destroyAllWindows()
            
            # ìµœì¢… í†µê³„
            total_time = time.time() - self.start_time
            print("âœ… ë°ëª¨ ì¢…ë£Œ")
            print(f"ğŸ“Š ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.1f}ì´ˆ")
            print(f"ğŸ“Š ì´ í”„ë ˆì„ ìˆ˜: {self.frame_count}")
            print(f"ğŸ“Š í‰ê·  FPS: {self.frame_count/total_time:.1f}")
        
        return True

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ì–¼êµ´ ì¸ì‹ ë°ëª¨")
    parser.add_argument("--camera", type=int, default=0, help="ì¹´ë©”ë¼ ID (ê¸°ë³¸ê°’: 0)")
    parser.add_argument("--verbose", "-v", action="store_true", help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")
    args = parser.parse_args()
    
    # ë¡œê¹… ì„¤ì •
    setup_logging(level="DEBUG" if args.verbose else "INFO")
    
    # ë°ëª¨ ì‹¤í–‰
    demo = FaceRecognitionDemo(camera_id=args.camera)
    success = demo.run()
    
    return 0 if success else 1

if __name__ == "__main__":
    sys.exit(main()) 