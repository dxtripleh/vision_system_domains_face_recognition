# Datasets í´ë”

ì´ í´ë”ëŠ” ë¹„ì „ ì‹œìŠ¤í…œì˜ í•™ìŠµ ë°ì´í„°ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.

## ğŸ“ í´ë” êµ¬ì¡°

```
datasets/
â”œâ”€â”€ __init__.py                 # Python íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
â”œâ”€â”€ README.md                   # ì´ íŒŒì¼
â”œâ”€â”€ humanoid/                   # ì¸ê°„í˜• ë„ë©”ì¸ ë°ì´í„°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ raw/                    # ì›ë³¸ ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ face_images/        # ì–¼êµ´ ì´ë¯¸ì§€
â”‚   â”‚   â”œâ”€â”€ emotion_images/     # ê°ì • ì´ë¯¸ì§€ (í–¥í›„)
â”‚   â”‚   â””â”€â”€ pose_images/        # ìì„¸ ì´ë¯¸ì§€ (í–¥í›„)
â”‚   â”œâ”€â”€ processed/              # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ aligned_faces/      # ì •ë ¬ëœ ì–¼êµ´
â”‚   â”‚   â”œâ”€â”€ normalized/         # ì •ê·œí™”ëœ ì´ë¯¸ì§€
â”‚   â”‚   â””â”€â”€ resized/            # í¬ê¸° ì¡°ì •ëœ ì´ë¯¸ì§€
â”‚   â”œâ”€â”€ augmented/              # ë°ì´í„° ì¦ê°• ê²°ê³¼
â”‚   â”‚   â”œâ”€â”€ rotation/           # íšŒì „ ì¦ê°•
â”‚   â”‚   â”œâ”€â”€ brightness/         # ë°ê¸° ì¦ê°•
â”‚   â”‚   â”œâ”€â”€ flip/               # ì¢Œìš° ë°˜ì „
â”‚   â”‚   â””â”€â”€ noise/              # ë…¸ì´ì¦ˆ ì¶”ê°€
â”‚   â”œâ”€â”€ annotations/            # ë¼ë²¨ë§ ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ face_landmarks.json # ì–¼êµ´ ëœë“œë§ˆí¬
â”‚   â”‚   â”œâ”€â”€ emotion_labels.csv  # ê°ì • ë¼ë²¨ (í–¥í›„)
â”‚   â”‚   â””â”€â”€ pose_keypoints.json # ìì„¸ í‚¤í¬ì¸íŠ¸ (í–¥í›„)
â”‚   â””â”€â”€ splits/                 # ë°ì´í„° ë¶„í• 
â”‚       â”œâ”€â”€ train.txt           # í•™ìŠµ ë°ì´í„° ëª©ë¡
â”‚       â”œâ”€â”€ val.txt             # ê²€ì¦ ë°ì´í„° ëª©ë¡
â”‚       â””â”€â”€ test.txt            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ëª©ë¡
â”œâ”€â”€ factory/                    # ê³µì¥ ë„ë©”ì¸ ë°ì´í„° (í–¥í›„)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ raw/                    # ì›ë³¸ ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ defect_images/      # ë¶ˆëŸ‰ ì´ë¯¸ì§€
â”‚   â”‚   â””â”€â”€ normal_images/      # ì •ìƒ ì´ë¯¸ì§€
â”‚   â”œâ”€â”€ processed/              # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”‚   â”œâ”€â”€ augmented/              # ë°ì´í„° ì¦ê°• ê²°ê³¼
â”‚   â”œâ”€â”€ annotations/            # ë¼ë²¨ë§ ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ defect_labels.json  # ë¶ˆëŸ‰ ë¼ë²¨
â”‚   â”‚   â””â”€â”€ bounding_boxes.json # ë°”ìš´ë”© ë°•ìŠ¤
â”‚   â””â”€â”€ splits/                 # ë°ì´í„° ë¶„í• 
â”‚       â”œâ”€â”€ train.txt
â”‚       â”œâ”€â”€ val.txt
â”‚       â””â”€â”€ test.txt
â””â”€â”€ powerline_inspection/       # í™œì„  ê²€ì‚¬ ë„ë©”ì¸ ë°ì´í„° (í–¥í›„)
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ raw/                    # ì›ë³¸ ë°ì´í„°
    â”œâ”€â”€ processed/              # ì „ì²˜ë¦¬ëœ ë°ì´í„°
    â”œâ”€â”€ augmented/              # ë°ì´í„° ì¦ê°• ê²°ê³¼
    â”œâ”€â”€ annotations/            # ë¼ë²¨ë§ ë°ì´í„°
    â””â”€â”€ splits/                 # ë°ì´í„° ë¶„í• 
```

## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥

### 1. ë°ì´í„° êµ¬ì¡°í™”
- **ë„ë©”ì¸ë³„ ë¶„ë¥˜**: humanoid, factory, powerline_inspection
- **ë‹¨ê³„ë³„ ê´€ë¦¬**: raw â†’ processed â†’ augmented
- **ë¼ë²¨ë§ í†µí•©**: JSON, CSV, YOLO í˜•ì‹ ì§€ì›

### 2. ë°ì´í„° ì¦ê°•
- **ê¸°í•˜í•™ì  ë³€í™˜**: íšŒì „, ë°˜ì „, í¬ê¸° ì¡°ì •
- **ìƒ‰ìƒ ë³€í™˜**: ë°ê¸°, ëŒ€ë¹„, ì±„ë„ ì¡°ì •
- **ë…¸ì´ì¦ˆ ì¶”ê°€**: ê°€ìš°ì‹œì•ˆ, ì†”íŠ¸&í˜í¼ ë…¸ì´ì¦ˆ

### 3. ë°ì´í„° ê²€ì¦
- **í’ˆì§ˆ ê²€ì‚¬**: ì´ë¯¸ì§€ í’ˆì§ˆ, ë¼ë²¨ ì •í™•ì„±
- **ì¼ê´€ì„± ê²€ì¦**: íŒŒì¼ëª…, ê²½ë¡œ, í˜•ì‹ ì¼ê´€ì„±
- **í†µê³„ ë¶„ì„**: í´ë˜ìŠ¤ ë¶„í¬, ë°ì´í„°ì…‹ í¬ê¸°

## ğŸ“ ë°ì´í„° ë„¤ì´ë° ê·œì¹™

### ì´ë¯¸ì§€ íŒŒì¼ ë„¤ì´ë°
**íŒ¨í„´**: `{domain}_{class}_{date}_{info}_{index}.{ext}`

**ì˜ˆì‹œ**:
```
humanoid_face_happy_20250628_indoor_001.jpg
humanoid_face_sad_20250628_outdoor_002.jpg
factory_defect_scratch_20250628_line1_001.jpg
factory_normal_product_20250628_line2_001.jpg
```

### ì¦ê°• íŒŒì¼ ë„¤ì´ë°
**íŒ¨í„´**: `{original_name}_{augment_type}[_{param}].{ext}`

**ì˜ˆì‹œ**:
```
humanoid_face_happy_20250628_indoor_001_flip.jpg
humanoid_face_happy_20250628_indoor_001_bright_120.jpg
humanoid_face_happy_20250628_indoor_001_rot_15.jpg
```

## ğŸ”§ ì‚¬ìš© ì˜ˆì‹œ

### ë°ì´í„°ì…‹ ë¡œë”©
```python
import cv2
import json
import pandas as pd
from pathlib import Path
from typing import List, Dict, Tuple

class DatasetLoader:
    """ë°ì´í„°ì…‹ ë¡œë”"""
    
    def __init__(self, dataset_path: str):
        self.dataset_path = Path(dataset_path)
        self.splits_path = self.dataset_path / "splits"
        self.annotations_path = self.dataset_path / "annotations"
    
    def load_split(self, split_name: str) -> List[Dict]:
        """ë°ì´í„° ë¶„í•  ë¡œë”©"""
        
        split_file = self.splits_path / f"{split_name}.txt"
        if not split_file.exists():
            raise FileNotFoundError(f"ë¶„í•  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {split_file}")
        
        data_list = []
        with open(split_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    data_list.append(self._load_data_item(line))
        
        return data_list
    
    def _load_data_item(self, image_path: str) -> Dict:
        """ë°ì´í„° ì•„ì´í…œ ë¡œë”©"""
        
        full_path = self.dataset_path / image_path
        if not full_path.exists():
            raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {full_path}")
        
        # ì´ë¯¸ì§€ ë¡œë”©
        image = cv2.imread(str(full_path))
        if image is None:
            raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {full_path}")
        
        # ë¼ë²¨ ë¡œë”© (ìˆëŠ” ê²½ìš°)
        label_path = self._get_label_path(image_path)
        label = self._load_label(label_path) if label_path else None
        
        return {
            "image_path": str(full_path),
            "image": image,
            "label": label,
            "metadata": self._extract_metadata(image_path)
        }
    
    def _get_label_path(self, image_path: str) -> Path:
        """ë¼ë²¨ íŒŒì¼ ê²½ë¡œ ìƒì„±"""
        
        # ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ ìƒëŒ€ ê²½ë¡œ ì¶”ì¶œ
        rel_path = Path(image_path)
        
        # ë¼ë²¨ íŒŒì¼ ê²½ë¡œ ìƒì„± (ì—¬ëŸ¬ í˜•ì‹ ì§€ì›)
        label_paths = [
            self.annotations_path / f"{rel_path.stem}.json",
            self.annotations_path / f"{rel_path.stem}.csv",
            self.annotations_path / f"{rel_path.stem}.txt"
        ]
        
        for label_path in label_paths:
            if label_path.exists():
                return label_path
        
        return None
    
    def _load_label(self, label_path: Path) -> Dict:
        """ë¼ë²¨ íŒŒì¼ ë¡œë”©"""
        
        if label_path.suffix == ".json":
            with open(label_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        elif label_path.suffix == ".csv":
            return pd.read_csv(label_path).to_dict('records')
        elif label_path.suffix == ".txt":
            with open(label_path, 'r', encoding='utf-8') as f:
                return {"text": f.read().strip()}
        
        return None
    
    def _extract_metadata(self, image_path: str) -> Dict:
        """ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        
        # íŒŒì¼ëª… íŒŒì‹±: domain_class_date_info_index.ext
        filename = Path(image_path).stem
        parts = filename.split('_')
        
        if len(parts) >= 4:
            return {
                "domain": parts[0],
                "class": parts[1],
                "date": parts[2],
                "info": parts[3],
                "index": parts[4] if len(parts) > 4 else "001"
            }
        
        return {"filename": filename}

# ì‚¬ìš© ì˜ˆì‹œ
loader = DatasetLoader("datasets/humanoid")
train_data = loader.load_split("train")
val_data = loader.load_split("val")
test_data = loader.load_split("test")

print(f"í•™ìŠµ ë°ì´í„°: {len(train_data)}ê°œ")
print(f"ê²€ì¦ ë°ì´í„°: {len(val_data)}ê°œ")
print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_data)}ê°œ")
```

### ë°ì´í„° ì¦ê°• íŒŒì´í”„ë¼ì¸
```python
import cv2
import numpy as np
from pathlib import Path
from typing import List, Tuple

class DataAugmentation:
    """ë°ì´í„° ì¦ê°• í´ë˜ìŠ¤"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.augmentation_methods = {
            "rotation": self._rotate_image,
            "brightness": self._adjust_brightness,
            "contrast": self._adjust_contrast,
            "flip": self._flip_image,
            "noise": self._add_noise,
            "blur": self._add_blur
        }
    
    def augment_dataset(self, input_dir: str, output_dir: str, num_augmentations: int = 5):
        """ë°ì´í„°ì…‹ ì¦ê°•"""
        
        input_path = Path(input_dir)
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡
        image_files = list(input_path.glob("*.jpg")) + list(input_path.glob("*.png"))
        
        total_augmented = 0
        
        for image_file in image_files:
            # ì´ë¯¸ì§€ ë¡œë”©
            image = cv2.imread(str(image_file))
            if image is None:
                continue
            
            # ì¦ê°• ìˆ˜í–‰
            augmented_images = self._augment_single_image(image, num_augmentations)
            
            # ì¦ê°•ëœ ì´ë¯¸ì§€ ì €ì¥
            base_name = image_file.stem
            for i, aug_image in enumerate(augmented_images):
                output_file = output_path / f"{base_name}_aug_{i:03d}.jpg"
                cv2.imwrite(str(output_file), aug_image)
                total_augmented += 1
            
            print(f"ì²˜ë¦¬ ì™„ë£Œ: {image_file.name} -> {num_augmentations}ê°œ ì¦ê°•")
        
        print(f"ì´ ì¦ê°•ëœ ì´ë¯¸ì§€ ìˆ˜: {total_augmented}")
    
    def _augment_single_image(self, image: np.ndarray, num_augmentations: int) -> List[np.ndarray]:
        """ë‹¨ì¼ ì´ë¯¸ì§€ ì¦ê°•"""
        
        augmented_images = []
        
        for _ in range(num_augmentations):
            aug_image = image.copy()
            
            # ëœë¤í•˜ê²Œ ì¦ê°• ë°©ë²• ì„ íƒ
            methods = list(self.augmentation_methods.keys())
            selected_methods = np.random.choice(
                methods, 
                size=min(3, len(methods)), 
                replace=False
            )
            
            # ì„ íƒëœ ë°©ë²•ë“¤ ì ìš©
            for method in selected_methods:
                if np.random.random() < self.config.get(f"{method}_probability", 0.5):
                    aug_image = self.augmentation_methods[method](aug_image)
            
            augmented_images.append(aug_image)
        
        return augmented_images
    
    def _rotate_image(self, image: np.ndarray) -> np.ndarray:
        """ì´ë¯¸ì§€ íšŒì „"""
        angle = np.random.uniform(
            self.config.get("rotation_range", (-15, 15))[0],
            self.config.get("rotation_range", (-15, 15))[1]
        )
        
        height, width = image.shape[:2]
        center = (width // 2, height // 2)
        
        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
        rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))
        
        return rotated_image
    
    def _adjust_brightness(self, image: np.ndarray) -> np.ndarray:
        """ë°ê¸° ì¡°ì •"""
        factor = np.random.uniform(
            self.config.get("brightness_range", (0.8, 1.2))[0],
            self.config.get("brightness_range", (0.8, 1.2))[1]
        )
        
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        hsv[:, :, 2] = np.clip(hsv[:, :, 2] * factor, 0, 255)
        adjusted_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        
        return adjusted_image
    
    def _adjust_contrast(self, image: np.ndarray) -> np.ndarray:
        """ëŒ€ë¹„ ì¡°ì •"""
        factor = np.random.uniform(
            self.config.get("contrast_range", (0.8, 1.2))[0],
            self.config.get("contrast_range", (0.8, 1.2))[1]
        )
        
        adjusted_image = np.clip(image * factor, 0, 255).astype(np.uint8)
        return adjusted_image
    
    def _flip_image(self, image: np.ndarray) -> np.ndarray:
        """ì¢Œìš° ë°˜ì „"""
        return cv2.flip(image, 1)
    
    def _add_noise(self, image: np.ndarray) -> np.ndarray:
        """ë…¸ì´ì¦ˆ ì¶”ê°€"""
        noise_type = np.random.choice(["gaussian", "salt_pepper"])
        
        if noise_type == "gaussian":
            mean = 0
            std = np.random.uniform(5, 25)
            noise = np.random.normal(mean, std, image.shape)
            noisy_image = np.clip(image + noise, 0, 255).astype(np.uint8)
        else:  # salt_pepper
            noisy_image = image.copy()
            prob = np.random.uniform(0.001, 0.01)
            
            # Salt noise
            salt_mask = np.random.random(image.shape[:2]) < prob
            noisy_image[salt_mask] = 255
            
            # Pepper noise
            pepper_mask = np.random.random(image.shape[:2]) < prob
            noisy_image[pepper_mask] = 0
        
        return noisy_image
    
    def _add_blur(self, image: np.ndarray) -> np.ndarray:
        """ë¸”ëŸ¬ ì¶”ê°€"""
        kernel_size = np.random.choice([3, 5, 7])
        blurred_image = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)
        return blurred_image

# ì‚¬ìš© ì˜ˆì‹œ
augmentation_config = {
    "rotation_range": (-15, 15),
    "brightness_range": (0.8, 1.2),
    "contrast_range": (0.8, 1.2),
    "rotation_probability": 0.7,
    "brightness_probability": 0.6,
    "contrast_probability": 0.6,
    "flip_probability": 0.5,
    "noise_probability": 0.3,
    "blur_probability": 0.2
}

augmenter = DataAugmentation(augmentation_config)
augmenter.augment_dataset(
    input_dir="datasets/humanoid/raw/face_images",
    output_dir="datasets/humanoid/augmented",
    num_augmentations=5
)
```

### ë°ì´í„° ê²€ì¦ ì‹œìŠ¤í…œ
```python
import cv2
import json
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple

class DatasetValidator:
    """ë°ì´í„°ì…‹ ê²€ì¦ í´ë˜ìŠ¤"""
    
    def __init__(self, dataset_path: str):
        self.dataset_path = Path(dataset_path)
        self.validation_results = {}
    
    def validate_dataset(self) -> Dict:
        """ì „ì²´ ë°ì´í„°ì…‹ ê²€ì¦"""
        
        validation_results = {
            "structure": self._validate_structure(),
            "images": self._validate_images(),
            "annotations": self._validate_annotations(),
            "splits": self._validate_splits(),
            "statistics": self._calculate_statistics()
        }
        
        self.validation_results = validation_results
        return validation_results
    
    def _validate_structure(self) -> Dict:
        """í´ë” êµ¬ì¡° ê²€ì¦"""
        
        required_folders = ["raw", "processed", "augmented", "annotations", "splits"]
        structure_results = {"valid": True, "missing_folders": []}
        
        for folder in required_folders:
            folder_path = self.dataset_path / folder
            if not folder_path.exists():
                structure_results["missing_folders"].append(folder)
                structure_results["valid"] = False
        
        return structure_results
    
    def _validate_images(self) -> Dict:
        """ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦"""
        
        image_results = {
            "valid": True,
            "total_images": 0,
            "corrupted_images": [],
            "invalid_formats": [],
            "size_issues": []
        }
        
        # ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ê²€ì‚¬
        image_extensions = [".jpg", ".jpeg", ".png", ".bmp"]
        image_files = []
        
        for ext in image_extensions:
            image_files.extend(self.dataset_path.rglob(f"*{ext}"))
            image_files.extend(self.dataset_path.rglob(f"*{ext.upper()}"))
        
        image_results["total_images"] = len(image_files)
        
        for image_file in image_files:
            # ì´ë¯¸ì§€ ë¡œë”© í…ŒìŠ¤íŠ¸
            try:
                image = cv2.imread(str(image_file))
                if image is None:
                    image_results["corrupted_images"].append(str(image_file))
                    image_results["valid"] = False
                else:
                    # í¬ê¸° ê²€ì¦
                    height, width = image.shape[:2]
                    if height < 50 or width < 50:
                        image_results["size_issues"].append({
                            "file": str(image_file),
                            "size": (width, height)
                        })
            except Exception as e:
                image_results["corrupted_images"].append(str(image_file))
                image_results["valid"] = False
        
        return image_results
    
    def _validate_annotations(self) -> Dict:
        """ë¼ë²¨ë§ ë°ì´í„° ê²€ì¦"""
        
        annotation_results = {
            "valid": True,
            "total_annotations": 0,
            "missing_annotations": [],
            "invalid_formats": [],
            "inconsistent_labels": []
        }
        
        annotations_path = self.dataset_path / "annotations"
        if not annotations_path.exists():
            annotation_results["valid"] = False
            return annotation_results
        
        # ë¼ë²¨ íŒŒì¼ ê²€ì‚¬
        label_files = list(annotations_path.glob("*.json")) + \
                     list(annotations_path.glob("*.csv")) + \
                     list(annotations_path.glob("*.txt"))
        
        annotation_results["total_annotations"] = len(label_files)
        
        for label_file in label_files:
            try:
                if label_file.suffix == ".json":
                    with open(label_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                elif label_file.suffix == ".csv":
                    data = pd.read_csv(label_file)
                elif label_file.suffix == ".txt":
                    with open(label_file, 'r', encoding='utf-8') as f:
                        data = f.read().strip()
                else:
                    annotation_results["invalid_formats"].append(str(label_file))
                    annotation_results["valid"] = False
                    continue
                
                # ë¼ë²¨ ë‚´ìš© ê²€ì¦ (ë„ë©”ì¸ë³„)
                if not self._validate_label_content(data, label_file):
                    annotation_results["inconsistent_labels"].append(str(label_file))
                    annotation_results["valid"] = False
                    
            except Exception as e:
                annotation_results["missing_annotations"].append(str(label_file))
                annotation_results["valid"] = False
        
        return annotation_results
    
    def _validate_label_content(self, data: any, label_file: Path) -> bool:
        """ë¼ë²¨ ë‚´ìš© ê²€ì¦"""
        
        # ë„ë©”ì¸ë³„ ê²€ì¦ ë¡œì§
        if "humanoid" in str(self.dataset_path):
            return self._validate_humanoid_labels(data)
        elif "factory" in str(self.dataset_path):
            return self._validate_factory_labels(data)
        
        return True
    
    def _validate_humanoid_labels(self, data: any) -> bool:
        """ì¸ê°„í˜• ë„ë©”ì¸ ë¼ë²¨ ê²€ì¦"""
        
        # ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¦
        if isinstance(data, dict) and "landmarks" in data:
            landmarks = data["landmarks"]
            if len(landmarks) != 5:  # 5ì  ëœë“œë§ˆí¬
                return False
            
            # ì¢Œí‘œ ë²”ìœ„ ê²€ì¦
            for point in landmarks:
                if len(point) != 2 or point[0] < 0 or point[1] < 0:
                    return False
        
        return True
    
    def _validate_factory_labels(self, data: any) -> bool:
        """ê³µì¥ ë„ë©”ì¸ ë¼ë²¨ ê²€ì¦"""
        
        # ë¶ˆëŸ‰ ë¼ë²¨ ê²€ì¦
        if isinstance(data, dict) and "defect_type" in data:
            valid_defect_types = ["scratch", "dent", "crack", "discoloration"]
            if data["defect_type"] not in valid_defect_types:
                return False
        
        return True
    
    def _validate_splits(self) -> Dict:
        """ë°ì´í„° ë¶„í•  ê²€ì¦"""
        
        splits_results = {
            "valid": True,
            "missing_splits": [],
            "empty_splits": [],
            "overlap_issues": []
        }
        
        splits_path = self.dataset_path / "splits"
        required_splits = ["train.txt", "val.txt", "test.txt"]
        
        split_files = {}
        for split_name in required_splits:
            split_file = splits_path / split_name
            if not split_file.exists():
                splits_results["missing_splits"].append(split_name)
                splits_results["valid"] = False
            else:
                with open(split_file, 'r', encoding='utf-8') as f:
                    files = [line.strip() for line in f if line.strip()]
                    split_files[split_name] = files
                    
                    if len(files) == 0:
                        splits_results["empty_splits"].append(split_name)
                        splits_results["valid"] = False
        
        # ì¤‘ë³µ ê²€ì‚¬
        all_files = []
        for split_name, files in split_files.items():
            for file in files:
                if file in all_files:
                    splits_results["overlap_issues"].append(file)
                    splits_results["valid"] = False
                all_files.append(file)
        
        return splits_results
    
    def _calculate_statistics(self) -> Dict:
        """ë°ì´í„°ì…‹ í†µê³„ ê³„ì‚°"""
        
        stats = {
            "total_images": 0,
            "class_distribution": {},
            "size_distribution": {},
            "format_distribution": {}
        }
        
        # ì´ë¯¸ì§€ íŒŒì¼ í†µê³„
        image_files = list(self.dataset_path.rglob("*.jpg")) + \
                     list(self.dataset_path.rglob("*.jpeg")) + \
                     list(self.dataset_path.rglob("*.png")) + \
                     list(self.dataset_path.rglob("*.bmp"))
        
        stats["total_images"] = len(image_files)
        
        for image_file in image_files:
            # í˜•ì‹ ë¶„í¬
            ext = image_file.suffix.lower()
            stats["format_distribution"][ext] = stats["format_distribution"].get(ext, 0) + 1
            
            # í¬ê¸° ë¶„í¬
            try:
                image = cv2.imread(str(image_file))
                if image is not None:
                    height, width = image.shape[:2]
                    size_category = f"{width}x{height}"
                    stats["size_distribution"][size_category] = stats["size_distribution"].get(size_category, 0) + 1
            except:
                pass
            
            # í´ë˜ìŠ¤ ë¶„í¬ (íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ)
            filename = image_file.stem
            parts = filename.split('_')
            if len(parts) >= 2:
                class_name = parts[1]
                stats["class_distribution"][class_name] = stats["class_distribution"].get(class_name, 0) + 1
        
        return stats
    
    def generate_report(self) -> str:
        """ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        if not self.validation_results:
            self.validate_dataset()
        
        report = []
        report.append("# ë°ì´í„°ì…‹ ê²€ì¦ ë¦¬í¬íŠ¸")
        report.append(f"ë°ì´í„°ì…‹ ê²½ë¡œ: {self.dataset_path}")
        report.append("")
        
        # êµ¬ì¡° ê²€ì¦ ê²°ê³¼
        structure = self.validation_results["structure"]
        report.append("## 1. í´ë” êµ¬ì¡° ê²€ì¦")
        if structure["valid"]:
            report.append("âœ… í´ë” êµ¬ì¡°ê°€ ì˜¬ë°”ë¦…ë‹ˆë‹¤.")
        else:
            report.append("âŒ í´ë” êµ¬ì¡°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
            for folder in structure["missing_folders"]:
                report.append(f"  - ëˆ„ë½ëœ í´ë”: {folder}")
        report.append("")
        
        # ì´ë¯¸ì§€ ê²€ì¦ ê²°ê³¼
        images = self.validation_results["images"]
        report.append("## 2. ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦")
        report.append(f"ì´ ì´ë¯¸ì§€ ìˆ˜: {images['total_images']}")
        if images["valid"]:
            report.append("âœ… ëª¨ë“  ì´ë¯¸ì§€ê°€ ì˜¬ë°”ë¦…ë‹ˆë‹¤.")
        else:
            report.append("âŒ ì´ë¯¸ì§€ íŒŒì¼ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
            if images["corrupted_images"]:
                report.append(f"  - ì†ìƒëœ ì´ë¯¸ì§€: {len(images['corrupted_images'])}ê°œ")
            if images["size_issues"]:
                report.append(f"  - í¬ê¸° ë¬¸ì œ: {len(images['size_issues'])}ê°œ")
        report.append("")
        
        # ë¼ë²¨ë§ ê²€ì¦ ê²°ê³¼
        annotations = self.validation_results["annotations"]
        report.append("## 3. ë¼ë²¨ë§ ë°ì´í„° ê²€ì¦")
        report.append(f"ì´ ë¼ë²¨ íŒŒì¼ ìˆ˜: {annotations['total_annotations']}")
        if annotations["valid"]:
            report.append("âœ… ëª¨ë“  ë¼ë²¨ë§ì´ ì˜¬ë°”ë¦…ë‹ˆë‹¤.")
        else:
            report.append("âŒ ë¼ë²¨ë§ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
            if annotations["missing_annotations"]:
                report.append(f"  - ëˆ„ë½ëœ ë¼ë²¨: {len(annotations['missing_annotations'])}ê°œ")
            if annotations["inconsistent_labels"]:
                report.append(f"  - ì¼ê´€ì„± ë¬¸ì œ: {len(annotations['inconsistent_labels'])}ê°œ")
        report.append("")
        
        # ë¶„í•  ê²€ì¦ ê²°ê³¼
        splits = self.validation_results["splits"]
        report.append("## 4. ë°ì´í„° ë¶„í•  ê²€ì¦")
        if splits["valid"]:
            report.append("âœ… ë°ì´í„° ë¶„í• ì´ ì˜¬ë°”ë¦…ë‹ˆë‹¤.")
        else:
            report.append("âŒ ë°ì´í„° ë¶„í• ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
            if splits["missing_splits"]:
                report.append(f"  - ëˆ„ë½ëœ ë¶„í• : {splits['missing_splits']}")
            if splits["empty_splits"]:
                report.append(f"  - ë¹ˆ ë¶„í• : {splits['empty_splits']}")
        report.append("")
        
        # í†µê³„ ì •ë³´
        stats = self.validation_results["statistics"]
        report.append("## 5. ë°ì´í„°ì…‹ í†µê³„")
        report.append(f"ì´ ì´ë¯¸ì§€ ìˆ˜: {stats['total_images']}")
        report.append("í´ë˜ìŠ¤ ë¶„í¬:")
        for class_name, count in stats["class_distribution"].items():
            report.append(f"  - {class_name}: {count}ê°œ")
        report.append("")
        
        return "\n".join(report)

# ì‚¬ìš© ì˜ˆì‹œ
validator = DatasetValidator("datasets/humanoid")
validation_results = validator.validate_dataset()
report = validator.generate_report()

print(report)

# ê²€ì¦ ê²°ê³¼ ì €ì¥
with open("datasets/validation_report.md", "w", encoding="utf-8") as f:
    f.write(report)
```

## ğŸ“Š ë°ì´í„°ì…‹ í†µê³„

### í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„
```python
def analyze_class_distribution(dataset_path: str) -> Dict:
    """í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„"""
    
    class_counts = {}
    dataset_path = Path(dataset_path)
    
    # ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ê²€ì‚¬
    image_files = list(dataset_path.rglob("*.jpg")) + list(dataset_path.rglob("*.png"))
    
    for image_file in image_files:
        # íŒŒì¼ëª…ì—ì„œ í´ë˜ìŠ¤ ì¶”ì¶œ
        filename = image_file.stem
        parts = filename.split('_')
        
        if len(parts) >= 2:
            class_name = parts[1]
            class_counts[class_name] = class_counts.get(class_name, 0) + 1
    
    # í†µê³„ ê³„ì‚°
    total_images = sum(class_counts.values())
    class_distribution = {
        class_name: {
            "count": count,
            "percentage": (count / total_images) * 100
        }
        for class_name, count in class_counts.items()
    }
    
    return {
        "total_images": total_images,
        "class_distribution": class_distribution,
        "imbalance_ratio": max(class_counts.values()) / min(class_counts.values()) if class_counts else 0
    }

# ì‚¬ìš© ì˜ˆì‹œ
stats = analyze_class_distribution("datasets/humanoid")
print(f"ì´ ì´ë¯¸ì§€ ìˆ˜: {stats['total_images']}")
print("í´ë˜ìŠ¤ ë¶„í¬:")
for class_name, info in stats["class_distribution"].items():
    print(f"  {class_name}: {info['count']}ê°œ ({info['percentage']:.1f}%)")
print(f"ë¶ˆê· í˜• ë¹„ìœ¨: {stats['imbalance_ratio']:.2f}")
```

## ğŸš¨ ì£¼ì˜ì‚¬í•­

### 1. ë°ì´í„° í’ˆì§ˆ
- **ì´ë¯¸ì§€ í’ˆì§ˆ**: í•´ìƒë„, ë…¸ì´ì¦ˆ, ë¸”ëŸ¬ ë“± í’ˆì§ˆ ê²€ì¦
- **ë¼ë²¨ ì •í™•ì„±**: ë¼ë²¨ë§ ì˜¤ë¥˜ ë° ì¼ê´€ì„± ê²€ì¦
- **ë°ì´í„° ì¤‘ë³µ**: ì¤‘ë³µ ì´ë¯¸ì§€ ë° ë¼ë²¨ ì œê±°

### 2. ë°ì´í„° ë³´ì•ˆ
- **ê°œì¸ì •ë³´ ë³´í˜¸**: ì–¼êµ´ ë°ì´í„° ìµëª…í™” ë° ì•”í˜¸í™”
- **ì ‘ê·¼ ì œì–´**: ë°ì´í„° ì ‘ê·¼ ê¶Œí•œ ê´€ë¦¬
- **ë°±ì—…**: ì¤‘ìš” ë°ì´í„° ì •ê¸° ë°±ì—…

### 3. ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­
- **ì €ì¥ ê³µê°„**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì••ì¶• ë° ìµœì í™”
- **ë¡œë”© ì†ë„**: ë°ì´í„° ë¡œë”© ìµœì í™”
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: ë°°ì¹˜ ì²˜ë¦¬ ë° ìŠ¤íŠ¸ë¦¬ë°

### 4. ìœ ì§€ë³´ìˆ˜ ê³ ë ¤ì‚¬í•­
- **ë²„ì „ ê´€ë¦¬**: ë°ì´í„°ì…‹ ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ
- **ë¬¸ì„œí™”**: ë°ì´í„°ì…‹ êµ¬ì¡° ë° ì‚¬ìš©ë²• ë¬¸ì„œí™”
- **í…ŒìŠ¤íŠ¸**: ì •ê¸°ì ì¸ ë°ì´í„°ì…‹ ê²€ì¦

## ğŸ“ ì§€ì›

### ë¬¸ì œ í•´ê²°
1. **ë°ì´í„° ë¡œë”© ì‹¤íŒ¨**: íŒŒì¼ ê²½ë¡œ ë° í˜•ì‹ í™•ì¸
2. **ë©”ëª¨ë¦¬ ë¶€ì¡±**: ë°°ì¹˜ í¬ê¸° ë° ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
3. **ë¼ë²¨ë§ ì˜¤ë¥˜**: ë¼ë²¨ í˜•ì‹ ë° ë‚´ìš© ê²€ì¦
4. **ì„±ëŠ¥ ì €í•˜**: ë°ì´í„° ì „ì²˜ë¦¬ ìµœì í™”

### ì¶”ê°€ ë„ì›€ë§
- ê° ë„ë©”ì¸ë³„ ë°ì´í„° êµ¬ì¡° ë¬¸ì„œ ì°¸ì¡°
- ë°ì´í„° ì¦ê°• íŒŒë¼ë¯¸í„° íŠœë‹ ê°€ì´ë“œ
- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ í™•ì¸
- GitHub Issuesì—ì„œ ìœ ì‚¬í•œ ë¬¸ì œ ê²€ìƒ‰

### ê¸°ì—¬ ë°©ë²•
1. ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ì¶”ê°€ ì‹œ êµ¬ì¡° ê·œì¹™ ì¤€ìˆ˜
2. ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ë¬¸ì„œí™” í¬í•¨
3. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì œê³µ
4. ì‚¬ìš© ì˜ˆì‹œ ë° ê°€ì´ë“œ í¬í•¨ 